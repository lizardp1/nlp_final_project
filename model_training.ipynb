{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1NvX6pTMwuyIVFoczcX-VPpOMgG-1Bsdw","authorship_tag":"ABX9TyMt001D4WxHrWO3pxxmNLAY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c5eff0c0f2394d5fa500049c4fc85060":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f323b672eeda4a70b6b6404fa1f43c3a","IPY_MODEL_b4ebc2b83c094f5daca214d82ab0d4f3","IPY_MODEL_44fbd53563154e1fba565a2e8c18b705"],"layout":"IPY_MODEL_0ef7e579d23143f59a8fdb9ba8f16dbe"}},"f323b672eeda4a70b6b6404fa1f43c3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9286212282064944ad3ea3d16fbd6430","placeholder":"​","style":"IPY_MODEL_118489bb70664cb3b58824b6e52d94cc","value":"README.md: 100%"}},"b4ebc2b83c094f5daca214d82ab0d4f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7c4cc876b844f28b0f8dab34d1a9ea9","max":20789,"min":0,"orientation":"horizontal","style":"IPY_MODEL_afa56c57c26847a3bf09d44e6ceea461","value":20789}},"44fbd53563154e1fba565a2e8c18b705":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4f46bc75930430aa1970508aa00c619","placeholder":"​","style":"IPY_MODEL_e22cafa89a2040da952b9e3ee0cec947","value":" 20.8k/20.8k [00:00&lt;00:00, 1.83MB/s]"}},"0ef7e579d23143f59a8fdb9ba8f16dbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9286212282064944ad3ea3d16fbd6430":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"118489bb70664cb3b58824b6e52d94cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7c4cc876b844f28b0f8dab34d1a9ea9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afa56c57c26847a3bf09d44e6ceea461":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4f46bc75930430aa1970508aa00c619":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e22cafa89a2040da952b9e3ee0cec947":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"777fcf690dcc4f1d97e999d9556f6028":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66a41f46bcbd4c2d89996641b2913fcf","IPY_MODEL_30ebedab284b40f7bcd20a38e2f03685","IPY_MODEL_ae65bc55b8a6429b8e19153a43cf84fd"],"layout":"IPY_MODEL_3ef5ce5810604f148ff054700d3a7186"}},"66a41f46bcbd4c2d89996641b2913fcf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a33535e778c9451787be252b9e21e662","placeholder":"​","style":"IPY_MODEL_c428c02eee1e452dbe0e014684a3bcda","value":"train-00000-of-00001.parquet: 100%"}},"30ebedab284b40f7bcd20a38e2f03685":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c557f58f51c140f492d92e67f5997b01","max":50161923,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be9c22c7e61d4accbaef182cb7389875","value":50161923}},"ae65bc55b8a6429b8e19153a43cf84fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e5bde8874fc48cab3095b86176a55c6","placeholder":"​","style":"IPY_MODEL_229496ee6ee9413b883b1e822536e94f","value":" 50.2M/50.2M [00:01&lt;00:00, 37.6MB/s]"}},"3ef5ce5810604f148ff054700d3a7186":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a33535e778c9451787be252b9e21e662":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c428c02eee1e452dbe0e014684a3bcda":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c557f58f51c140f492d92e67f5997b01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be9c22c7e61d4accbaef182cb7389875":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e5bde8874fc48cab3095b86176a55c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"229496ee6ee9413b883b1e822536e94f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51866096df0b4ddb9dc240405baad580":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80a775b1e227462f81fbfc826e784cb8","IPY_MODEL_df2b41c4c3894f75844c1e0948372421","IPY_MODEL_f347eb185a314fcab69adec16291add8"],"layout":"IPY_MODEL_4141fadd0cf14803b82bf736ccbe5987"}},"80a775b1e227462f81fbfc826e784cb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bd8b82ef3464be586455bcc4e80bfaf","placeholder":"​","style":"IPY_MODEL_9fa54321a56d4ce2a01e8062231b6803","value":"test-00000-of-00001.parquet: 100%"}},"df2b41c4c3894f75844c1e0948372421":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6195d085399e4de5bbf8b06b4bf841b6","max":308237,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed67c71938ff466db22b0eb5ac873cf2","value":308237}},"f347eb185a314fcab69adec16291add8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baa31d96c07e468faa858e70c3f87533","placeholder":"​","style":"IPY_MODEL_b8951c4e49ad42e7a8c7f1b7615a8378","value":" 308k/308k [00:00&lt;00:00, 22.3MB/s]"}},"4141fadd0cf14803b82bf736ccbe5987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bd8b82ef3464be586455bcc4e80bfaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fa54321a56d4ce2a01e8062231b6803":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6195d085399e4de5bbf8b06b4bf841b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed67c71938ff466db22b0eb5ac873cf2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"baa31d96c07e468faa858e70c3f87533":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8951c4e49ad42e7a8c7f1b7615a8378":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b675bb2d19a54357b44f38f942a80275":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1750fd2df44c4bcc876838e9e9d153d3","IPY_MODEL_61301d98ab684ddba3fe482ef983f125","IPY_MODEL_4e95b3173ee245ba989b42c2d9553f79"],"layout":"IPY_MODEL_f094e821b3944e2386082bbdacec521b"}},"1750fd2df44c4bcc876838e9e9d153d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b67fb092b50e43cb8dad05a82c611463","placeholder":"​","style":"IPY_MODEL_de973b1c29ed4e508d36d5d28251da95","value":"validation-00000-of-00001.parquet: 100%"}},"61301d98ab684ddba3fe482ef983f125":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a885f96145f04cf580246b242a976c1f","max":157207,"min":0,"orientation":"horizontal","style":"IPY_MODEL_843736a3b321447baaac1253bd733946","value":157207}},"4e95b3173ee245ba989b42c2d9553f79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb6b994470a745e8b5323c038ec4819a","placeholder":"​","style":"IPY_MODEL_51bd9967ef9f484fa5983da27d1696f3","value":" 157k/157k [00:00&lt;00:00, 2.38MB/s]"}},"f094e821b3944e2386082bbdacec521b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b67fb092b50e43cb8dad05a82c611463":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de973b1c29ed4e508d36d5d28251da95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a885f96145f04cf580246b242a976c1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"843736a3b321447baaac1253bd733946":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb6b994470a745e8b5323c038ec4819a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51bd9967ef9f484fa5983da27d1696f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1952fe0c24fb4ec1aad57b0dcdfeda02":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f82721c4914b4dbebe9c765f76c72111","IPY_MODEL_2c1d4b6c40c54af8a7144ff84f88beed","IPY_MODEL_0c079b8a7c32420e8b942f07118f4c46"],"layout":"IPY_MODEL_ef1e2895d6434da6a198ca71cd0aebc9"}},"f82721c4914b4dbebe9c765f76c72111":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1964009f5cf546b3af8e96a1bc773981","placeholder":"​","style":"IPY_MODEL_1745f9ddb16a4a95b570302ba4a1785c","value":"Generating train split: 100%"}},"2c1d4b6c40c54af8a7144ff84f88beed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f63ea06f13764113968d1b0d0d62a420","max":392702,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15d76f2175a54ac49d08c13dcf76d709","value":392702}},"0c079b8a7c32420e8b942f07118f4c46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_446e826a84774187815819447709057d","placeholder":"​","style":"IPY_MODEL_4b461d4733e74fdd9ec85a5fd50f3e76","value":" 392702/392702 [00:00&lt;00:00, 760752.38 examples/s]"}},"ef1e2895d6434da6a198ca71cd0aebc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1964009f5cf546b3af8e96a1bc773981":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1745f9ddb16a4a95b570302ba4a1785c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f63ea06f13764113968d1b0d0d62a420":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15d76f2175a54ac49d08c13dcf76d709":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"446e826a84774187815819447709057d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b461d4733e74fdd9ec85a5fd50f3e76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4239608ef5d44380b531412449296664":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_625aee655b7b46079d34a0a1647e1a1c","IPY_MODEL_adb6ea80ea264d748d0d2402db98a242","IPY_MODEL_3671d379a42942c6a28bcb0397d1f11b"],"layout":"IPY_MODEL_7939ad7bd3fe4625b9787e8499800b14"}},"625aee655b7b46079d34a0a1647e1a1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73f81764edb144f586df097407391a51","placeholder":"​","style":"IPY_MODEL_d54a38b16eb549d2bd65bfd41cf6fbc5","value":"Generating test split: 100%"}},"adb6ea80ea264d748d0d2402db98a242":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ce7ec4509e04be78395db3cd7431706","max":5010,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68cb99c32d0d4c75a94bb7298ec519aa","value":5010}},"3671d379a42942c6a28bcb0397d1f11b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1be1c5276fa54bcd8912e5f823e48bd9","placeholder":"​","style":"IPY_MODEL_531d9d7203c14ab5998c0c6ed0aced1d","value":" 5010/5010 [00:00&lt;00:00, 234803.04 examples/s]"}},"7939ad7bd3fe4625b9787e8499800b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73f81764edb144f586df097407391a51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d54a38b16eb549d2bd65bfd41cf6fbc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ce7ec4509e04be78395db3cd7431706":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68cb99c32d0d4c75a94bb7298ec519aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1be1c5276fa54bcd8912e5f823e48bd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"531d9d7203c14ab5998c0c6ed0aced1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0de9968509cb4b6e8b73a3bf95b15229":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a930521520214ebdbe47c62a98c0b955","IPY_MODEL_3eea2cc4bd8048e59e1aa26502c47b1e","IPY_MODEL_ae0f7f3cfd1b4ccaaf64ad0cd8368d32"],"layout":"IPY_MODEL_8e4ef496569644aab212c2400f38a519"}},"a930521520214ebdbe47c62a98c0b955":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dc1088ab7ae4402aaeda02d55377c41","placeholder":"​","style":"IPY_MODEL_0d9fef2b8b0a4c8cb7d35508f1ce8366","value":"Generating validation split: 100%"}},"3eea2cc4bd8048e59e1aa26502c47b1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b70cf127b67742f78c1a4cc4313ced38","max":2490,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd62c6ef18f7421e848a48ce13f4a371","value":2490}},"ae0f7f3cfd1b4ccaaf64ad0cd8368d32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82be2b292dfa434594637da0687cd6e6","placeholder":"​","style":"IPY_MODEL_9d42386cdbcf42c4b5597ef54d018310","value":" 2490/2490 [00:00&lt;00:00, 134085.90 examples/s]"}},"8e4ef496569644aab212c2400f38a519":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dc1088ab7ae4402aaeda02d55377c41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d9fef2b8b0a4c8cb7d35508f1ce8366":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b70cf127b67742f78c1a4cc4313ced38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd62c6ef18f7421e848a48ce13f4a371":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82be2b292dfa434594637da0687cd6e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d42386cdbcf42c4b5597ef54d018310":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec3f77678fb942b1a60255ec15b3459a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_703f91a736874fcfafc982d69eb8219d","IPY_MODEL_74e666169dfa47f19c6ce9eabb972e30","IPY_MODEL_7b6a95ccb9b145c3ad32a5bc5cea7e1d"],"layout":"IPY_MODEL_9e9894c74acc45e98d046266787831fe"}},"703f91a736874fcfafc982d69eb8219d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_284ade51d420416997ee700c934fbe74","placeholder":"​","style":"IPY_MODEL_ee2fecf0c1654127b5ab464f29861a45","value":"train-00000-of-00001.parquet: 100%"}},"74e666169dfa47f19c6ce9eabb972e30":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfc0272afb314e66b9c0624a62961a19","max":69986524,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fde60a02eae64189b41f6bc170146c40","value":69986524}},"7b6a95ccb9b145c3ad32a5bc5cea7e1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52de107e329e49ee8407e12fc9918eab","placeholder":"​","style":"IPY_MODEL_6c2bfd7b971045caae82c53f2096b741","value":" 70.0M/70.0M [00:00&lt;00:00, 236MB/s]"}},"9e9894c74acc45e98d046266787831fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"284ade51d420416997ee700c934fbe74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee2fecf0c1654127b5ab464f29861a45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfc0272afb314e66b9c0624a62961a19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fde60a02eae64189b41f6bc170146c40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52de107e329e49ee8407e12fc9918eab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c2bfd7b971045caae82c53f2096b741":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4247d0d404f4ac9bcf6133239229681":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6784498f6f44fe9889e676facff3c46","IPY_MODEL_6952cc7cd5ec448c85c00d999ff2af2c","IPY_MODEL_3f5c0271e1de4a7b8ba79fa60eee2c20"],"layout":"IPY_MODEL_c9484394b9d840b3a26a45209b1805a4"}},"f6784498f6f44fe9889e676facff3c46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13c675c74c334056b0901c8c34e8b946","placeholder":"​","style":"IPY_MODEL_2e7988ee5e9d4476ba9f9053bb09abe9","value":"test-00000-of-00001.parquet: 100%"}},"6952cc7cd5ec448c85c00d999ff2af2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_338cc5388179482c8c8d5ce76248b382","max":477352,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb501f8b7c2e4679bde9289995849f8d","value":477352}},"3f5c0271e1de4a7b8ba79fa60eee2c20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54b38046cd5141fe8087ff13237c4464","placeholder":"​","style":"IPY_MODEL_120b2b2e45a24d03830f6b76074d4f64","value":" 477k/477k [00:00&lt;00:00, 31.6MB/s]"}},"c9484394b9d840b3a26a45209b1805a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13c675c74c334056b0901c8c34e8b946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e7988ee5e9d4476ba9f9053bb09abe9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"338cc5388179482c8c8d5ce76248b382":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb501f8b7c2e4679bde9289995849f8d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54b38046cd5141fe8087ff13237c4464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"120b2b2e45a24d03830f6b76074d4f64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e0ed24092144c96b12888c5937d8ab4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_641f175a7c644cf486856ac2ede1b78d","IPY_MODEL_662d467a9ec14131b3ea1be8a2154e4d","IPY_MODEL_8590b0a044fd46bf9510eafa52277bc9"],"layout":"IPY_MODEL_87d00a3e5f9643a8936372911e211a2f"}},"641f175a7c644cf486856ac2ede1b78d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bf91109f13a40fe95bff9f1eae9ad10","placeholder":"​","style":"IPY_MODEL_926163f90b0e4e0b971f921c959bca54","value":"validation-00000-of-00001.parquet: 100%"}},"662d467a9ec14131b3ea1be8a2154e4d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcac846564f84c2485efe390fce29f71","max":238730,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2627a09a65f342e3be5b0e60d1dc26d5","value":238730}},"8590b0a044fd46bf9510eafa52277bc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4b3cabc7c49433fbe217d0029d52cce","placeholder":"​","style":"IPY_MODEL_3256342c752942bc9a8239f720944f12","value":" 239k/239k [00:00&lt;00:00, 3.51MB/s]"}},"87d00a3e5f9643a8936372911e211a2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bf91109f13a40fe95bff9f1eae9ad10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"926163f90b0e4e0b971f921c959bca54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcac846564f84c2485efe390fce29f71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2627a09a65f342e3be5b0e60d1dc26d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4b3cabc7c49433fbe217d0029d52cce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3256342c752942bc9a8239f720944f12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f632e34fe2894fda85f56097e606f10e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39830c52ff47493e9b221017693c29be","IPY_MODEL_329f4a7ff10c465abda5227255def485","IPY_MODEL_ba64cb8ee44245de9f798c1dd785c797"],"layout":"IPY_MODEL_1fa8a72f3f994a5895ea7f5209bf4787"}},"39830c52ff47493e9b221017693c29be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7c9feb8d5e6408a828ec601c94c9d49","placeholder":"​","style":"IPY_MODEL_f3220480d1c04aee9b8e7e88171133c1","value":"Generating train split: 100%"}},"329f4a7ff10c465abda5227255def485":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_baa36fe718fc473e9241fa16da0e0f3b","max":392702,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3f8408273104cf0918dc50269a0fc5d","value":392702}},"ba64cb8ee44245de9f798c1dd785c797":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54b0bc60195d4027a99858c743a0b9fd","placeholder":"​","style":"IPY_MODEL_94a612a3a2ae4432ad9dbeeead1c6b9f","value":" 392702/392702 [00:00&lt;00:00, 552418.38 examples/s]"}},"1fa8a72f3f994a5895ea7f5209bf4787":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7c9feb8d5e6408a828ec601c94c9d49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3220480d1c04aee9b8e7e88171133c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"baa36fe718fc473e9241fa16da0e0f3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3f8408273104cf0918dc50269a0fc5d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54b0bc60195d4027a99858c743a0b9fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94a612a3a2ae4432ad9dbeeead1c6b9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5da183acd4a41f69030ad29d042ae4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c85476ee3f6b4bc59d28a5f5c95682cc","IPY_MODEL_bddc6b50f6e54335b3425d07d4b5c9a6","IPY_MODEL_7e811f3a6c574afa9295d9cddb70b8db"],"layout":"IPY_MODEL_74d4000d02bd4fc59bd67aa6fcd1ba6d"}},"c85476ee3f6b4bc59d28a5f5c95682cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79a2b32c8c944a7684d7042032b93dee","placeholder":"​","style":"IPY_MODEL_866e7d39da0e4af5a5e222cf4c7146ee","value":"Generating test split: 100%"}},"bddc6b50f6e54335b3425d07d4b5c9a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5593579a3e744bb58dce3e4ce1ad8151","max":5010,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1eecb74bc26443d0ba6fe33d97315a95","value":5010}},"7e811f3a6c574afa9295d9cddb70b8db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cfd9620ce0243f3b5f3c774ef95600c","placeholder":"​","style":"IPY_MODEL_89421c928c324220bd71ae5fcc95ca5a","value":" 5010/5010 [00:00&lt;00:00, 236170.01 examples/s]"}},"74d4000d02bd4fc59bd67aa6fcd1ba6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79a2b32c8c944a7684d7042032b93dee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"866e7d39da0e4af5a5e222cf4c7146ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5593579a3e744bb58dce3e4ce1ad8151":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1eecb74bc26443d0ba6fe33d97315a95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6cfd9620ce0243f3b5f3c774ef95600c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89421c928c324220bd71ae5fcc95ca5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f65dd0c562c44fdb78358bc81da46ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a9b60d79117348e8b7ebb697c660376f","IPY_MODEL_150537a8366b4cb88a5f3ef08fe9d616","IPY_MODEL_386d6658c8514f98920fcb618a2caeb3"],"layout":"IPY_MODEL_59d756a77f154725a0a9264beb7f3650"}},"a9b60d79117348e8b7ebb697c660376f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b34edf6fd9a47f59d46e94d3eedd92c","placeholder":"​","style":"IPY_MODEL_d3640bc5bd394b7898688cb2262230f6","value":"Generating validation split: 100%"}},"150537a8366b4cb88a5f3ef08fe9d616":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f785a33f1ba24aaf8c4fd321e52b7a71","max":2490,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a2557f0a3cb42e986b014b22c1ab28b","value":2490}},"386d6658c8514f98920fcb618a2caeb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6288c8f2a14f4e6382e09e9836abcb52","placeholder":"​","style":"IPY_MODEL_b6818808fd7c480b8d302de1aa203b16","value":" 2490/2490 [00:00&lt;00:00, 139276.89 examples/s]"}},"59d756a77f154725a0a9264beb7f3650":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b34edf6fd9a47f59d46e94d3eedd92c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3640bc5bd394b7898688cb2262230f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f785a33f1ba24aaf8c4fd321e52b7a71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a2557f0a3cb42e986b014b22c1ab28b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6288c8f2a14f4e6382e09e9836abcb52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6818808fd7c480b8d302de1aa203b16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f95d4e24b5ff4ce58363c2bfdd382f0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c5913678a024b04869aafbbe118e33c","IPY_MODEL_8964646b4f75495fa0f2cb283ef08f7d","IPY_MODEL_b24f314f463248cb9bf1fb3842eb2e6c"],"layout":"IPY_MODEL_4c38bbb97b2b48818129e6249ca912b3"}},"3c5913678a024b04869aafbbe118e33c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8354a6c390a4e0f89ab1553c472fd71","placeholder":"​","style":"IPY_MODEL_7c3b66d657264652bc2e3dce036afeb6","value":"Map: 100%"}},"8964646b4f75495fa0f2cb283ef08f7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c726f0a97c9a4d9badea0c786d4e994e","max":392702,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9e3aed004484b99a88617b89ec6855d","value":392702}},"b24f314f463248cb9bf1fb3842eb2e6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04b9d5f35c1c4116b264fc6e4eed35e2","placeholder":"​","style":"IPY_MODEL_9f90f8f9b58b4bce8c5e2cb45892853d","value":" 392702/392702 [00:15&lt;00:00, 24855.74 examples/s]"}},"4c38bbb97b2b48818129e6249ca912b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8354a6c390a4e0f89ab1553c472fd71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c3b66d657264652bc2e3dce036afeb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c726f0a97c9a4d9badea0c786d4e994e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9e3aed004484b99a88617b89ec6855d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04b9d5f35c1c4116b264fc6e4eed35e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f90f8f9b58b4bce8c5e2cb45892853d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"508badfb278f4fb8a1dff5eaa39e2404":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5e44b2fd63049919eb1d5a87604176d","IPY_MODEL_11e04d82c9944427a67472569072b7f0","IPY_MODEL_53975500bd0e4f31bc77f2d951d7d26b"],"layout":"IPY_MODEL_3bb55423857e46b5a08f8f245d8d2dd1"}},"d5e44b2fd63049919eb1d5a87604176d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_195a728a521648a5a7b694f96cba1cb2","placeholder":"​","style":"IPY_MODEL_cdda620050584352a386a2dfd56f21c2","value":"Map: 100%"}},"11e04d82c9944427a67472569072b7f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c77cd3d62764627aa60172a511c0560","max":5010,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8227c6a2a8043b59fbb9d2a615a491a","value":5010}},"53975500bd0e4f31bc77f2d951d7d26b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ea40ac86251409198c095453b71a78f","placeholder":"​","style":"IPY_MODEL_9a150a2028b7434bb130766e0556e5e0","value":" 5010/5010 [00:00&lt;00:00, 29086.49 examples/s]"}},"3bb55423857e46b5a08f8f245d8d2dd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"195a728a521648a5a7b694f96cba1cb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdda620050584352a386a2dfd56f21c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c77cd3d62764627aa60172a511c0560":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8227c6a2a8043b59fbb9d2a615a491a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ea40ac86251409198c095453b71a78f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a150a2028b7434bb130766e0556e5e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab8e3451963c4885ba6b12c45d22181e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56dcdfeb63cb497c8aeb06cb9ed6b929","IPY_MODEL_302192475ec74238bd6dad3431726c84","IPY_MODEL_723f0977839c42a7a2777fa79ddef1b0"],"layout":"IPY_MODEL_893bf172036341978f5e2795b7b40c3a"}},"56dcdfeb63cb497c8aeb06cb9ed6b929":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae791a614e324f06a26a2957e49d3f43","placeholder":"​","style":"IPY_MODEL_7bbde7cd022a48059a7fd6a39ae7479a","value":"Map: 100%"}},"302192475ec74238bd6dad3431726c84":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_446b4b713f344245b916ca6d188add8a","max":2490,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a4b7bb44e054f95adc49c5fa8aeacba","value":2490}},"723f0977839c42a7a2777fa79ddef1b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eec5d32b110347658cb7fc06463bcdac","placeholder":"​","style":"IPY_MODEL_bc1c5451d6ab4171987e0dc225a62923","value":" 2490/2490 [00:00&lt;00:00, 24977.38 examples/s]"}},"893bf172036341978f5e2795b7b40c3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae791a614e324f06a26a2957e49d3f43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bbde7cd022a48059a7fd6a39ae7479a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"446b4b713f344245b916ca6d188add8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a4b7bb44e054f95adc49c5fa8aeacba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eec5d32b110347658cb7fc06463bcdac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc1c5451d6ab4171987e0dc225a62923":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c12a23dce3945ddb95894a2d072f181":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c18dbd0971a4ceba0900abb9715d734","IPY_MODEL_b3ba41cce11a49c1ab36c7740c185ea0","IPY_MODEL_1f08050f06064bbdbb7d66bbc4c8a4bd"],"layout":"IPY_MODEL_2a46a48504db4a0a8a0a860b34366eb2"}},"2c18dbd0971a4ceba0900abb9715d734":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3afa9861be5d465ba7998178f9254c4e","placeholder":"​","style":"IPY_MODEL_aa25080704da4076a7b00d4c08b017c3","value":"Map: 100%"}},"b3ba41cce11a49c1ab36c7740c185ea0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd6eafed78b14191b7f7e086239f6648","max":392702,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d200311dd9ca411d82aed5d9486eee30","value":392702}},"1f08050f06064bbdbb7d66bbc4c8a4bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5748b042116497d8b65c98b04266b54","placeholder":"​","style":"IPY_MODEL_c117d72d8fbd404f858c0c3cccac7390","value":" 392702/392702 [00:14&lt;00:00, 19536.39 examples/s]"}},"2a46a48504db4a0a8a0a860b34366eb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3afa9861be5d465ba7998178f9254c4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa25080704da4076a7b00d4c08b017c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd6eafed78b14191b7f7e086239f6648":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d200311dd9ca411d82aed5d9486eee30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5748b042116497d8b65c98b04266b54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c117d72d8fbd404f858c0c3cccac7390":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"692aa2fee9424b1ea12739401fb72678":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f14f385282c14679853260f7612273ee","IPY_MODEL_165ecc94799c438b86361a864065b535","IPY_MODEL_8d853ceebfd749b5b350c10ede815cf9"],"layout":"IPY_MODEL_a78137d9f1bc45ecbbd79b350b61ad9c"}},"f14f385282c14679853260f7612273ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08b63e1d541c4874a8a0d293f58acdf7","placeholder":"​","style":"IPY_MODEL_7ae44ed0d5aa44468c5902d805bd3a66","value":"Map: 100%"}},"165ecc94799c438b86361a864065b535":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e69e73be4b6b493a87c73310a39c4861","max":5010,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d80cf0cdb54a423584a8e5438812b8e8","value":5010}},"8d853ceebfd749b5b350c10ede815cf9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_885c4eb4f7ca4ad2bc48475063616e2d","placeholder":"​","style":"IPY_MODEL_24a960467f424a529942e477d928828a","value":" 5010/5010 [00:00&lt;00:00, 32477.01 examples/s]"}},"a78137d9f1bc45ecbbd79b350b61ad9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08b63e1d541c4874a8a0d293f58acdf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ae44ed0d5aa44468c5902d805bd3a66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e69e73be4b6b493a87c73310a39c4861":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d80cf0cdb54a423584a8e5438812b8e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"885c4eb4f7ca4ad2bc48475063616e2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24a960467f424a529942e477d928828a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61bf2c49a6494d909db2fa2bdfe03038":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_089fbe188f4a4fb59f4694e3d8a4fe23","IPY_MODEL_0ba4e6e4d2754c97bd406620ea3a1d19","IPY_MODEL_30b5ed00629b4e6aabaaa2f4e33ec5e4"],"layout":"IPY_MODEL_ec8dbf03b8194a83bff2ea1ac150767f"}},"089fbe188f4a4fb59f4694e3d8a4fe23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b59dfbc709e542fea59b3ca622bdf9d4","placeholder":"​","style":"IPY_MODEL_90733f00216e4787992f2b032b0c7985","value":"Map: 100%"}},"0ba4e6e4d2754c97bd406620ea3a1d19":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95bd9ca28a0e4fbc8d16307bd0105008","max":2490,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2b06ba26cef46c5b85fb3f6b5a7644f","value":2490}},"30b5ed00629b4e6aabaaa2f4e33ec5e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cef2c8ae22a4428925290023db03aea","placeholder":"​","style":"IPY_MODEL_b29ff8612c65471d95d1ff7391d39ae4","value":" 2490/2490 [00:00&lt;00:00, 29021.32 examples/s]"}},"ec8dbf03b8194a83bff2ea1ac150767f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b59dfbc709e542fea59b3ca622bdf9d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90733f00216e4787992f2b032b0c7985":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95bd9ca28a0e4fbc8d16307bd0105008":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2b06ba26cef46c5b85fb3f6b5a7644f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2cef2c8ae22a4428925290023db03aea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b29ff8612c65471d95d1ff7391d39ae4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef47772530464533a917a00c1c06b810":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3197eeeff96048a6a27ae0665e283912","IPY_MODEL_003089f3950a474b9e5213ab467c2e34","IPY_MODEL_5cbf10dc8270493daddec74a325776ea"],"layout":"IPY_MODEL_27afe2f29a1c4489ba82d2c78f115f5a"}},"3197eeeff96048a6a27ae0665e283912":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6303c37b4827432d93f78184a5c3e110","placeholder":"​","style":"IPY_MODEL_664bc47886cc41748c9ceb080064106f","value":"Saving the dataset (1/1 shards): 100%"}},"003089f3950a474b9e5213ab467c2e34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9778458d44e141278fa30b3b83f23596","max":785404,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92126911133f49b6a72fa70e645a1bcd","value":785404}},"5cbf10dc8270493daddec74a325776ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dabf89cd18d44aee8834fc842e9f3313","placeholder":"​","style":"IPY_MODEL_c2f79e026ce04f77af29b5e612bfe920","value":" 785404/785404 [00:08&lt;00:00, 318794.98 examples/s]"}},"27afe2f29a1c4489ba82d2c78f115f5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6303c37b4827432d93f78184a5c3e110":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"664bc47886cc41748c9ceb080064106f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9778458d44e141278fa30b3b83f23596":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92126911133f49b6a72fa70e645a1bcd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dabf89cd18d44aee8834fc842e9f3313":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2f79e026ce04f77af29b5e612bfe920":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"886dcf01f9014f4f96c22a31f78b1473":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90c2f0ae1afe473eba56f493570481d4","IPY_MODEL_8b74421f84c4479cae25b97ceea2b362","IPY_MODEL_100ef594c4ae48d2bf18017801e33fd7"],"layout":"IPY_MODEL_eb1f9ae258af4f8a88c784c74635df25"}},"90c2f0ae1afe473eba56f493570481d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2319f6b4ecf405a830f208ace55b5b9","placeholder":"​","style":"IPY_MODEL_74c48ba2190048fcb398665a34400a71","value":"Saving the dataset (1/1 shards): 100%"}},"8b74421f84c4479cae25b97ceea2b362":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40f935c95c254071bd118d13b8ed6966","max":4980,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0803825d69e4b8d9841a5fe152cebdd","value":4980}},"100ef594c4ae48d2bf18017801e33fd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5810da4819044df8470ce1299b04917","placeholder":"​","style":"IPY_MODEL_7ce9ee7e7e6e42b7a610dd19c292b7ff","value":" 4980/4980 [00:00&lt;00:00, 172149.88 examples/s]"}},"eb1f9ae258af4f8a88c784c74635df25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2319f6b4ecf405a830f208ace55b5b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74c48ba2190048fcb398665a34400a71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40f935c95c254071bd118d13b8ed6966":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0803825d69e4b8d9841a5fe152cebdd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5810da4819044df8470ce1299b04917":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ce9ee7e7e6e42b7a610dd19c292b7ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94a42d29906249378c0c02cc0610c312":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe411d1d87a8443691978b44c2d8f7a8","IPY_MODEL_8b1c2e94b31247809b8077e1d2205ed9","IPY_MODEL_f4862d0f0e784a1ca319472413bda64c"],"layout":"IPY_MODEL_fa5c2ebec03042f1ad6d5a930ae31f51"}},"fe411d1d87a8443691978b44c2d8f7a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_703fa7d8fdfa45bcbb35424847cee255","placeholder":"​","style":"IPY_MODEL_0150a5c77daa48808906626686c13b19","value":"Saving the dataset (1/1 shards): 100%"}},"8b1c2e94b31247809b8077e1d2205ed9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5215eae3de1c47a99944a49403962905","max":10020,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f805983c7abf4ffb97773ea9f16cb1c9","value":10020}},"f4862d0f0e784a1ca319472413bda64c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0808666704784676811c3d65ffe36d80","placeholder":"​","style":"IPY_MODEL_29d5f93b19b14d78b7f555a68988b18c","value":" 10020/10020 [00:00&lt;00:00, 12335.25 examples/s]"}},"fa5c2ebec03042f1ad6d5a930ae31f51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"703fa7d8fdfa45bcbb35424847cee255":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0150a5c77daa48808906626686c13b19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5215eae3de1c47a99944a49403962905":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f805983c7abf4ffb97773ea9f16cb1c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0808666704784676811c3d65ffe36d80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29d5f93b19b14d78b7f555a68988b18c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96e3bd7048624eb785f530c2b209522a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7d7b7f0f9074d3cb017cb7381c25cc1","IPY_MODEL_89de870af4c84c53b6713b144eeffcee","IPY_MODEL_f839c098167146c5b7d5ab348c8693b8"],"layout":"IPY_MODEL_2e18a6778ad54301ac0dedf4d93d5543"}},"f7d7b7f0f9074d3cb017cb7381c25cc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4705f8a754f44b778a1573d468d417ab","placeholder":"​","style":"IPY_MODEL_4e4baab2fba04921bca51a88a75e6bbf","value":"Map: 100%"}},"89de870af4c84c53b6713b144eeffcee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86c8563a46ba460094cf80c7668d47f9","max":5010,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c92d51b72eb042a08a9c479d40292eb2","value":5010}},"f839c098167146c5b7d5ab348c8693b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c5e7d56a3d7404ba6535172bef01267","placeholder":"​","style":"IPY_MODEL_1d850ff1b3e44c18895bb91d29cf92e9","value":" 5010/5010 [00:00&lt;00:00, 11523.19 examples/s]"}},"2e18a6778ad54301ac0dedf4d93d5543":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4705f8a754f44b778a1573d468d417ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e4baab2fba04921bca51a88a75e6bbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86c8563a46ba460094cf80c7668d47f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c92d51b72eb042a08a9c479d40292eb2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c5e7d56a3d7404ba6535172bef01267":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d850ff1b3e44c18895bb91d29cf92e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"288f2ccb91fc44fba22c518b1b4b7648":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a72f5e1e414e47a69499bb782a995ae4","IPY_MODEL_fc41c29e4d414fb3828cf3ad6bfee33d","IPY_MODEL_e3a09da8c44b4dc38e4ee742495167b4"],"layout":"IPY_MODEL_94e9420192dd4fa4b2dd02037882794a"}},"a72f5e1e414e47a69499bb782a995ae4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_671b980dc2f64023b00218c4b551cb5e","placeholder":"​","style":"IPY_MODEL_90fb9183904e40bda75330508dfbd50e","value":"Map: 100%"}},"fc41c29e4d414fb3828cf3ad6bfee33d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d05f1fd39e3448781446745203720aa","max":5010,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61b02ef95d1240b69d99fbd1929342c0","value":5010}},"e3a09da8c44b4dc38e4ee742495167b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0841b58c45e249c4b5849d70793b2b5f","placeholder":"​","style":"IPY_MODEL_ffc88476302f4264a2f9e13acc86ca67","value":" 5010/5010 [00:00&lt;00:00, 10899.15 examples/s]"}},"94e9420192dd4fa4b2dd02037882794a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"671b980dc2f64023b00218c4b551cb5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90fb9183904e40bda75330508dfbd50e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d05f1fd39e3448781446745203720aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61b02ef95d1240b69d99fbd1929342c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0841b58c45e249c4b5849d70793b2b5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffc88476302f4264a2f9e13acc86ca67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIXXCKVUFGDs","executionInfo":{"status":"ok","timestamp":1733495954715,"user_tz":360,"elapsed":8466,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"b01e84e6-c37e-4fdc-c50c-70f63fc8d882"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["pip install --upgrade pip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ZhKHcW7CXA-","executionInfo":{"status":"ok","timestamp":1733495974502,"user_tz":360,"elapsed":3966,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"1d562348-d6d4-46a2-97c4-4c2560eafffc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n","Collecting pip\n","  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n","Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 24.1.2\n","    Uninstalling pip-24.1.2:\n","      Successfully uninstalled pip-24.1.2\n","Successfully installed pip-24.3.1\n"]}]},{"cell_type":"code","source":["import os\n","working_dir = '/content/drive/My Drive/nlp_final_project'\n","os.chdir(working_dir)"],"metadata":{"id":"GgTOFwaeFieI","executionInfo":{"status":"ok","timestamp":1733497116156,"user_tz":360,"elapsed":152,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zi8jPBz_CXrU","executionInfo":{"status":"ok","timestamp":1733495979118,"user_tz":360,"elapsed":4617,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"e5368d62-f9dd-4eed-ef5d-7bf5d2a8f394"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.1.1)\n","Collecting datasets (from -r requirements.txt (line 2))\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.5.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.66.6)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.46.3)\n","Collecting evaluate (from -r requirements.txt (line 6))\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.26.3)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 2))\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (2.32.3)\n","Collecting xxhash (from datasets->-r requirements.txt (line 2))\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 2))\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r requirements.txt (line 2))\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.11.9)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 3)) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.20.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 2)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 2)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 2)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 2)) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 2)) (1.16.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","Installing collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"WANDB_MODE\"] = \"disabled\""],"metadata":{"id":"68VS0_MAE_eN","executionInfo":{"status":"ok","timestamp":1733279875265,"user_tz":360,"elapsed":1,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#Create XNLI datasets\n","from datasets import load_dataset, concatenate_datasets\n","\n","xnli_en = load_dataset(\"facebook/xnli\", \"en\")\n","xnli_ru = load_dataset(\"facebook/xnli\", \"ru\")\n","\n","xnli_en = xnli_en.map(lambda examples: {'language': 'en'})\n","xnli_ru = xnli_ru.map(lambda examples: {'language': 'ru'})\n","\n","train_dataset = concatenate_datasets([xnli_en['train'], xnli_ru['train']])\n","validation_dataset = concatenate_datasets([xnli_en['validation'], xnli_ru['validation']])\n","test_dataset = concatenate_datasets([xnli_en['test'], xnli_ru['test']])\n","\n","train_dataset.save_to_disk(\"xnli_train_en_ru\")\n","validation_dataset.save_to_disk(\"xnli_validation_en_ru\")\n","test_dataset.save_to_disk(\"xnli_test_en_ru\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":721,"referenced_widgets":["c5eff0c0f2394d5fa500049c4fc85060","f323b672eeda4a70b6b6404fa1f43c3a","b4ebc2b83c094f5daca214d82ab0d4f3","44fbd53563154e1fba565a2e8c18b705","0ef7e579d23143f59a8fdb9ba8f16dbe","9286212282064944ad3ea3d16fbd6430","118489bb70664cb3b58824b6e52d94cc","e7c4cc876b844f28b0f8dab34d1a9ea9","afa56c57c26847a3bf09d44e6ceea461","b4f46bc75930430aa1970508aa00c619","e22cafa89a2040da952b9e3ee0cec947","777fcf690dcc4f1d97e999d9556f6028","66a41f46bcbd4c2d89996641b2913fcf","30ebedab284b40f7bcd20a38e2f03685","ae65bc55b8a6429b8e19153a43cf84fd","3ef5ce5810604f148ff054700d3a7186","a33535e778c9451787be252b9e21e662","c428c02eee1e452dbe0e014684a3bcda","c557f58f51c140f492d92e67f5997b01","be9c22c7e61d4accbaef182cb7389875","6e5bde8874fc48cab3095b86176a55c6","229496ee6ee9413b883b1e822536e94f","51866096df0b4ddb9dc240405baad580","80a775b1e227462f81fbfc826e784cb8","df2b41c4c3894f75844c1e0948372421","f347eb185a314fcab69adec16291add8","4141fadd0cf14803b82bf736ccbe5987","1bd8b82ef3464be586455bcc4e80bfaf","9fa54321a56d4ce2a01e8062231b6803","6195d085399e4de5bbf8b06b4bf841b6","ed67c71938ff466db22b0eb5ac873cf2","baa31d96c07e468faa858e70c3f87533","b8951c4e49ad42e7a8c7f1b7615a8378","b675bb2d19a54357b44f38f942a80275","1750fd2df44c4bcc876838e9e9d153d3","61301d98ab684ddba3fe482ef983f125","4e95b3173ee245ba989b42c2d9553f79","f094e821b3944e2386082bbdacec521b","b67fb092b50e43cb8dad05a82c611463","de973b1c29ed4e508d36d5d28251da95","a885f96145f04cf580246b242a976c1f","843736a3b321447baaac1253bd733946","fb6b994470a745e8b5323c038ec4819a","51bd9967ef9f484fa5983da27d1696f3","1952fe0c24fb4ec1aad57b0dcdfeda02","f82721c4914b4dbebe9c765f76c72111","2c1d4b6c40c54af8a7144ff84f88beed","0c079b8a7c32420e8b942f07118f4c46","ef1e2895d6434da6a198ca71cd0aebc9","1964009f5cf546b3af8e96a1bc773981","1745f9ddb16a4a95b570302ba4a1785c","f63ea06f13764113968d1b0d0d62a420","15d76f2175a54ac49d08c13dcf76d709","446e826a84774187815819447709057d","4b461d4733e74fdd9ec85a5fd50f3e76","4239608ef5d44380b531412449296664","625aee655b7b46079d34a0a1647e1a1c","adb6ea80ea264d748d0d2402db98a242","3671d379a42942c6a28bcb0397d1f11b","7939ad7bd3fe4625b9787e8499800b14","73f81764edb144f586df097407391a51","d54a38b16eb549d2bd65bfd41cf6fbc5","7ce7ec4509e04be78395db3cd7431706","68cb99c32d0d4c75a94bb7298ec519aa","1be1c5276fa54bcd8912e5f823e48bd9","531d9d7203c14ab5998c0c6ed0aced1d","0de9968509cb4b6e8b73a3bf95b15229","a930521520214ebdbe47c62a98c0b955","3eea2cc4bd8048e59e1aa26502c47b1e","ae0f7f3cfd1b4ccaaf64ad0cd8368d32","8e4ef496569644aab212c2400f38a519","5dc1088ab7ae4402aaeda02d55377c41","0d9fef2b8b0a4c8cb7d35508f1ce8366","b70cf127b67742f78c1a4cc4313ced38","dd62c6ef18f7421e848a48ce13f4a371","82be2b292dfa434594637da0687cd6e6","9d42386cdbcf42c4b5597ef54d018310","ec3f77678fb942b1a60255ec15b3459a","703f91a736874fcfafc982d69eb8219d","74e666169dfa47f19c6ce9eabb972e30","7b6a95ccb9b145c3ad32a5bc5cea7e1d","9e9894c74acc45e98d046266787831fe","284ade51d420416997ee700c934fbe74","ee2fecf0c1654127b5ab464f29861a45","bfc0272afb314e66b9c0624a62961a19","fde60a02eae64189b41f6bc170146c40","52de107e329e49ee8407e12fc9918eab","6c2bfd7b971045caae82c53f2096b741","e4247d0d404f4ac9bcf6133239229681","f6784498f6f44fe9889e676facff3c46","6952cc7cd5ec448c85c00d999ff2af2c","3f5c0271e1de4a7b8ba79fa60eee2c20","c9484394b9d840b3a26a45209b1805a4","13c675c74c334056b0901c8c34e8b946","2e7988ee5e9d4476ba9f9053bb09abe9","338cc5388179482c8c8d5ce76248b382","cb501f8b7c2e4679bde9289995849f8d","54b38046cd5141fe8087ff13237c4464","120b2b2e45a24d03830f6b76074d4f64","5e0ed24092144c96b12888c5937d8ab4","641f175a7c644cf486856ac2ede1b78d","662d467a9ec14131b3ea1be8a2154e4d","8590b0a044fd46bf9510eafa52277bc9","87d00a3e5f9643a8936372911e211a2f","7bf91109f13a40fe95bff9f1eae9ad10","926163f90b0e4e0b971f921c959bca54","bcac846564f84c2485efe390fce29f71","2627a09a65f342e3be5b0e60d1dc26d5","b4b3cabc7c49433fbe217d0029d52cce","3256342c752942bc9a8239f720944f12","f632e34fe2894fda85f56097e606f10e","39830c52ff47493e9b221017693c29be","329f4a7ff10c465abda5227255def485","ba64cb8ee44245de9f798c1dd785c797","1fa8a72f3f994a5895ea7f5209bf4787","e7c9feb8d5e6408a828ec601c94c9d49","f3220480d1c04aee9b8e7e88171133c1","baa36fe718fc473e9241fa16da0e0f3b","b3f8408273104cf0918dc50269a0fc5d","54b0bc60195d4027a99858c743a0b9fd","94a612a3a2ae4432ad9dbeeead1c6b9f","a5da183acd4a41f69030ad29d042ae4c","c85476ee3f6b4bc59d28a5f5c95682cc","bddc6b50f6e54335b3425d07d4b5c9a6","7e811f3a6c574afa9295d9cddb70b8db","74d4000d02bd4fc59bd67aa6fcd1ba6d","79a2b32c8c944a7684d7042032b93dee","866e7d39da0e4af5a5e222cf4c7146ee","5593579a3e744bb58dce3e4ce1ad8151","1eecb74bc26443d0ba6fe33d97315a95","6cfd9620ce0243f3b5f3c774ef95600c","89421c928c324220bd71ae5fcc95ca5a","4f65dd0c562c44fdb78358bc81da46ec","a9b60d79117348e8b7ebb697c660376f","150537a8366b4cb88a5f3ef08fe9d616","386d6658c8514f98920fcb618a2caeb3","59d756a77f154725a0a9264beb7f3650","0b34edf6fd9a47f59d46e94d3eedd92c","d3640bc5bd394b7898688cb2262230f6","f785a33f1ba24aaf8c4fd321e52b7a71","4a2557f0a3cb42e986b014b22c1ab28b","6288c8f2a14f4e6382e09e9836abcb52","b6818808fd7c480b8d302de1aa203b16","f95d4e24b5ff4ce58363c2bfdd382f0a","3c5913678a024b04869aafbbe118e33c","8964646b4f75495fa0f2cb283ef08f7d","b24f314f463248cb9bf1fb3842eb2e6c","4c38bbb97b2b48818129e6249ca912b3","f8354a6c390a4e0f89ab1553c472fd71","7c3b66d657264652bc2e3dce036afeb6","c726f0a97c9a4d9badea0c786d4e994e","d9e3aed004484b99a88617b89ec6855d","04b9d5f35c1c4116b264fc6e4eed35e2","9f90f8f9b58b4bce8c5e2cb45892853d","508badfb278f4fb8a1dff5eaa39e2404","d5e44b2fd63049919eb1d5a87604176d","11e04d82c9944427a67472569072b7f0","53975500bd0e4f31bc77f2d951d7d26b","3bb55423857e46b5a08f8f245d8d2dd1","195a728a521648a5a7b694f96cba1cb2","cdda620050584352a386a2dfd56f21c2","4c77cd3d62764627aa60172a511c0560","c8227c6a2a8043b59fbb9d2a615a491a","5ea40ac86251409198c095453b71a78f","9a150a2028b7434bb130766e0556e5e0","ab8e3451963c4885ba6b12c45d22181e","56dcdfeb63cb497c8aeb06cb9ed6b929","302192475ec74238bd6dad3431726c84","723f0977839c42a7a2777fa79ddef1b0","893bf172036341978f5e2795b7b40c3a","ae791a614e324f06a26a2957e49d3f43","7bbde7cd022a48059a7fd6a39ae7479a","446b4b713f344245b916ca6d188add8a","7a4b7bb44e054f95adc49c5fa8aeacba","eec5d32b110347658cb7fc06463bcdac","bc1c5451d6ab4171987e0dc225a62923","6c12a23dce3945ddb95894a2d072f181","2c18dbd0971a4ceba0900abb9715d734","b3ba41cce11a49c1ab36c7740c185ea0","1f08050f06064bbdbb7d66bbc4c8a4bd","2a46a48504db4a0a8a0a860b34366eb2","3afa9861be5d465ba7998178f9254c4e","aa25080704da4076a7b00d4c08b017c3","dd6eafed78b14191b7f7e086239f6648","d200311dd9ca411d82aed5d9486eee30","e5748b042116497d8b65c98b04266b54","c117d72d8fbd404f858c0c3cccac7390","692aa2fee9424b1ea12739401fb72678","f14f385282c14679853260f7612273ee","165ecc94799c438b86361a864065b535","8d853ceebfd749b5b350c10ede815cf9","a78137d9f1bc45ecbbd79b350b61ad9c","08b63e1d541c4874a8a0d293f58acdf7","7ae44ed0d5aa44468c5902d805bd3a66","e69e73be4b6b493a87c73310a39c4861","d80cf0cdb54a423584a8e5438812b8e8","885c4eb4f7ca4ad2bc48475063616e2d","24a960467f424a529942e477d928828a","61bf2c49a6494d909db2fa2bdfe03038","089fbe188f4a4fb59f4694e3d8a4fe23","0ba4e6e4d2754c97bd406620ea3a1d19","30b5ed00629b4e6aabaaa2f4e33ec5e4","ec8dbf03b8194a83bff2ea1ac150767f","b59dfbc709e542fea59b3ca622bdf9d4","90733f00216e4787992f2b032b0c7985","95bd9ca28a0e4fbc8d16307bd0105008","a2b06ba26cef46c5b85fb3f6b5a7644f","2cef2c8ae22a4428925290023db03aea","b29ff8612c65471d95d1ff7391d39ae4","ef47772530464533a917a00c1c06b810","3197eeeff96048a6a27ae0665e283912","003089f3950a474b9e5213ab467c2e34","5cbf10dc8270493daddec74a325776ea","27afe2f29a1c4489ba82d2c78f115f5a","6303c37b4827432d93f78184a5c3e110","664bc47886cc41748c9ceb080064106f","9778458d44e141278fa30b3b83f23596","92126911133f49b6a72fa70e645a1bcd","dabf89cd18d44aee8834fc842e9f3313","c2f79e026ce04f77af29b5e612bfe920","886dcf01f9014f4f96c22a31f78b1473","90c2f0ae1afe473eba56f493570481d4","8b74421f84c4479cae25b97ceea2b362","100ef594c4ae48d2bf18017801e33fd7","eb1f9ae258af4f8a88c784c74635df25","c2319f6b4ecf405a830f208ace55b5b9","74c48ba2190048fcb398665a34400a71","40f935c95c254071bd118d13b8ed6966","c0803825d69e4b8d9841a5fe152cebdd","a5810da4819044df8470ce1299b04917","7ce9ee7e7e6e42b7a610dd19c292b7ff","94a42d29906249378c0c02cc0610c312","fe411d1d87a8443691978b44c2d8f7a8","8b1c2e94b31247809b8077e1d2205ed9","f4862d0f0e784a1ca319472413bda64c","fa5c2ebec03042f1ad6d5a930ae31f51","703fa7d8fdfa45bcbb35424847cee255","0150a5c77daa48808906626686c13b19","5215eae3de1c47a99944a49403962905","f805983c7abf4ffb97773ea9f16cb1c9","0808666704784676811c3d65ffe36d80","29d5f93b19b14d78b7f555a68988b18c"]},"id":"RfyuLQCmPgw2","executionInfo":{"status":"ok","timestamp":1732721459946,"user_tz":360,"elapsed":59903,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"4b3f58d7-6f8c-47e5-8047-35a17825a075"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5eff0c0f2394d5fa500049c4fc85060"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"777fcf690dcc4f1d97e999d9556f6028"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51866096df0b4ddb9dc240405baad580"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b675bb2d19a54357b44f38f942a80275"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1952fe0c24fb4ec1aad57b0dcdfeda02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4239608ef5d44380b531412449296664"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0de9968509cb4b6e8b73a3bf95b15229"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["train-00000-of-00001.parquet:   0%|          | 0.00/70.0M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec3f77678fb942b1a60255ec15b3459a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["test-00000-of-00001.parquet:   0%|          | 0.00/477k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4247d0d404f4ac9bcf6133239229681"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["validation-00000-of-00001.parquet:   0%|          | 0.00/239k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e0ed24092144c96b12888c5937d8ab4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f632e34fe2894fda85f56097e606f10e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5da183acd4a41f69030ad29d042ae4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f65dd0c562c44fdb78358bc81da46ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/392702 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f95d4e24b5ff4ce58363c2bfdd382f0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5010 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"508badfb278f4fb8a1dff5eaa39e2404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2490 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab8e3451963c4885ba6b12c45d22181e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/392702 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c12a23dce3945ddb95894a2d072f181"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5010 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"692aa2fee9424b1ea12739401fb72678"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2490 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61bf2c49a6494d909db2fa2bdfe03038"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Saving the dataset (0/1 shards):   0%|          | 0/785404 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef47772530464533a917a00c1c06b810"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Saving the dataset (0/1 shards):   0%|          | 0/4980 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"886dcf01f9014f4f96c22a31f78b1473"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Saving the dataset (0/1 shards):   0%|          | 0/10020 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94a42d29906249378c0c02cc0610c312"}},"metadata":{}}]},{"cell_type":"code","source":["from datasets import load_from_disk\n","import matplotlib.pyplot as plt\n","\n","train_dataset = load_from_disk(\"xnli_train_en_ru\")\n","labels = train_dataset['label']\n","\n","from collections import Counter\n","label_counts = Counter(labels)\n","\n","label_map = {\n","    0: 'Entailment',\n","    1: 'Neutral',\n","    2: 'Contradiction'\n","}\n","\n","for label_id, count in label_counts.items():\n","    print(f\"Label {label_id} ({label_map[label_id]}): {count} examples\")\n","\n","plt.bar(\n","    [label_map[label_id] for label_id in label_counts.keys()],\n","    label_counts.values()\n",")\n","plt.title(\"Class Distribution in Training Data\")\n","plt.xlabel(\"Class\")\n","plt.ylabel(\"Number of Examples\")\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":526},"id":"8p7_ZVdWo9vY","executionInfo":{"status":"ok","timestamp":1732627509645,"user_tz":360,"elapsed":4627,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"e24ae3b3-31e2-4f8b-dea5-7a28658db518"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Label 1 (Neutral): 261800 examples\n","Label 0 (Entailment): 261798 examples\n","Label 2 (Contradiction): 261806 examples\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["def prepare_dataset_nli(examples, tokenizer, max_seq_length=None):\n","    max_seq_length = tokenizer.model_max_length if max_seq_length is None else max_seq_length\n","\n","    tokenized_examples = tokenizer(\n","        examples['premise'],\n","        examples['hypothesis'],\n","        truncation=True,\n","        max_length=max_seq_length,\n","        padding='max_length'\n","    )\n","\n","    tokenized_examples['label'] = examples['label']\n","    return tokenized_examples\n"],"metadata":{"id":"Kgaw0huApVVn","executionInfo":{"status":"ok","timestamp":1732627564468,"user_tz":360,"elapsed":52,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from datasets import load_from_disk\n","from helpers import prepare_dataset_nli\n","from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased', use_fast=True)\n","\n","eval_dataset = load_from_disk(\"xnli_validation_en_ru\")\n","eval_dataset_featurized = eval_dataset.map(\n","    lambda exs: prepare_dataset_nli(exs, tokenizer, max_seq_length=128),\n","    batched=True,\n","    remove_columns=eval_dataset.column_names\n",")\n","\n","eval_dataset_en = eval_dataset.filter(lambda x: x['language'] == 'en')\n","eval_dataset_ru = eval_dataset.filter(lambda x: x['language'] == 'ru')\n","\n","test_dataset = load_from_disk(\"xnli_test_en_ru\")\n","test_dataset_featurized = test_dataset.map(\n","    lambda exs: prepare_dataset_nli(exs, tokenizer, max_seq_length=128),\n","    batched=True,\n","    remove_columns=test_dataset.column_names\n",")\n","\n","test_dataset_en = test_dataset.filter(lambda x: x['language'] == 'en')\n","test_dataset_ru = test_dataset.filter(lambda x: x['language'] == 'ru')\n"],"metadata":{"id":"JqfsrCqvklWr","executionInfo":{"status":"ok","timestamp":1732721674880,"user_tz":360,"elapsed":875,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["test_dataset_en_featurized = test_dataset_en.map(\n","    lambda exs: prepare_dataset_nli(exs, tokenizer, max_seq_length=128),\n","    batched=True,\n","    remove_columns=test_dataset_en.column_names\n",")\n","\n","test_dataset_ru_featurized = test_dataset_en.map(\n","    lambda exs: prepare_dataset_nli(exs, tokenizer, max_seq_length=128),\n","    batched=True,\n","    remove_columns=test_dataset_ru.column_names\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["96e3bd7048624eb785f530c2b209522a","f7d7b7f0f9074d3cb017cb7381c25cc1","89de870af4c84c53b6713b144eeffcee","f839c098167146c5b7d5ab348c8693b8","2e18a6778ad54301ac0dedf4d93d5543","4705f8a754f44b778a1573d468d417ab","4e4baab2fba04921bca51a88a75e6bbf","86c8563a46ba460094cf80c7668d47f9","c92d51b72eb042a08a9c479d40292eb2","9c5e7d56a3d7404ba6535172bef01267","1d850ff1b3e44c18895bb91d29cf92e9","288f2ccb91fc44fba22c518b1b4b7648","a72f5e1e414e47a69499bb782a995ae4","fc41c29e4d414fb3828cf3ad6bfee33d","e3a09da8c44b4dc38e4ee742495167b4","94e9420192dd4fa4b2dd02037882794a","671b980dc2f64023b00218c4b551cb5e","90fb9183904e40bda75330508dfbd50e","0d05f1fd39e3448781446745203720aa","61b02ef95d1240b69d99fbd1929342c0","0841b58c45e249c4b5849d70793b2b5f","ffc88476302f4264a2f9e13acc86ca67"]},"id":"8cxN1WmnGBJU","executionInfo":{"status":"ok","timestamp":1732721735779,"user_tz":360,"elapsed":1130,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"6404b285-220d-46c1-b41e-2bf3ad8a7c4e"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5010 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96e3bd7048624eb785f530c2b209522a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5010 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"288f2ccb91fc44fba22c518b1b4b7648"}},"metadata":{}}]},{"cell_type":"markdown","source":["Training and Testing on XNLI"],"metadata":{"id":"ZK_VneOza56F"}},{"cell_type":"code","source":["!python3 run.py \\\n","    --model bert-base-multilingual-cased \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_xnli_en_ru_bert_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iDYHH_-q8NjB","executionInfo":{"status":"ok","timestamp":1732770899566,"user_tz":360,"elapsed":4420019,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"313443c4-1cbe-45ef-8e60-50141be5e16d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-27 22:47:36.217727: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-27 22:47:36.234920: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-27 22:47:36.255902: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-27 22:47:36.262268: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-27 22:47:36.277334: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-27 22:47:37.341323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241127_224740-95n3tfjo\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbert-multilingual-cased\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/95n3tfjo\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","/content/drive/MyDrive/nlp_final_project/run.py:233: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.7233, 'grad_norm': 21.286230087280273, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 49088/245440 [1:17:06<5:37:13,  9.70it/s]\n","  0% 0/623 [00:00<?, ?it/s]\u001b[A\n","  1% 7/623 [00:00<00:08, 69.70it/s]\u001b[A\n","  2% 14/623 [00:00<00:09, 63.24it/s]\u001b[A\n","  3% 21/623 [00:00<00:09, 61.45it/s]\u001b[A\n","  4% 28/623 [00:00<00:09, 60.46it/s]\u001b[A\n","  6% 35/623 [00:00<00:09, 59.89it/s]\u001b[A\n","  7% 42/623 [00:00<00:09, 59.80it/s]\u001b[A\n","  8% 48/623 [00:00<00:09, 59.41it/s]\u001b[A\n","  9% 54/623 [00:00<00:09, 59.18it/s]\u001b[A\n"," 10% 60/623 [00:00<00:09, 59.07it/s]\u001b[A\n"," 11% 66/623 [00:01<00:09, 58.99it/s]\u001b[A\n"," 12% 72/623 [00:01<00:09, 58.96it/s]\u001b[A\n"," 13% 78/623 [00:01<00:09, 59.21it/s]\u001b[A\n"," 14% 85/623 [00:01<00:09, 59.50it/s]\u001b[A\n"," 15% 91/623 [00:01<00:08, 59.53it/s]\u001b[A\n"," 16% 98/623 [00:01<00:08, 59.73it/s]\u001b[A\n"," 17% 105/623 [00:01<00:08, 59.87it/s]\u001b[A\n"," 18% 111/623 [00:01<00:08, 59.74it/s]\u001b[A\n"," 19% 117/623 [00:01<00:08, 59.80it/s]\u001b[A\n"," 20% 124/623 [00:02<00:08, 59.88it/s]\u001b[A\n"," 21% 130/623 [00:02<00:08, 59.69it/s]\u001b[A\n"," 22% 137/623 [00:02<00:08, 59.83it/s]\u001b[A\n"," 23% 143/623 [00:02<00:08, 59.77it/s]\u001b[A\n"," 24% 149/623 [00:02<00:07, 59.65it/s]\u001b[A\n"," 25% 155/623 [00:02<00:07, 59.60it/s]\u001b[A\n"," 26% 161/623 [00:02<00:07, 59.59it/s]\u001b[A\n"," 27% 167/623 [00:02<00:07, 59.68it/s]\u001b[A\n"," 28% 173/623 [00:02<00:07, 59.75it/s]\u001b[A\n"," 29% 179/623 [00:02<00:07, 59.73it/s]\u001b[A\n"," 30% 185/623 [00:03<00:07, 59.72it/s]\u001b[A\n"," 31% 191/623 [00:03<00:07, 59.54it/s]\u001b[A\n"," 32% 197/623 [00:03<00:07, 59.48it/s]\u001b[A\n"," 33% 203/623 [00:03<00:07, 59.49it/s]\u001b[A\n"," 34% 209/623 [00:03<00:06, 59.34it/s]\u001b[A\n"," 35% 215/623 [00:03<00:06, 59.30it/s]\u001b[A\n"," 35% 221/623 [00:03<00:06, 59.25it/s]\u001b[A\n"," 36% 227/623 [00:03<00:06, 59.42it/s]\u001b[A\n"," 37% 233/623 [00:03<00:06, 59.49it/s]\u001b[A\n"," 38% 239/623 [00:04<00:06, 59.53it/s]\u001b[A\n"," 39% 245/623 [00:04<00:06, 59.63it/s]\u001b[A\n"," 40% 251/623 [00:04<00:06, 59.65it/s]\u001b[A\n"," 41% 257/623 [00:04<00:06, 59.65it/s]\u001b[A\n"," 42% 263/623 [00:04<00:06, 59.38it/s]\u001b[A\n"," 43% 269/623 [00:04<00:05, 59.24it/s]\u001b[A\n"," 44% 275/623 [00:04<00:05, 59.19it/s]\u001b[A\n"," 45% 281/623 [00:04<00:05, 59.10it/s]\u001b[A\n"," 46% 287/623 [00:04<00:05, 59.20it/s]\u001b[A\n"," 47% 293/623 [00:04<00:05, 59.33it/s]\u001b[A\n"," 48% 299/623 [00:05<00:05, 59.37it/s]\u001b[A\n"," 49% 305/623 [00:05<00:05, 59.35it/s]\u001b[A\n"," 50% 311/623 [00:05<00:05, 59.36it/s]\u001b[A\n"," 51% 317/623 [00:05<00:05, 59.47it/s]\u001b[A\n"," 52% 324/623 [00:05<00:05, 59.68it/s]\u001b[A\n"," 53% 330/623 [00:05<00:04, 59.77it/s]\u001b[A\n"," 54% 336/623 [00:05<00:04, 59.70it/s]\u001b[A\n"," 55% 343/623 [00:05<00:04, 59.87it/s]\u001b[A\n"," 56% 350/623 [00:05<00:04, 59.95it/s]\u001b[A\n"," 57% 356/623 [00:05<00:04, 59.94it/s]\u001b[A\n"," 58% 362/623 [00:06<00:04, 59.90it/s]\u001b[A\n"," 59% 368/623 [00:06<00:04, 59.69it/s]\u001b[A\n"," 60% 374/623 [00:06<00:04, 59.66it/s]\u001b[A\n"," 61% 381/623 [00:06<00:04, 59.81it/s]\u001b[A\n"," 62% 387/623 [00:06<00:03, 59.87it/s]\u001b[A\n"," 63% 394/623 [00:06<00:03, 59.97it/s]\u001b[A\n"," 64% 401/623 [00:06<00:03, 60.05it/s]\u001b[A\n"," 65% 408/623 [00:06<00:03, 60.09it/s]\u001b[A\n"," 67% 415/623 [00:06<00:03, 60.18it/s]\u001b[A\n"," 68% 422/623 [00:07<00:03, 60.22it/s]\u001b[A\n"," 69% 429/623 [00:07<00:03, 60.02it/s]\u001b[A\n"," 70% 436/623 [00:07<00:03, 59.83it/s]\u001b[A\n"," 71% 442/623 [00:07<00:03, 59.62it/s]\u001b[A\n"," 72% 448/623 [00:07<00:02, 59.60it/s]\u001b[A\n"," 73% 454/623 [00:07<00:02, 59.66it/s]\u001b[A\n"," 74% 461/623 [00:07<00:02, 59.80it/s]\u001b[A\n"," 75% 467/623 [00:07<00:02, 59.83it/s]\u001b[A\n"," 76% 473/623 [00:07<00:02, 59.79it/s]\u001b[A\n"," 77% 479/623 [00:08<00:02, 59.60it/s]\u001b[A\n"," 78% 485/623 [00:08<00:02, 59.61it/s]\u001b[A\n"," 79% 491/623 [00:08<00:02, 59.67it/s]\u001b[A\n"," 80% 497/623 [00:08<00:02, 59.61it/s]\u001b[A\n"," 81% 503/623 [00:08<00:02, 59.67it/s]\u001b[A\n"," 82% 509/623 [00:08<00:01, 59.71it/s]\u001b[A\n"," 83% 515/623 [00:08<00:01, 59.67it/s]\u001b[A\n"," 84% 521/623 [00:08<00:01, 59.66it/s]\u001b[A\n"," 85% 527/623 [00:08<00:01, 59.57it/s]\u001b[A\n"," 86% 533/623 [00:08<00:01, 59.48it/s]\u001b[A\n"," 87% 539/623 [00:09<00:01, 59.55it/s]\u001b[A\n"," 87% 545/623 [00:09<00:01, 59.41it/s]\u001b[A\n"," 88% 551/623 [00:09<00:01, 59.16it/s]\u001b[A\n"," 89% 557/623 [00:09<00:01, 58.98it/s]\u001b[A\n"," 90% 563/623 [00:09<00:01, 59.25it/s]\u001b[A\n"," 91% 569/623 [00:09<00:00, 59.29it/s]\u001b[A\n"," 92% 575/623 [00:09<00:00, 59.32it/s]\u001b[A\n"," 93% 581/623 [00:09<00:00, 59.20it/s]\u001b[A\n"," 94% 587/623 [00:09<00:00, 59.02it/s]\u001b[A\n"," 95% 593/623 [00:09<00:00, 59.05it/s]\u001b[A\n"," 96% 599/623 [00:10<00:00, 59.27it/s]\u001b[A\n"," 97% 605/623 [00:10<00:00, 59.48it/s]\u001b[A\n"," 98% 611/623 [00:10<00:00, 59.54it/s]\u001b[A\n","                                              \n","\u001b[A{'eval_loss': 0.6482426524162292, 'eval_accuracy': 0.7359437751004017, 'eval_precision': 0.7402026149283661, 'eval_recall': 0.7359437751004017, 'eval_f1': 0.7368390608776211, 'eval_runtime': 10.4738, 'eval_samples_per_second': 475.472, 'eval_steps_per_second': 59.482, 'epoch': 1.0}\n"," 20% 49088/245440 [1:17:17<5:37:13,  9.70it/s]\n","100% 623/623 [00:10<00:00, 59.58it/s]\u001b[A\n","{'loss': 0.6061, 'grad_norm': 13.918755531311035, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 98176/245440 [2:34:27<4:14:06,  9.66it/s]\n","  0% 0/623 [00:00<?, ?it/s]\u001b[A\n","  1% 7/623 [00:00<00:09, 67.66it/s]\u001b[A\n","  2% 14/623 [00:00<00:09, 62.03it/s]\u001b[A\n","  3% 21/623 [00:00<00:09, 60.30it/s]\u001b[A\n","  4% 28/623 [00:00<00:09, 59.68it/s]\u001b[A\n","  5% 34/623 [00:00<00:09, 59.73it/s]\u001b[A\n","  6% 40/623 [00:00<00:09, 59.78it/s]\u001b[A\n","  7% 46/623 [00:00<00:09, 59.82it/s]\u001b[A\n","  9% 53/623 [00:00<00:09, 59.93it/s]\u001b[A\n"," 10% 60/623 [00:00<00:09, 60.00it/s]\u001b[A\n"," 11% 67/623 [00:01<00:09, 60.09it/s]\u001b[A\n"," 12% 74/623 [00:01<00:09, 60.07it/s]\u001b[A\n"," 13% 81/623 [00:01<00:09, 60.07it/s]\u001b[A\n"," 14% 88/623 [00:01<00:08, 59.63it/s]\u001b[A\n"," 15% 94/623 [00:01<00:08, 59.64it/s]\u001b[A\n"," 16% 100/623 [00:01<00:08, 59.22it/s]\u001b[A\n"," 17% 106/623 [00:01<00:08, 59.29it/s]\u001b[A\n"," 18% 112/623 [00:01<00:08, 59.47it/s]\u001b[A\n"," 19% 119/623 [00:01<00:08, 59.73it/s]\u001b[A\n"," 20% 126/623 [00:02<00:08, 59.91it/s]\u001b[A\n"," 21% 133/623 [00:02<00:08, 60.01it/s]\u001b[A\n"," 22% 140/623 [00:02<00:08, 60.10it/s]\u001b[A\n"," 24% 147/623 [00:02<00:07, 60.10it/s]\u001b[A\n"," 25% 154/623 [00:02<00:07, 59.97it/s]\u001b[A\n"," 26% 160/623 [00:02<00:07, 59.71it/s]\u001b[A\n"," 27% 166/623 [00:02<00:07, 59.65it/s]\u001b[A\n"," 28% 172/623 [00:02<00:07, 59.61it/s]\u001b[A\n"," 29% 178/623 [00:02<00:07, 59.71it/s]\u001b[A\n"," 30% 184/623 [00:03<00:07, 59.78it/s]\u001b[A\n"," 30% 190/623 [00:03<00:07, 59.82it/s]\u001b[A\n"," 31% 196/623 [00:03<00:07, 59.71it/s]\u001b[A\n"," 32% 202/623 [00:03<00:07, 59.65it/s]\u001b[A\n"," 33% 208/623 [00:03<00:06, 59.55it/s]\u001b[A\n"," 34% 214/623 [00:03<00:06, 59.48it/s]\u001b[A\n"," 35% 221/623 [00:03<00:06, 59.66it/s]\u001b[A\n"," 36% 227/623 [00:03<00:06, 59.26it/s]\u001b[A\n"," 37% 233/623 [00:03<00:06, 58.97it/s]\u001b[A\n"," 38% 239/623 [00:04<00:06, 58.81it/s]\u001b[A\n"," 39% 245/623 [00:04<00:06, 58.68it/s]\u001b[A\n"," 40% 251/623 [00:04<00:06, 58.62it/s]\u001b[A\n"," 41% 257/623 [00:04<00:06, 58.55it/s]\u001b[A\n"," 42% 263/623 [00:04<00:06, 58.14it/s]\u001b[A\n"," 43% 269/623 [00:04<00:06, 58.43it/s]\u001b[A\n"," 44% 275/623 [00:04<00:05, 58.82it/s]\u001b[A\n"," 45% 281/623 [00:04<00:05, 58.49it/s]\u001b[A\n"," 46% 287/623 [00:04<00:05, 58.30it/s]\u001b[A\n"," 47% 293/623 [00:04<00:05, 58.36it/s]\u001b[A\n"," 48% 299/623 [00:05<00:05, 58.31it/s]\u001b[A\n"," 49% 305/623 [00:05<00:05, 58.22it/s]\u001b[A\n"," 50% 311/623 [00:05<00:05, 58.09it/s]\u001b[A\n"," 51% 317/623 [00:05<00:05, 58.14it/s]\u001b[A\n"," 52% 323/623 [00:05<00:05, 57.65it/s]\u001b[A\n"," 53% 329/623 [00:05<00:05, 58.21it/s]\u001b[A\n"," 54% 336/623 [00:05<00:04, 58.74it/s]\u001b[A\n"," 55% 342/623 [00:05<00:04, 58.99it/s]\u001b[A\n"," 56% 348/623 [00:05<00:04, 59.25it/s]\u001b[A\n"," 57% 355/623 [00:05<00:04, 59.57it/s]\u001b[A\n"," 58% 361/623 [00:06<00:04, 59.66it/s]\u001b[A\n"," 59% 367/623 [00:06<00:04, 59.70it/s]\u001b[A\n"," 60% 374/623 [00:06<00:04, 59.82it/s]\u001b[A\n"," 61% 380/623 [00:06<00:04, 59.84it/s]\u001b[A\n"," 62% 386/623 [00:06<00:03, 59.82it/s]\u001b[A\n"," 63% 392/623 [00:06<00:03, 59.79it/s]\u001b[A\n"," 64% 398/623 [00:06<00:03, 59.83it/s]\u001b[A\n"," 65% 404/623 [00:06<00:03, 59.81it/s]\u001b[A\n"," 66% 410/623 [00:06<00:03, 59.64it/s]\u001b[A\n"," 67% 416/623 [00:06<00:03, 59.73it/s]\u001b[A\n"," 68% 423/623 [00:07<00:03, 59.89it/s]\u001b[A\n"," 69% 430/623 [00:07<00:03, 59.93it/s]\u001b[A\n"," 70% 436/623 [00:07<00:03, 59.72it/s]\u001b[A\n"," 71% 442/623 [00:07<00:03, 59.61it/s]\u001b[A\n"," 72% 448/623 [00:07<00:02, 59.62it/s]\u001b[A\n"," 73% 454/623 [00:07<00:02, 59.71it/s]\u001b[A\n"," 74% 460/623 [00:07<00:02, 59.45it/s]\u001b[A\n"," 75% 466/623 [00:07<00:02, 59.36it/s]\u001b[A\n"," 76% 472/623 [00:07<00:02, 59.30it/s]\u001b[A\n"," 77% 478/623 [00:08<00:02, 59.30it/s]\u001b[A\n"," 78% 484/623 [00:08<00:02, 59.47it/s]\u001b[A\n"," 79% 490/623 [00:08<00:02, 59.61it/s]\u001b[A\n"," 80% 496/623 [00:08<00:02, 59.61it/s]\u001b[A\n"," 81% 502/623 [00:08<00:02, 59.63it/s]\u001b[A\n"," 82% 508/623 [00:08<00:01, 59.63it/s]\u001b[A\n"," 83% 515/623 [00:08<00:01, 59.72it/s]\u001b[A\n"," 84% 521/623 [00:08<00:01, 59.30it/s]\u001b[A\n"," 85% 527/623 [00:08<00:01, 59.26it/s]\u001b[A\n"," 86% 533/623 [00:08<00:01, 59.10it/s]\u001b[A\n"," 87% 539/623 [00:09<00:01, 59.27it/s]\u001b[A\n"," 88% 546/623 [00:09<00:01, 59.56it/s]\u001b[A\n"," 89% 552/623 [00:09<00:01, 59.57it/s]\u001b[A\n"," 90% 558/623 [00:09<00:01, 59.48it/s]\u001b[A\n"," 91% 564/623 [00:09<00:00, 59.60it/s]\u001b[A\n"," 92% 571/623 [00:09<00:00, 59.77it/s]\u001b[A\n"," 93% 577/623 [00:09<00:00, 59.83it/s]\u001b[A\n"," 94% 584/623 [00:09<00:00, 59.91it/s]\u001b[A\n"," 95% 590/623 [00:09<00:00, 59.74it/s]\u001b[A\n"," 96% 596/623 [00:10<00:00, 59.71it/s]\u001b[A\n"," 97% 602/623 [00:10<00:00, 59.77it/s]\u001b[A\n"," 98% 609/623 [00:10<00:00, 59.87it/s]\u001b[A\n"," 99% 615/623 [00:10<00:00, 59.74it/s]\u001b[A\n","                                              \n","\u001b[A{'eval_loss': 0.6250696182250977, 'eval_accuracy': 0.7463855421686747, 'eval_precision': 0.7555137730127041, 'eval_recall': 0.7463855421686747, 'eval_f1': 0.7474124591960262, 'eval_runtime': 10.495, 'eval_samples_per_second': 474.511, 'eval_steps_per_second': 59.361, 'epoch': 2.0}\n"," 40% 98176/245440 [2:34:37<4:14:06,  9.66it/s]\n","100% 623/623 [00:10<00:00, 59.64it/s]\u001b[A\n","{'loss': 0.5133, 'grad_norm': 7.035335540771484, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 147264/245440 [3:51:51<2:44:28,  9.95it/s]\n","  0% 0/623 [00:00<?, ?it/s]\u001b[A\n","  1% 7/623 [00:00<00:09, 67.00it/s]\u001b[A\n","  2% 14/623 [00:00<00:09, 61.08it/s]\u001b[A\n","  3% 21/623 [00:00<00:10, 59.39it/s]\u001b[A\n","  4% 27/623 [00:00<00:10, 58.85it/s]\u001b[A\n","  5% 33/623 [00:00<00:10, 58.55it/s]\u001b[A\n","  6% 39/623 [00:00<00:10, 57.99it/s]\u001b[A\n","  7% 45/623 [00:00<00:09, 58.56it/s]\u001b[A\n","  8% 51/623 [00:00<00:09, 58.72it/s]\u001b[A\n","  9% 57/623 [00:00<00:09, 58.97it/s]\u001b[A\n"," 10% 63/623 [00:01<00:09, 59.12it/s]\u001b[A\n"," 11% 69/623 [00:01<00:09, 59.20it/s]\u001b[A\n"," 12% 75/623 [00:01<00:09, 59.33it/s]\u001b[A\n"," 13% 81/623 [00:01<00:09, 59.21it/s]\u001b[A\n"," 14% 87/623 [00:01<00:09, 59.40it/s]\u001b[A\n"," 15% 93/623 [00:01<00:08, 59.33it/s]\u001b[A\n"," 16% 99/623 [00:01<00:08, 59.08it/s]\u001b[A\n"," 17% 105/623 [00:01<00:08, 59.23it/s]\u001b[A\n"," 18% 111/623 [00:01<00:08, 59.13it/s]\u001b[A\n"," 19% 117/623 [00:01<00:08, 59.36it/s]\u001b[A\n"," 20% 123/623 [00:02<00:08, 59.25it/s]\u001b[A\n"," 21% 129/623 [00:02<00:08, 59.30it/s]\u001b[A\n"," 22% 135/623 [00:02<00:08, 59.44it/s]\u001b[A\n"," 23% 141/623 [00:02<00:08, 59.13it/s]\u001b[A\n"," 24% 147/623 [00:02<00:08, 59.39it/s]\u001b[A\n"," 25% 153/623 [00:02<00:07, 59.14it/s]\u001b[A\n"," 26% 159/623 [00:02<00:07, 59.05it/s]\u001b[A\n"," 26% 165/623 [00:02<00:07, 59.06it/s]\u001b[A\n"," 27% 171/623 [00:02<00:07, 58.56it/s]\u001b[A\n"," 28% 177/623 [00:02<00:07, 58.85it/s]\u001b[A\n"," 29% 183/623 [00:03<00:07, 58.86it/s]\u001b[A\n"," 30% 189/623 [00:03<00:07, 59.05it/s]\u001b[A\n"," 31% 195/623 [00:03<00:07, 59.10it/s]\u001b[A\n"," 32% 201/623 [00:03<00:07, 58.63it/s]\u001b[A\n"," 33% 207/623 [00:03<00:07, 58.60it/s]\u001b[A\n"," 34% 213/623 [00:03<00:06, 58.72it/s]\u001b[A\n"," 35% 219/623 [00:03<00:06, 59.02it/s]\u001b[A\n"," 36% 225/623 [00:03<00:06, 58.95it/s]\u001b[A\n"," 37% 231/623 [00:03<00:06, 59.00it/s]\u001b[A\n"," 38% 237/623 [00:04<00:06, 59.02it/s]\u001b[A\n"," 39% 243/623 [00:04<00:06, 58.98it/s]\u001b[A\n"," 40% 249/623 [00:04<00:06, 59.19it/s]\u001b[A\n"," 41% 255/623 [00:04<00:06, 59.14it/s]\u001b[A\n"," 42% 261/623 [00:04<00:06, 58.90it/s]\u001b[A\n"," 43% 267/623 [00:04<00:06, 58.86it/s]\u001b[A\n"," 44% 273/623 [00:04<00:05, 58.61it/s]\u001b[A\n"," 45% 279/623 [00:04<00:05, 58.81it/s]\u001b[A\n"," 46% 285/623 [00:04<00:05, 58.63it/s]\u001b[A\n"," 47% 291/623 [00:04<00:05, 58.77it/s]\u001b[A\n"," 48% 297/623 [00:05<00:05, 58.79it/s]\u001b[A\n"," 49% 303/623 [00:05<00:05, 58.94it/s]\u001b[A\n"," 50% 309/623 [00:05<00:05, 59.20it/s]\u001b[A\n"," 51% 315/623 [00:05<00:05, 58.94it/s]\u001b[A\n"," 52% 321/623 [00:05<00:05, 59.17it/s]\u001b[A\n"," 52% 327/623 [00:05<00:05, 59.01it/s]\u001b[A\n"," 53% 333/623 [00:05<00:04, 58.67it/s]\u001b[A\n"," 54% 339/623 [00:05<00:04, 58.61it/s]\u001b[A\n"," 55% 345/623 [00:05<00:04, 58.55it/s]\u001b[A\n"," 56% 351/623 [00:05<00:04, 58.60it/s]\u001b[A\n"," 57% 357/623 [00:06<00:04, 58.86it/s]\u001b[A\n"," 58% 363/623 [00:06<00:04, 58.96it/s]\u001b[A\n"," 59% 369/623 [00:06<00:04, 58.88it/s]\u001b[A\n"," 60% 375/623 [00:06<00:04, 58.66it/s]\u001b[A\n"," 61% 381/623 [00:06<00:04, 58.46it/s]\u001b[A\n"," 62% 387/623 [00:06<00:04, 58.71it/s]\u001b[A\n"," 63% 393/623 [00:06<00:03, 58.77it/s]\u001b[A\n"," 64% 399/623 [00:06<00:03, 58.57it/s]\u001b[A\n"," 65% 405/623 [00:06<00:03, 58.72it/s]\u001b[A\n"," 66% 411/623 [00:06<00:03, 58.67it/s]\u001b[A\n"," 67% 418/623 [00:07<00:03, 59.13it/s]\u001b[A\n"," 68% 424/623 [00:07<00:03, 58.90it/s]\u001b[A\n"," 69% 430/623 [00:07<00:03, 59.05it/s]\u001b[A\n"," 70% 436/623 [00:07<00:03, 58.84it/s]\u001b[A\n"," 71% 442/623 [00:07<00:03, 58.16it/s]\u001b[A\n"," 72% 448/623 [00:07<00:03, 57.93it/s]\u001b[A\n"," 73% 454/623 [00:07<00:02, 57.73it/s]\u001b[A\n"," 74% 460/623 [00:07<00:02, 57.80it/s]\u001b[A\n"," 75% 466/623 [00:07<00:02, 57.41it/s]\u001b[A\n"," 76% 472/623 [00:08<00:02, 57.58it/s]\u001b[A\n"," 77% 478/623 [00:08<00:02, 57.76it/s]\u001b[A\n"," 78% 484/623 [00:08<00:02, 57.64it/s]\u001b[A\n"," 79% 490/623 [00:08<00:02, 57.52it/s]\u001b[A\n"," 80% 496/623 [00:08<00:02, 57.34it/s]\u001b[A\n"," 81% 502/623 [00:08<00:02, 57.70it/s]\u001b[A\n"," 82% 508/623 [00:08<00:01, 57.64it/s]\u001b[A\n"," 83% 514/623 [00:08<00:01, 57.58it/s]\u001b[A\n"," 83% 520/623 [00:08<00:01, 58.08it/s]\u001b[A\n"," 84% 526/623 [00:08<00:01, 57.83it/s]\u001b[A\n"," 85% 532/623 [00:09<00:01, 57.76it/s]\u001b[A\n"," 86% 538/623 [00:09<00:01, 57.41it/s]\u001b[A\n"," 87% 544/623 [00:09<00:01, 57.35it/s]\u001b[A\n"," 88% 550/623 [00:09<00:01, 56.81it/s]\u001b[A\n"," 89% 556/623 [00:09<00:01, 56.48it/s]\u001b[A\n"," 90% 562/623 [00:09<00:01, 56.88it/s]\u001b[A\n"," 91% 568/623 [00:09<00:00, 56.83it/s]\u001b[A\n"," 92% 574/623 [00:09<00:00, 56.85it/s]\u001b[A\n"," 93% 580/623 [00:09<00:00, 57.04it/s]\u001b[A\n"," 94% 586/623 [00:10<00:00, 57.31it/s]\u001b[A\n"," 95% 592/623 [00:10<00:00, 57.31it/s]\u001b[A\n"," 96% 598/623 [00:10<00:00, 57.40it/s]\u001b[A\n"," 97% 604/623 [00:10<00:00, 57.51it/s]\u001b[A\n"," 98% 610/623 [00:10<00:00, 57.41it/s]\u001b[A\n"," 99% 616/623 [00:10<00:00, 57.66it/s]\u001b[A\n","                                               \n","\u001b[A{'eval_loss': 0.6192278265953064, 'eval_accuracy': 0.7526104417670683, 'eval_precision': 0.7587320592767952, 'eval_recall': 0.7526104417670683, 'eval_f1': 0.7532090002334877, 'eval_runtime': 10.6759, 'eval_samples_per_second': 466.47, 'eval_steps_per_second': 58.356, 'epoch': 3.0}\n"," 60% 147264/245440 [3:52:02<2:44:28,  9.95it/s]\n","100% 623/623 [00:10<00:00, 57.73it/s]\u001b[A\n","{'loss': 0.4105, 'grad_norm': 5.4885077476501465, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 196352/245440 [5:09:09<1:21:56,  9.98it/s]\n","  0% 0/623 [00:00<?, ?it/s]\u001b[A\n","  1% 7/623 [00:00<00:09, 68.09it/s]\u001b[A\n","  2% 14/623 [00:00<00:09, 62.35it/s]\u001b[A\n","  3% 21/623 [00:00<00:09, 60.84it/s]\u001b[A\n","  4% 28/623 [00:00<00:09, 60.08it/s]\u001b[A\n","  6% 35/623 [00:00<00:09, 60.05it/s]\u001b[A\n","  7% 42/623 [00:00<00:09, 59.75it/s]\u001b[A\n","  8% 48/623 [00:00<00:09, 59.43it/s]\u001b[A\n","  9% 54/623 [00:00<00:09, 59.21it/s]\u001b[A\n"," 10% 60/623 [00:01<00:09, 58.99it/s]\u001b[A\n"," 11% 66/623 [00:01<00:09, 58.82it/s]\u001b[A\n"," 12% 72/623 [00:01<00:09, 58.71it/s]\u001b[A\n"," 13% 78/623 [00:01<00:09, 58.82it/s]\u001b[A\n"," 13% 84/623 [00:01<00:09, 58.86it/s]\u001b[A\n"," 14% 90/623 [00:01<00:09, 58.79it/s]\u001b[A\n"," 15% 96/623 [00:01<00:08, 58.63it/s]\u001b[A\n"," 16% 102/623 [00:01<00:08, 58.76it/s]\u001b[A\n"," 17% 108/623 [00:01<00:08, 58.78it/s]\u001b[A\n"," 18% 114/623 [00:01<00:08, 58.61it/s]\u001b[A\n"," 19% 120/623 [00:02<00:08, 58.19it/s]\u001b[A\n"," 20% 126/623 [00:02<00:08, 58.28it/s]\u001b[A\n"," 21% 132/623 [00:02<00:08, 58.49it/s]\u001b[A\n"," 22% 138/623 [00:02<00:08, 58.59it/s]\u001b[A\n"," 23% 144/623 [00:02<00:08, 58.71it/s]\u001b[A\n"," 24% 150/623 [00:02<00:08, 58.81it/s]\u001b[A\n"," 25% 156/623 [00:02<00:07, 58.54it/s]\u001b[A\n"," 26% 162/623 [00:02<00:07, 58.72it/s]\u001b[A\n"," 27% 168/623 [00:02<00:07, 58.75it/s]\u001b[A\n"," 28% 174/623 [00:02<00:07, 58.63it/s]\u001b[A\n"," 29% 180/623 [00:03<00:07, 58.62it/s]\u001b[A\n"," 30% 186/623 [00:03<00:07, 58.17it/s]\u001b[A\n"," 31% 192/623 [00:03<00:07, 58.35it/s]\u001b[A\n"," 32% 199/623 [00:03<00:07, 58.95it/s]\u001b[A\n"," 33% 205/623 [00:03<00:07, 59.00it/s]\u001b[A\n"," 34% 211/623 [00:03<00:06, 58.86it/s]\u001b[A\n"," 35% 217/623 [00:03<00:06, 58.86it/s]\u001b[A\n"," 36% 223/623 [00:03<00:06, 58.71it/s]\u001b[A\n"," 37% 229/623 [00:03<00:06, 58.76it/s]\u001b[A\n"," 38% 235/623 [00:03<00:06, 58.44it/s]\u001b[A\n"," 39% 241/623 [00:04<00:06, 58.57it/s]\u001b[A\n"," 40% 247/623 [00:04<00:06, 58.65it/s]\u001b[A\n"," 41% 253/623 [00:04<00:06, 57.96it/s]\u001b[A\n"," 42% 259/623 [00:04<00:06, 57.26it/s]\u001b[A\n"," 43% 265/623 [00:04<00:06, 57.62it/s]\u001b[A\n"," 43% 271/623 [00:04<00:06, 57.81it/s]\u001b[A\n"," 44% 277/623 [00:04<00:05, 58.14it/s]\u001b[A\n"," 45% 283/623 [00:04<00:05, 58.15it/s]\u001b[A\n"," 46% 289/623 [00:04<00:05, 58.30it/s]\u001b[A\n"," 47% 295/623 [00:05<00:05, 58.40it/s]\u001b[A\n"," 48% 301/623 [00:05<00:05, 58.45it/s]\u001b[A\n"," 49% 307/623 [00:05<00:05, 58.29it/s]\u001b[A\n"," 50% 313/623 [00:05<00:05, 57.60it/s]\u001b[A\n"," 51% 319/623 [00:05<00:05, 58.06it/s]\u001b[A\n"," 52% 325/623 [00:05<00:05, 58.27it/s]\u001b[A\n"," 53% 331/623 [00:05<00:04, 58.47it/s]\u001b[A\n"," 54% 337/623 [00:05<00:04, 58.64it/s]\u001b[A\n"," 55% 343/623 [00:05<00:04, 58.71it/s]\u001b[A\n"," 56% 349/623 [00:05<00:04, 58.38it/s]\u001b[A\n"," 57% 355/623 [00:06<00:04, 58.33it/s]\u001b[A\n"," 58% 361/623 [00:06<00:04, 58.60it/s]\u001b[A\n"," 59% 367/623 [00:06<00:04, 58.74it/s]\u001b[A\n"," 60% 373/623 [00:06<00:04, 58.72it/s]\u001b[A\n"," 61% 379/623 [00:06<00:04, 58.95it/s]\u001b[A\n"," 62% 385/623 [00:06<00:04, 58.74it/s]\u001b[A\n"," 63% 391/623 [00:06<00:03, 58.96it/s]\u001b[A\n"," 64% 397/623 [00:06<00:03, 58.97it/s]\u001b[A\n"," 65% 403/623 [00:06<00:03, 58.82it/s]\u001b[A\n"," 66% 409/623 [00:06<00:03, 58.21it/s]\u001b[A\n"," 67% 415/623 [00:07<00:03, 58.32it/s]\u001b[A\n"," 68% 422/623 [00:07<00:03, 58.87it/s]\u001b[A\n"," 69% 429/623 [00:07<00:03, 59.28it/s]\u001b[A\n"," 70% 436/623 [00:07<00:03, 59.62it/s]\u001b[A\n"," 71% 443/623 [00:07<00:03, 59.82it/s]\u001b[A\n"," 72% 449/623 [00:07<00:02, 59.84it/s]\u001b[A\n"," 73% 456/623 [00:07<00:02, 59.95it/s]\u001b[A\n"," 74% 463/623 [00:07<00:02, 60.07it/s]\u001b[A\n"," 75% 470/623 [00:07<00:02, 59.99it/s]\u001b[A\n"," 76% 476/623 [00:08<00:02, 59.98it/s]\u001b[A\n"," 77% 482/623 [00:08<00:02, 59.95it/s]\u001b[A\n"," 78% 489/623 [00:08<00:02, 60.05it/s]\u001b[A\n"," 80% 496/623 [00:08<00:02, 60.09it/s]\u001b[A\n"," 81% 503/623 [00:08<00:01, 60.19it/s]\u001b[A\n"," 82% 510/623 [00:08<00:01, 59.92it/s]\u001b[A\n"," 83% 516/623 [00:08<00:01, 59.67it/s]\u001b[A\n"," 84% 522/623 [00:08<00:01, 59.50it/s]\u001b[A\n"," 85% 528/623 [00:08<00:01, 59.29it/s]\u001b[A\n"," 86% 534/623 [00:09<00:01, 58.83it/s]\u001b[A\n"," 87% 540/623 [00:09<00:01, 58.72it/s]\u001b[A\n"," 88% 546/623 [00:09<00:01, 58.52it/s]\u001b[A\n"," 89% 552/623 [00:09<00:01, 58.68it/s]\u001b[A\n"," 90% 559/623 [00:09<00:01, 59.22it/s]\u001b[A\n"," 91% 566/623 [00:09<00:00, 59.51it/s]\u001b[A\n"," 92% 572/623 [00:09<00:00, 59.57it/s]\u001b[A\n"," 93% 578/623 [00:09<00:00, 59.19it/s]\u001b[A\n"," 94% 584/623 [00:09<00:00, 59.15it/s]\u001b[A\n"," 95% 590/623 [00:10<00:00, 58.84it/s]\u001b[A\n"," 96% 596/623 [00:10<00:00, 58.97it/s]\u001b[A\n"," 97% 602/623 [00:10<00:00, 59.17it/s]\u001b[A\n"," 98% 608/623 [00:10<00:00, 59.19it/s]\u001b[A\n"," 99% 615/623 [00:10<00:00, 59.49it/s]\u001b[A\n","                                               \n","\u001b[A{'eval_loss': 0.6621495485305786, 'eval_accuracy': 0.7562248995983936, 'eval_precision': 0.7701711412487691, 'eval_recall': 0.7562248995983936, 'eval_f1': 0.7570879675844214, 'eval_runtime': 10.5832, 'eval_samples_per_second': 470.557, 'eval_steps_per_second': 58.867, 'epoch': 4.0}\n"," 80% 196352/245440 [5:09:20<1:21:56,  9.98it/s]\n","100% 623/623 [00:10<00:00, 59.54it/s]\u001b[A\n","{'loss': 0.3043, 'grad_norm': 26.672821044921875, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 245440/245440 [6:26:25<00:00, 10.11it/s]\n","  0% 0/623 [00:00<?, ?it/s]\u001b[A\n","  1% 6/623 [00:00<00:10, 58.71it/s]\u001b[A\n","  2% 12/623 [00:00<00:11, 52.57it/s]\u001b[A\n","  3% 18/623 [00:00<00:11, 54.43it/s]\u001b[A\n","  4% 24/623 [00:00<00:10, 56.40it/s]\u001b[A\n","  5% 30/623 [00:00<00:10, 57.41it/s]\u001b[A\n","  6% 36/623 [00:00<00:10, 57.96it/s]\u001b[A\n","  7% 43/623 [00:00<00:09, 58.75it/s]\u001b[A\n","  8% 50/623 [00:00<00:09, 59.21it/s]\u001b[A\n","  9% 57/623 [00:00<00:09, 59.52it/s]\u001b[A\n"," 10% 64/623 [00:01<00:09, 59.61it/s]\u001b[A\n"," 11% 70/623 [00:01<00:09, 59.34it/s]\u001b[A\n"," 12% 76/623 [00:01<00:09, 59.34it/s]\u001b[A\n"," 13% 82/623 [00:01<00:09, 59.41it/s]\u001b[A\n"," 14% 89/623 [00:01<00:08, 59.67it/s]\u001b[A\n"," 15% 96/623 [00:01<00:08, 59.86it/s]\u001b[A\n"," 17% 103/623 [00:01<00:08, 60.01it/s]\u001b[A\n"," 18% 110/623 [00:01<00:08, 60.08it/s]\u001b[A\n"," 19% 117/623 [00:01<00:08, 60.03it/s]\u001b[A\n"," 20% 124/623 [00:02<00:08, 60.05it/s]\u001b[A\n"," 21% 131/623 [00:02<00:08, 59.88it/s]\u001b[A\n"," 22% 137/623 [00:02<00:08, 59.32it/s]\u001b[A\n"," 23% 143/623 [00:02<00:08, 59.35it/s]\u001b[A\n"," 24% 149/623 [00:02<00:07, 59.48it/s]\u001b[A\n"," 25% 155/623 [00:02<00:07, 59.57it/s]\u001b[A\n"," 26% 161/623 [00:02<00:07, 59.54it/s]\u001b[A\n"," 27% 167/623 [00:02<00:07, 59.58it/s]\u001b[A\n"," 28% 174/623 [00:02<00:07, 59.79it/s]\u001b[A\n"," 29% 181/623 [00:03<00:07, 59.89it/s]\u001b[A\n"," 30% 187/623 [00:03<00:07, 59.78it/s]\u001b[A\n"," 31% 193/623 [00:03<00:07, 59.75it/s]\u001b[A\n"," 32% 199/623 [00:03<00:07, 59.61it/s]\u001b[A\n"," 33% 205/623 [00:03<00:07, 59.41it/s]\u001b[A\n"," 34% 211/623 [00:03<00:06, 59.58it/s]\u001b[A\n"," 35% 218/623 [00:03<00:06, 59.80it/s]\u001b[A\n"," 36% 224/623 [00:03<00:06, 59.76it/s]\u001b[A\n"," 37% 230/623 [00:03<00:06, 59.79it/s]\u001b[A\n"," 38% 236/623 [00:03<00:06, 59.81it/s]\u001b[A\n"," 39% 243/623 [00:04<00:06, 59.92it/s]\u001b[A\n"," 40% 249/623 [00:04<00:06, 59.68it/s]\u001b[A\n"," 41% 256/623 [00:04<00:06, 59.84it/s]\u001b[A\n"," 42% 262/623 [00:04<00:06, 59.87it/s]\u001b[A\n"," 43% 269/623 [00:04<00:05, 59.96it/s]\u001b[A\n"," 44% 276/623 [00:04<00:05, 60.04it/s]\u001b[A\n"," 45% 283/623 [00:04<00:05, 60.16it/s]\u001b[A\n"," 47% 290/623 [00:04<00:05, 60.21it/s]\u001b[A\n"," 48% 297/623 [00:04<00:05, 60.25it/s]\u001b[A\n"," 49% 304/623 [00:05<00:05, 60.20it/s]\u001b[A\n"," 50% 311/623 [00:05<00:05, 60.11it/s]\u001b[A\n"," 51% 318/623 [00:05<00:05, 60.17it/s]\u001b[A\n"," 52% 325/623 [00:05<00:04, 60.16it/s]\u001b[A\n"," 53% 332/623 [00:05<00:04, 60.22it/s]\u001b[A\n"," 54% 339/623 [00:05<00:04, 60.25it/s]\u001b[A\n"," 56% 346/623 [00:05<00:04, 59.86it/s]\u001b[A\n"," 57% 353/623 [00:05<00:04, 59.94it/s]\u001b[A\n"," 58% 359/623 [00:06<00:04, 59.54it/s]\u001b[A\n","100% 245440/245440 [6:26:31<00:00, 10.11it/s]\n"," 60% 371/623 [00:06<00:04, 59.49it/s]\u001b[A\n"," 61% 377/623 [00:06<00:04, 59.43it/s]\u001b[A\n"," 61% 383/623 [00:06<00:04, 59.20it/s]\u001b[A\n"," 62% 389/623 [00:06<00:03, 59.37it/s]\u001b[A\n"," 64% 396/623 [00:06<00:03, 59.62it/s]\u001b[A\n"," 65% 402/623 [00:06<00:03, 59.30it/s]\u001b[A\n"," 66% 409/623 [00:06<00:03, 59.64it/s]\u001b[A\n"," 67% 416/623 [00:06<00:03, 59.82it/s]\u001b[A\n"," 68% 423/623 [00:07<00:03, 59.98it/s]\u001b[A\n"," 69% 429/623 [00:07<00:03, 59.63it/s]\u001b[A\n"," 70% 435/623 [00:07<00:03, 59.40it/s]\u001b[A\n"," 71% 441/623 [00:07<00:03, 59.34it/s]\u001b[A\n"," 72% 447/623 [00:07<00:02, 59.25it/s]\u001b[A\n"," 73% 453/623 [00:07<00:02, 59.25it/s]\u001b[A\n"," 74% 459/623 [00:07<00:02, 59.06it/s]\u001b[A\n"," 75% 465/623 [00:07<00:02, 58.83it/s]\u001b[A\n"," 76% 471/623 [00:07<00:02, 58.61it/s]\u001b[A\n"," 77% 477/623 [00:08<00:02, 58.49it/s]\u001b[A\n"," 78% 483/623 [00:08<00:02, 58.56it/s]\u001b[A\n"," 78% 489/623 [00:08<00:02, 58.41it/s]\u001b[A\n"," 79% 495/623 [00:08<00:02, 58.47it/s]\u001b[A\n"," 80% 501/623 [00:08<00:02, 58.56it/s]\u001b[A\n"," 81% 507/623 [00:08<00:01, 58.10it/s]\u001b[A\n"," 82% 513/623 [00:08<00:01, 58.20it/s]\u001b[A\n"," 83% 519/623 [00:08<00:01, 57.85it/s]\u001b[A\n"," 84% 525/623 [00:08<00:01, 57.60it/s]\u001b[A\n"," 85% 531/623 [00:08<00:01, 57.65it/s]\u001b[A\n"," 86% 537/623 [00:09<00:01, 57.88it/s]\u001b[A\n"," 87% 543/623 [00:09<00:01, 58.02it/s]\u001b[A\n"," 88% 549/623 [00:09<00:01, 57.75it/s]\u001b[A\n"," 89% 555/623 [00:09<00:01, 57.67it/s]\u001b[A\n"," 90% 561/623 [00:09<00:01, 57.81it/s]\u001b[A\n"," 91% 567/623 [00:09<00:00, 58.41it/s]\u001b[A\n"," 92% 574/623 [00:09<00:00, 58.97it/s]\u001b[A\n"," 93% 580/623 [00:09<00:00, 58.57it/s]\u001b[A\n"," 94% 586/623 [00:09<00:00, 58.03it/s]\u001b[A\n"," 95% 592/623 [00:10<00:00, 58.00it/s]\u001b[A\n"," 96% 598/623 [00:10<00:00, 57.53it/s]\u001b[A\n"," 97% 604/623 [00:10<00:00, 57.53it/s]\u001b[A\n"," 98% 610/623 [00:10<00:00, 58.15it/s]\u001b[A\n"," 99% 616/623 [00:10<00:00, 58.10it/s]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 0.7797014117240906, 'eval_accuracy': 0.7544176706827309, 'eval_precision': 0.7618592041368388, 'eval_recall': 0.7544176706827309, 'eval_f1': 0.7546003895567148, 'eval_runtime': 10.5692, 'eval_samples_per_second': 471.18, 'eval_steps_per_second': 58.945, 'epoch': 5.0}\n","100% 245440/245440 [6:26:36<00:00, 10.11it/s]\n","100% 623/623 [00:10<00:00, 57.38it/s]\u001b[A\n","{'train_runtime': 23205.4039, 'train_samples_per_second': 169.229, 'train_steps_per_second': 10.577, 'train_loss': 0.5114914278629706, 'epoch': 5.0}\n","100% 245440/245440 [6:26:45<00:00, 10.58it/s]\n","100% 623/623 [00:10<00:00, 58.94it/s]\n","Evaluation results:\n","{'eval_loss': 0.7797014117240906, 'eval_accuracy': 0.7544176706827309, 'eval_precision': 0.7618592041368388, 'eval_recall': 0.7544176706827309, 'eval_f1': 0.7546003895567148, 'eval_runtime': 10.5895, 'eval_samples_per_second': 470.277, 'eval_steps_per_second': 58.832, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mbert-multilingual-cased\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/95n3tfjo\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241127_224740-95n3tfjo/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFpmGPg1vulV","executionInfo":{"status":"ok","timestamp":1732991864623,"user_tz":360,"elapsed":3459602,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"146a785e-d6ff-4bae-9397-73d5aa837813"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-30 17:40:18.114911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-30 17:40:18.130988: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-30 17:40:18.135610: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-30 17:40:18.147321: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-30 17:40:19.503828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","README.md: 100% 20.8k/20.8k [00:00<00:00, 57.9MB/s]\n","train-00000-of-00001.parquet: 100% 50.2M/50.2M [00:00<00:00, 164MB/s]\n","test-00000-of-00001.parquet: 100% 308k/308k [00:00<00:00, 352MB/s]\n","validation-00000-of-00001.parquet: 100% 157k/157k [00:00<00:00, 260MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 697410.60 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 546087.92 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 480021.00 examples/s]\n","train-00000-of-00001.parquet: 100% 70.0M/70.0M [00:00<00:00, 246MB/s]\n","test-00000-of-00001.parquet: 100% 477k/477k [00:00<00:00, 406MB/s]\n","validation-00000-of-00001.parquet: 100% 239k/239k [00:00<00:00, 201MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 561230.10 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 490590.50 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 423049.26 examples/s]\n","Map: 100% 392702/392702 [00:14<00:00, 27155.45 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 30551.79 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 30055.71 examples/s]\n","Map: 100% 392702/392702 [00:14<00:00, 27774.74 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 33069.88 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 32848.18 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:02<00:00, 3716.72 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:233: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7811.55 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7918.83 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [09:23<00:00,  1.44it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [09:23<00:00,  1.11it/s]\n","{'eval_loss': 0.5767554044723511, 'eval_model_preparation_time': 0.0045, 'eval_accuracy': 0.7934131736526946, 'eval_precision': 0.8029884484897186, 'eval_recall': 0.7934131736526946, 'eval_f1': 0.794691954459509, 'eval_runtime': 568.7432, 'eval_samples_per_second': 8.809, 'eval_steps_per_second': 1.102}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [09:14<00:00,  1.13it/s]\n","{'eval_loss': 0.7448945045471191, 'eval_model_preparation_time': 0.0045, 'eval_accuracy': 0.720558882235529, 'eval_precision': 0.7384655130022001, 'eval_recall': 0.720558882235529, 'eval_f1': 0.7210061317302366, 'eval_runtime': 555.3497, 'eval_samples_per_second': 9.021, 'eval_steps_per_second': 1.129}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [18:18<00:00,  1.14it/s]\n","{'eval_loss': 0.6608249545097351, 'eval_model_preparation_time': 0.0045, 'eval_accuracy': 0.7569860279441117, 'eval_precision': 0.7707734033860607, 'eval_recall': 0.7569860279441117, 'eval_f1': 0.7580856679049447, 'eval_runtime': 1099.0755, 'eval_samples_per_second': 9.117, 'eval_steps_per_second': 1.14}\n","100% 627/627 [09:17<00:00,  1.12it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/misclassified_English.jsonl\n","100% 627/627 [09:25<00:00,  1.11it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m:\n","\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/nlp_final_project/wandb/offline-run-20241130_174042-ja2yv4uc\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241130_174042-ja2yv4uc/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./adversarial_shuffle.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/adversarial_shuffle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6FlLdGUEKIPq","executionInfo":{"status":"ok","timestamp":1732992675682,"user_tz":360,"elapsed":400863,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"d7349dde-bea8-42f4-959e-815e24f0ff9e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-30 18:44:38.563404: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-30 18:44:38.577792: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-30 18:44:38.581825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-30 18:44:38.591946: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-30 18:44:39.574604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","\n","Generating test split: 1200 examples [00:00, 2586.23 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 1200/1200 [00:00<00:00, 2471.48 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:235: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 1200/1200 [00:00<00:00, 7381.41 examples/s]\n","Filter: 100% 1200/1200 [00:00<00:00, 7479.24 examples/s]\n","\n","Evaluation on English test set:\n","100% 75/75 [01:00<00:00,  1.22it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 75/75 [01:00<00:00,  1.23it/s]\n","{'eval_loss': 0.5627508759498596, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.7916666666666666, 'eval_precision': 0.8041760194537972, 'eval_recall': 0.7916666666666666, 'eval_f1': 0.7929171640893232, 'eval_runtime': 62.1817, 'eval_samples_per_second': 9.649, 'eval_steps_per_second': 1.206}\n","\n","Evaluation on Russian test set:\n","100% 75/75 [01:00<00:00,  1.23it/s]\n","{'eval_loss': 0.7156760692596436, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.72, 'eval_precision': 0.739331260058876, 'eval_recall': 0.72, 'eval_f1': 0.7191791384854215, 'eval_runtime': 61.545, 'eval_samples_per_second': 9.749, 'eval_steps_per_second': 1.219}\n","\n","Evaluation on the entire test set:\n","100% 150/150 [02:04<00:00,  1.21it/s]\n","{'eval_loss': 0.6392134428024292, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.7558333333333334, 'eval_precision': 0.7716078394178232, 'eval_recall': 0.7558333333333334, 'eval_f1': 0.7562797934545146, 'eval_runtime': 124.8876, 'eval_samples_per_second': 9.609, 'eval_steps_per_second': 1.201}\n","100% 75/75 [01:01<00:00,  1.22it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/adversarial_shuffle/misclassified_English.jsonl\n","100% 75/75 [01:00<00:00,  1.24it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/adversarial_shuffle/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m:\n","\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/nlp_final_project/wandb/offline-run-20241130_184446-l10jh0ww\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241130_184446-l10jh0ww/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./adversarial_xnli_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/adversarial_premise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tZ8C6vW6Y5Bg","executionInfo":{"status":"ok","timestamp":1732993116985,"user_tz":360,"elapsed":430516,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"0f3e058e-6f8d-4c84-cb0c-7d248d313d7c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-30 18:51:30.304218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-30 18:51:30.319434: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-30 18:51:30.323705: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-30 18:51:30.334573: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-30 18:51:31.323390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","Generating test split: 1200 examples [00:00, 2052.75 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 1200/1200 [00:00<00:00, 2229.35 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:235: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 1200/1200 [00:00<00:00, 7042.94 examples/s]\n","Filter: 100% 1200/1200 [00:00<00:00, 7368.69 examples/s]\n","\n","Evaluation on English test set:\n","100% 75/75 [01:06<00:00,  1.11it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 75/75 [01:06<00:00,  1.13it/s]\n","{'eval_loss': 0.749423623085022, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.745, 'eval_precision': 0.7460249327036316, 'eval_recall': 0.745, 'eval_f1': 0.7453303323449387, 'eval_runtime': 67.7235, 'eval_samples_per_second': 8.86, 'eval_steps_per_second': 1.107}\n","\n","Evaluation on Russian test set:\n","100% 75/75 [01:05<00:00,  1.14it/s]\n","{'eval_loss': 0.9227625727653503, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.67, 'eval_precision': 0.6730811465645125, 'eval_recall': 0.67, 'eval_f1': 0.6707007568582748, 'eval_runtime': 66.9025, 'eval_samples_per_second': 8.968, 'eval_steps_per_second': 1.121}\n","\n","Evaluation on the entire test set:\n","100% 150/150 [02:13<00:00,  1.12it/s]\n","{'eval_loss': 0.8360930681228638, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.7075, 'eval_precision': 0.7094484949579557, 'eval_recall': 0.7075, 'eval_f1': 0.708021594587743, 'eval_runtime': 134.9363, 'eval_samples_per_second': 8.893, 'eval_steps_per_second': 1.112}\n","100% 75/75 [01:06<00:00,  1.13it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/adversarial_premise/misclassified_English.jsonl\n","100% 75/75 [01:05<00:00,  1.14it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/adversarial_premise/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m:\n","\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/nlp_final_project/wandb/offline-run-20241130_185137-xskdtxvb\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241130_185137-xskdtxvb/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","df_ru = pd.read_json('output_xnli_en_ru_bert_2_test/adversarial_premise/misclassified_Russian.jsonl', lines=True)\n","df_en = pd.read_json('output_xnli_en_ru_bert_2_test/adversarial_premise/misclassified_English.jsonl', lines=True)\n","print(df_en['true_label'].value_counts())\n","print(df_ru['true_label'].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcGR0XoKadhz","executionInfo":{"status":"ok","timestamp":1732993594375,"user_tz":360,"elapsed":1059,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"a83e35ad-8662-429f-c05e-345bcc223f3c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["true_label\n","1    55\n","0    51\n","2    47\n","Name: count, dtype: int64\n","true_label\n","1    75\n","0    62\n","2    61\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","cm_ru = confusion_matrix(df_ru['true_label'], df_ru['predicted_label'])\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm_ru)\n","disp.plot(cmap=plt.cm.Blues)\n","plt.title('Confusion Matrix for Misclassified Russian Examples')\n","plt.show()\n","\n","cm_en = confusion_matrix(df_en['true_label'], df_en['predicted_label'])\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm_en)\n","disp.plot(cmap=plt.cm.Blues)\n","plt.title('Confusion Matrix for Misclassified English Examples')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":927},"id":"V3FXwURUd67U","executionInfo":{"status":"ok","timestamp":1732993618894,"user_tz":360,"elapsed":2092,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"9ab4def8-3c22-4d2c-c4de-bf2fc0b9cc9c"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfIAAAHHCAYAAABEJtrOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRX0lEQVR4nO3deXhM1/8H8PdMlpnskYhEyGaLxFopGmsQUltpqFraRoouQpFq8Wvt1bTaoiqW1q5Va2npoqkQVGwhag2JIJqNRFayzv39oZmvMcGMmWS298tzn8ecu33u3Ml85px77rkiQRAEEBERkUES6zoAIiIienZM5ERERAaMiZyIiMiAMZETEREZMCZyIiIiA8ZETkREZMCYyImIiAwYEzkREZEBYyInIiIyYEaTyK9evYo+ffrAwcEBIpEIu3fv1ur2r1+/DpFIhPXr12t1u4YsKCgIQUFBWtteUVERxo4dCzc3N4hEIkyePFlr29amOXPmQCQS1ci2RSIR5syZUyPbVkV15zQrKwtDhw6Fs7MzRCIRlixZgoMHD0IkEuHgwYNa23dNvq+1Rdt/E/Q//A5+PK0m8pSUFLz99tto1KgRpFIp7O3t0blzZ3z99de4f/++NnelJCwsDOfOncOCBQuwadMmPP/88zW6v9o0evRoiEQi2NvbV/s+Xr16FSKRCCKRCF9++aXa209PT8ecOXOQmJiohWif3aeffor169fj3XffxaZNm/D666/X6P68vb0hEokQHBxc7fzvvvtO/r6eOnWqRmPRZ1OmTMG+ffswY8YMbNq0CS+++KJO46n6e6iaJBIJmjVrhlmzZqGkpESnselK1Q+rx01btmzRdYhUg8y1taFff/0Vr7zyCiQSCd544w20bNkSZWVlOHLkCD744ANcuHAB3377rbZ2p+D+/fuIj4/HRx99hAkTJtTIPry8vHD//n1YWFjUyPafxtzcHPfu3cOePXswbNgwhXk//PADpFLpM3+JpaenY+7cufD29kbbtm1VXu/PP/98pv09TmxsLF544QXMnj1bq9t9EqlUigMHDiAzMxNubm4K8x73vn788ceYPn16rcVYm6o7p7GxsRg0aBCmTp0qL2vWrBnu378PS0vL2gxPTiKRYPXq1QCA/Px8/Pzzz5g/fz5SUlLwww8/6CQmQPt/E+p677330L59e6XywMBAHURDtUUriTw1NRXDhw+Hl5cXYmNjUb9+ffm8iIgIJCcn49dff9XGrqp1+/ZtAICjo2ON7UMkEkEqldbY9p9GIpGgc+fO+PHHH5US+ebNm9G/f3/s3LmzVmK5d+8erK2ttf4lnp2dDX9/f61tr6KiAjKZ7Ilxdu7cGSdPnsTWrVsxadIkefmtW7dw+PBhvPzyy0rvq7m5OczNtfYbWK9U915lZ2cr/W2JxWKd/j2Ym5vjtddek78eP348OnXqhB9//BGLFi2Cq6urTuLS1Q+bKl27dsXQoUN1GgPVPq00rS9cuBBFRUVYs2aNQhKv0qRJE4UvyYqKCsyfPx+NGzeGRCKBt7c3/u///g+lpaUK63l7e2PAgAE4cuQIOnToAKlUikaNGmHjxo3yZebMmQMvLy8AwAcffACRSARvb28AD5rgqv7/sOquxcXExKBLly5wdHSEra0tfH198X//93/y+Y+7PhMbG4uuXbvCxsYGjo6OGDRoEC5dulTt/pKTkzF69Gg4OjrCwcEB4eHhuHfv3uPf2EeMHDkSv//+O/Ly8uRlJ0+exNWrVzFy5Eil5XNzczF16lS0atUKtra2sLe3R9++fXH27Fn5MgcPHpT/gg8PD5c3xVUdZ1BQEFq2bImEhAR069YN1tbW8vfl0euBYWFhkEqlSscfEhKCOnXqID09vdrjqmoWTE1Nxa+//iqP4fr16wAeJJIxY8bA1dUVUqkUbdq0wYYNGxS2UXV+vvzySyxZskT+2bp48eIT31OpVIrQ0FBs3rxZofzHH39EnTp1EBISorTOs3x+AKCkpARz5sxBs2bNIJVKUb9+fYSGhiIlJeWx8d24cQPjx4+Hr68vrKys4OzsjFdeeUX+3lQpLy/H3Llz0bRpU0ilUjg7O6NLly6IiYmRL5OZmYnw8HA0bNgQEokE9evXx6BBgxS29fA5Xb9+PUQiEQRBQHR0tPy8AHjsNfLjx4/jxRdfhIODA6ytrdG9e3f8/fffSsd15MgRtG/fHlKpFI0bN8aqVase+x6oQiQSoUuXLhAEAdeuXVMor67Pgbe3N0aPHi1/XRPvHwCUlZVh1qxZCAgIgIODA2xsbNC1a1ccOHBAIZ6HP7/ffvut/PPbvn17nDx5UqP35mHr1q2DSCTC2rVrFco//fRTiEQi/Pbbb/KyL7/8Ep06dYKzszOsrKwQEBCAHTt2KG1TJBJhwoQJ2L59O/z9/WFlZYXAwECcO3cOALBq1So0adIEUqkUQUFBSp/dh79jOnXqBCsrK/j4+GDlypUqHdPly5cxdOhQODk5QSqV4vnnn8cvv/yisIwq59eQaaVasWfPHjRq1AidOnVSafmxY8diw4YNGDp0KN5//30cP34cUVFRuHTpEnbt2qWwbHJyMoYOHYoxY8YgLCwMa9euxejRoxEQEIAWLVogNDQUjo6OmDJlCkaMGIF+/frB1tZWrfgvXLiAAQMGoHXr1pg3bx4kEgmSk5Or/QJ62F9//YW+ffuiUaNGmDNnDu7fv49vvvkGnTt3xunTp5V+RAwbNgw+Pj6IiorC6dOnsXr1atSrVw+ff/65SnGGhobinXfewU8//YQ333wTwIPaePPmzdGuXTul5a9du4bdu3fjlVdegY+PD7KysrBq1Sp0794dFy9ehLu7O/z8/DBv3jzMmjULb731Frp27QoACucyJycHffv2xfDhw/Haa689trbz9ddfIzY2FmFhYYiPj4eZmRlWrVqFP//8E5s2bYK7u3u16/n5+WHTpk2YMmUKGjZsiPfffx8A4OLigvv37yMoKAjJycmYMGECfHx8sH37dowePRp5eXkKPxCBB19UJSUleOuttyCRSODk5PTU93XkyJHo06cPUlJS0LhxY/n7OnToUJUupajy+amsrMSAAQOwf/9+DB8+HJMmTUJhYSFiYmJw/vx5+X4fdfLkSRw9ehTDhw9Hw4YNcf36daxYsQJBQUG4ePEirK2tATz4cREVFYWxY8eiQ4cOKCgowKlTp3D69Gn07t0bADBkyBBcuHABEydOhLe3N7KzsxETE4ObN29W+4O3W7du8r4KvXv3xhtvvPHE9yE2NhZ9+/ZFQEAAZs+eDbFYjHXr1qFnz544fPgwOnToAAA4d+4c+vTpAxcXF8yZMwcVFRWYPXu2xrXoqgRRp04dtdetifcPAAoKCrB69WqMGDEC48aNQ2FhIdasWYOQkBCcOHFC6VLW5s2bUVhYiLfffhsikQgLFy5EaGgorl27ptJnsbCwEHfu3FEqr+qoGB4ejp9++gmRkZHo3bs3PDw8cO7cOcydOxdjxoxBv3795Ot8/fXXeOmllzBq1CiUlZVhy5YteOWVV7B37170799fYfuHDx/GL7/8goiICABAVFQUBgwYgA8//BDLly/H+PHjcffuXSxcuBBvvvkmYmNjFda/e/cu+vXrh2HDhmHEiBHYtm0b3n33XVhaWsq/66pz4cIFdO7cGQ0aNMD06dNhY2ODbdu2YfDgwdi5cydefvllAKqdX4MmaCg/P18AIAwaNEil5RMTEwUAwtixYxXKp06dKgAQYmNj5WVeXl4CAOHQoUPysuzsbEEikQjvv/++vCw1NVUAIHzxxRcK2wwLCxO8vLyUYpg9e7bw8KEvXrxYACDcvn37sXFX7WPdunXysrZt2wr16tUTcnJy5GVnz54VxGKx8MYbbyjt780331TY5ssvvyw4Ozs/dp8PH4eNjY0gCIIwdOhQoVevXoIgCEJlZaXg5uYmzJ07t9r3oKSkRKisrFQ6DolEIsybN09edvLkSaVjq9K9e3cBgLBy5cpq53Xv3l2hbN++fQIA4ZNPPhGuXbsm2NraCoMHD37qMQrCg/Pdv39/hbIlS5YIAITvv/9eXlZWViYEBgYKtra2QkFBgfy4AAj29vZCdna2WvurqKgQ3NzchPnz5wuCIAgXL14UAAhxcXHCunXrBADCyZMn5es9y+dn7dq1AgBh0aJFSvNkMpn8/wCE2bNny1/fu3dPafn4+HgBgLBx40Z5WZs2bZTeu4fdvXu32r+RR1V3TgEIERERCmUHDhwQAAgHDhyQH0PTpk2FkJAQheO5d++e4OPjI/Tu3VteNnjwYEEqlQo3btyQl128eFEwMzMTVPlKqvp7uH37tnD79m0hOTlZ+PLLLwWRSCS0bNnyie9nFS8vLyEsLEz+uqbev4qKCqG0tFRpW66urgrfB1WfX2dnZyE3N1de/vPPPwsAhD179jxxv1Xn43FTRkaGfNmMjAzByclJ6N27t1BaWio899xzgqenp5Cfn6+wzUc/e2VlZULLli2Fnj17KpQDECQSiZCamiovW7VqlQBAcHNzk/+NCoIgzJgxQwCgsGzVd8xXX30lLystLZV/v5aVlSm8Rw9/T/Xq1Uto1aqVUFJSIi+TyWRCp06dhKZNm8rLnnZ+DZ3GTesFBQUAADs7O5WWr2q6iYyMVCivqoU9ei3d399fXksEHtTSfH19FZrPNFV1/e/nn3+GTCZTaZ2MjAwkJiZi9OjRCrW+1q1bo3fv3gpNVFXeeecdhdddu3ZFTk6O/D1UxciRI3Hw4EFkZmYiNjYWmZmZ1TarAw+uq4vFD05xZWUlcnJy5M2+p0+fVnmfEokE4eHhKi3bp08fvP3225g3bx5CQ0MhlUo1ajb97bff4ObmhhEjRsjLLCws8N5776GoqAhxcXEKyw8ZMgQuLi5q7cPMzAzDhg3Djz/+COBBJzcPDw+Fz92TqPL52blzJ+rWrYuJEycqzXvSLVdWVlby/5eXlyMnJwdNmjSBo6Ojwjl0dHTEhQsXcPXq1cdux9LSEgcPHsTdu3dVOSy1JCYmyi/x5OTk4M6dO7hz5w6Ki4vRq1cvHDp0CDKZDJWVldi3bx8GDx4MT09P+fp+fn7VXsZ4nOLiYri4uMDFxQVNmjTB1KlT0blzZ/z888/PdAtbTb1/ZmZm8uvmMpkMubm5qKiowPPPP1/t3+Crr76q0KJQ9RlU9ftu1qxZiImJUZoe/o5yc3NDdHQ0YmJi0LVrVyQmJmLt2rWwt7dXOuYqd+/eRX5+Prp27Vpt3L169VJolejYsSOAB3+PD+eGqvJHj8fc3Bxvv/22/LWlpSXefvttZGdnIyEhodpjzc3NRWxsLIYNGyZvibhz5w5ycnIQEhKCq1ev4t9//wXw9PNr6DRO5FUnv7CwUKXlb9y4AbFYjCZNmiiUu7m5wdHRETdu3FAof/iPvUqdOnW0+mX06quvonPnzhg7dixcXV0xfPhwbNu27YlJvSpOX19fpXl+fn7yL7GHPXosVX+w6hxLv379YGdnh61bt+KHH35A+/btld7LKjKZDIsXL0bTpk0hkUhQt25duLi44J9//kF+fr7K+2zQoIFanXi+/PJLODk5ITExEUuXLkW9evVUXvdRN27cQNOmTeU/SKr4+fnJ5z/Mx8fnmfYzcuRIXLx4EWfPnsXmzZsxfPhwlROCKp+flJQU+Pr6qt1J7v79+5g1axY8PDwUzmFeXp7COZw3bx7y8vLQrFkztGrVCh988AH++ecf+XyJRILPP/8cv//+O1xdXdGtWzcsXLgQmZmZasXzOFVfkGFhYfIEWzWtXr0apaWlyM/Px+3bt3H//n00bdpUaRvV/S09jlQqlSepdevWwc/PD9nZ2QrJRx01+f5t2LABrVu3ll+bdXFxwa+//lrt36Cm3xGtWrVCcHCw0vTo3+/w4cPRv39/nDhxAuPGjUOvXr2UtrV371688MILkEqlcHJygouLC1asWKFS3A4ODgAADw+PassfPR53d3fY2NgolDVr1gwAlK6pV0lOToYgCJg5c6bSZ67qzpfs7GwATz+/hk4ridzd3R3nz59Xaz1VvyTNzMyqLRcE4Zn3UVlZqfDaysoKhw4dwl9//YXXX38d//zzD1599VX07t1baVlNaHIsVSQSCUJDQ7Fhwwbs2rXrsbVx4EEHlsjISHTr1g3ff/899u3bh5iYGLRo0ULllgcAan85njlzRv4HVNXhpbY86xd5x44d0bhxY0yePBmpqalPfF+r22dNfX4mTpyIBQsWYNiwYdi2bRv+/PNPxMTEwNnZWeEcduvWDSkpKVi7di1atmyJ1atXo127dvJbtABg8uTJuHLlCqKioiCVSjFz5kz4+fnhzJkzGsUIQB7LF198UW2NMCYmRu2+K09iZmYmT1KjR4/G/v37kZmZqVCre5JHz0tNvX/ff/89Ro8ejcaNG2PNmjX4448/EBMTg549e1b7N6iN7whV5OTkyMdGuHjxolIshw8fxksvvQSpVIrly5fjt99+Q0xMDEaOHFltLI+LuyaPpyrmqVOnPvYzV1XJUeX8GjKt9FofMGAAUlJSEB8f/9Rlvby8IJPJlJo4srKykJeXJ++Brg116tRR6OFd5dFaHPDgdppevXph0aJFuHjxIhYsWIDY2Fil3qVVquJMSkpSmnf58mXUrVtX6RemtowcORJnzpxBYWEhhg8f/tjlduzYgR49emDNmjUYPnw4+vTpg+DgYKX3RJujaRUXFyM8PBz+/v546623sHDhQo163Xp5eeHq1atKXzSXL1+Wz9eWESNG4ODBg/Dz81Prfnrg6Z+fxo0bIykpCeXl5Wptd8eOHQgLC8NXX32FoUOHonfv3ujSpUu1n2snJyeEh4fjxx9/RFpaGlq3bq3UY7tx48Z4//338eeff+L8+fMoKyvDV199pVZM1anqrGdvb19tjTA4OBgWFhZwcXGBlZVVtU2c1f0tqap+/fqYMmUK9uzZg2PHjsnLq/sOKCsrQ0ZGhtI2auL927FjBxo1aoSffvoJr7/+OkJCQhAcHKzzgWsiIiJQWFiIqKgoHDlyBEuWLFGYv3PnTkilUuzbtw9vvvkm+vbt+9iBk7QhPT1dqQXzypUrAPDYjoSNGjUC8OBS2+M+cw8366tyfg2VVhL5hx9+CBsbG4wdOxZZWVlK81NSUvD1118DgLxX5KMfnEWLFgGAUm9ITTRu3Bj5+fkKTSgZGRlKPeNzc3OV1q36In/0lrgq9evXR9u2bbFhwwaFL4rz58/jzz//VOj9qW09evTA/PnzsWzZMqVBTB5mZmam9Mt3+/bt8utGVap+cFSXHNQ1bdo03Lx5Exs2bMCiRYvg7e2NsLCwx76PT9OvXz9kZmZi69at8rKKigp88803sLW1Rffu3TWOucrYsWMxe/ZstRObKp+fIUOG4M6dO1i2bJnSsk+qnVR3Dr/55hulGmVOTo7Ca1tbWzRp0kS+/3v37iklj8aNG8POzu6Zz83DAgIC0LhxY3z55ZcoKipSml811oOZmRlCQkKwe/du3Lx5Uz7/0qVL2Ldvn0YxTJw4EdbW1vjss8/kZY0bN8ahQ4cUlvv2229r7f2rqpE+fA6PHz+uUqWnpuzYsQNbt27FZ599hunTp2P48OH4+OOP5YkTeBC3SCRSeJ+uX7+u9aGvq1RUVCj0pSkrK8OqVavg4uKCgICAatepV68egoKCsGrVqmp/mFV95oCnn19Dp5Xbzxo3bozNmzfj1VdfhZ+fn8LIbkePHpXfLgQAbdq0QVhYGL799lvk5eWhe/fuOHHiBDZs2IDBgwejR48e2ggJwIPrQNOmTcPLL7+M9957D/fu3cOKFSvQrFkzhQ4b8+bNw6FDh9C/f394eXkhOzsby5cvR8OGDdGlS5fHbv+LL75A3759ERgYiDFjxshvP3NwcKjRX3pisRgff/zxU5cbMGAA5s2bh/DwcHTq1Annzp3DDz/8IP8lW6Vx48ZwdHTEypUrYWdnBxsbG3Ts2FHt682xsbFYvnw5Zs+eLb8dbt26dQgKCsLMmTOxcOFCtbYHAG+99RZWrVqF0aNHIyEhAd7e3tixYwf+/vtvLFmyROVOlqrw8vJ6pvOmyufnjTfewMaNGxEZGYkTJ06ga9euKC4uxl9//YXx48dj0KBB1W57wIAB2LRpExwcHODv74/4+Hj89ddfcHZ2VljO398fQUFBCAgIgJOTE06dOoUdO3bIRzq8cuUKevXqhWHDhsHf3x/m5ubYtWsXsrKyntiqoyqxWIzVq1ejb9++aNGiBcLDw9GgQQP8+++/OHDgAOzt7bFnzx4AwNy5c/HHH3+ga9euGD9+vPyHWYsWLTS6buns7Izw8HAsX74cly5dgp+fH8aOHYt33nkHQ4YMQe/evXH27Fns27cPdevWVVi3pt6/AQMG4KeffsLLL7+M/v37IzU1FStXroS/v3+1P3g0dfjw4Wpr+61bt0br1q2RnZ2Nd999Fz169JAf27Jly3DgwAGMHj0aR44cgVgsRv/+/bFo0SK8+OKLGDlyJLKzsxEdHY0mTZrUyLVld3d3fP7557h+/TqaNWuGrVu3IjExEd9+++0Tb7uLjo5Gly5d0KpVK4wbNw6NGjVCVlYW4uPjcevWLfmYGU87vwZPm13gr1y5IowbN07w9vYWLC0tBTs7O6Fz587CN998o3B7QHl5uTB37lzBx8dHsLCwEDw8PIQZM2YoLCMI1d+OJAjKt3g87vYzQRCEP//8U2jZsqVgaWkp+Pr6Ct9//73S7UP79+8XBg0aJLi7uwuWlpaCu7u7MGLECOHKlStK+3j0Fq2//vpL6Ny5s2BlZSXY29sLAwcOFC5evKiwTNX+Hr09qerWpodvxajOw7efPc7jbj97//33hfr16wtWVlZC586dhfj4+GpvMfr5558Ff39/wdzcXOE4u3fvLrRo0aLafT68nYKCAsHLy0to166dUF5errDclClTBLFYLMTHxz/xGB53vrOysoTw8HChbt26gqWlpdCqVSul8/Ckz4C6+3uYKrefqfL5EYQHt/N89NFH8s+9m5ubMHToUCElJUW+DB65Xeru3bvyY7e1tRVCQkKEy5cvK90+9cknnwgdOnQQHB0dBSsrK6F58+bCggUL5Lfu3LlzR4iIiBCaN28u2NjYCA4ODkLHjh2Fbdu2KcT4rLefVTlz5owQGhoqODs7CxKJRPDy8hKGDRsm7N+/X2G5uLg4ISAgQLC0tBQaNWokrFy5Uul9fZwn/T2kpKQIZmZm8vemsrJSmDZtmlC3bl3B2tpaCAkJEZKTk2vt/ZPJZMKnn34qeHl5CRKJRHjuueeEvXv3Kt0a+6TP76Ofieo87fazqvVDQ0MFOzs74fr16wrrV93m9vnnn8vL1qxZIzRt2lSQSCRC8+bNhXXr1lV7jqr7fDzueKri3L59u8J71qJFC+HUqVNCYGCgIJVKBS8vL2HZsmXVbvPRv/2UlBThjTfeENzc3AQLCwuhQYMGwoABA4QdO3bIl3na+TV0IkHQci8KIiIiFQUFBeHOnTtqd5im/zGax5gSERGZIiZyIiIiA8ZETkREZMCYyImISGcOHjxotNfHq56U+PDUvHlz+fySkhJERETA2dkZtra2GDJkSLW3cD8NEzkREVENadGiBTIyMuTTkSNH5POqBjHavn074uLikJ6ejtDQULX3oZX7yImIiEiZubl5tQN35efnY82aNdi8eTN69uwJAPLnBhw7dgwvvPCC6vvQWrQ6IJPJkJ6eDjs7O60OM0pERLVDEAQUFhbC3d1d6eFI2lRSUoKysjKNtyMIglK+kUgkkEgk1S5/9epVuLu7QyqVIjAwEFFRUfD09ERCQgLKy8sVhr5t3rw5PD09ER8fbzqJPD09XenpOkREZHjS0tLQsGHDGtl2SUkJrOycgYp7Gm/L1tZWaVS+2bNnVzsqZMeOHbF+/Xr4+voiIyMDc+fORdeuXXH+/HlkZmbC0tJS/hjkKq6urmo/ldCgE3nV8JzJqWmwe+RZumR8mk/YoesQqBZFvlb9GNtkXEruFWHBK120Otzyo8rKyoCKe5D4hwFmqj+SWUllGYoubkBaWprC89sfVxvv27ev/P+tW7dGx44d4eXlhW3btj3zkxqrY9CJvKp5w87eXuFNJeMktrTWdQhUi6Q2NffFTvqnVi6Pmksh0iCRC6IHTf/2z5hzHB0d0axZMyQnJ6N3794oKytDXl6eQq08KyvriQ/Dqg57rRMRkWkQARCJNJg0231RURFSUlJQv359BAQEwMLCAvv375fPT0pKws2bNxEYGKjWdg26Rk5ERKQykfjBpMn6apg6dSoGDhwILy8vpKenY/bs2TAzM8OIESPg4OCAMWPGIDIyEk5OTrC3t8fEiRMRGBioVkc3gImciIioRty6dQsjRoxATk4OXFxc0KVLFxw7dgwuLi4AgMWLF0MsFmPIkCEoLS1FSEgIli9frvZ+mMiJiMg0VDWRa7K+GrZs2fLE+VKpFNHR0YiOjn72mMBETkREpqKWm9Zri35GRURERCphjZyIiExDLTet1xYmciIiMhEaNq3raSO2fkZFREREKmGNnIiITAOb1omIiAwYe60TERGRvmGNnIiITAOb1omIiAyYkTatM5ETEZFpMNIauX7+vCAiIiKVsEZORESmgU3rREREBkwk0jCRs2mdiIiItIw1ciIiMg1i0YNJk/X1EBM5ERGZBiO9Rq6fUREREZFKWCMnIiLTYKT3kTORExGRaWDTOhEREekb1siJiMg0sGmdiIjIgBlp0zoTORERmQYjrZHr588LIiIiUglr5EREZBrYtE5ERGTA2LRORERE+oY1ciIiMhEaNq3rad2XiZyIiEwDm9aJiIhI37BGTkREpkEk0rDXun7WyJnIiYjINBjp7Wf6GRURERGphDVyIiIyDUba2Y2JnIiITIORNq0zkRMRkWkw0hq5fv68ICIiIpWwRk5ERKaBTetEREQGjE3rREREpG9YIyciIpMgEokgMsIaORM5ERGZBGNN5GxaJyIiMmCskRMRkWkQ/Tdpsr4eYiInIiKTwKZ1IiIi0juskRMRkUkw1ho5EzkREZkEJnLSC99ti8M33+9Hdk4BWjZtgM8/eAUBLbx1HRZpUURfP8wY0garY5IwZ+sZAMCobo0xuKMXWnrWgZ2VBfwn7kTB/XIdR0rqios5gUv/XMXt7FxYWJjDw9sdfQZ2hYurk3yZk0f/wT8Jl5FxKxulpWX4v0/Hw8paqsOojYexJnK9uEYeHR0Nb29vSKVSdOzYESdOnNB1SHrppz8T8PGSXZg2ti8ObpqGlk0bYMjEaNzOLdR1aKQlbbydMKpbY1xMu6tQLrU0w8HzGVj220UdRUbacD0lDR26tMVbk0cg7N2hkMlk2LByJ8pK//ejrLysAk39vNGtdwcdRkqGROeJfOvWrYiMjMTs2bNx+vRptGnTBiEhIcjOztZ1aHpn+eZYvDG4E0a9FIjmjepj0YzhsJZa4vtf4nUdGmmBtcQc34x9AR9uPIn8e4q17TV/XUH075dw+lqOjqIjbQh7ZwjadWwB1/p1Ub+BC0JHhiD/biHSb2XJl+kU1A7dgjvAw6u+DiM1UiItTHpI54l80aJFGDduHMLDw+Hv74+VK1fC2toaa9eu1XVoeqWsvAKJl9MQ1MFXXiYWi9G9gy9OnkvVYWSkLQtGBWD/uQwcuZT19IXJKJTcLwUANp3XkqqmdU0mfaTTRF5WVoaEhAQEBwfLy8RiMYKDgxEfz1rmw3LyilBZKYOLk51CuYuTPbJzCnQUFWnLS+090cqzDj7beVbXoVAtkckE/LbrIDx93OFav66uwyEDptPObnfu3EFlZSVcXV0Vyl1dXXH58mWl5UtLS1FaWip/XVDABEaGr34da8wd0Q4jFx1AaYVM1+FQLdm7Yz+yM3IwdtKrug7FZDx4iqkmnd20F4s2GVSv9aioKMydO1fXYeiEs6MtzMzESh3bbucWoJ6zvY6iIm1o7VUHLvZS/D4zRF5mbiZGx6YuGN2zKRq9sx0yQdBhhKRte3fsR9LFaxg78VU4ONo9fQXSChE0bR7Xz0yu00Ret25dmJmZIStL8ZpgVlYW3NzclJafMWMGIiMj5a8LCgrg4eFR43HqA0sLc7Rt7oG4k0noH9QGACCTyXDo5BWMfaWbjqMjTRy5lIVes35XKPsqvANSMgux/PdLTOJGRBAE/LozFhfPJWPMhGGo4+yg65DICOg0kVtaWiIgIAD79+/H4MGDATxITvv378eECROUlpdIJJBIJLUcpf4YP7Inxs/dhOf8PNGuhTdW/HgAxfdLMWrgC7oOjTRQXFqBpPR8hbL7ZZW4W1QqL3exl8LFQQrverYAgOYNHVFUUo703HvIKy6r9Zjp2ezdEYt/Ei5j5NiXYCmxRGFBMQBAKrWEhaUFAKCwoBhFBcXIuZMHAMjKuAOJxBIOdexgbWOlq9CNgrHeR67zpvXIyEiEhYXh+eefR4cOHbBkyRIUFxcjPDxc16HpndA+AbiTV4RPV/2K7JxCtGrWADuWRrBp3QS8HtQEkS+1lL/+aVovAMCUtcex/SjvWjAUJ/5+0Jlx7bLtCuUvjwhBu44tAAAn/z6LA/uOyeet+Wab0jL0jIz06WciQdB9u92yZcvwxRdfIDMzE23btsXSpUvRsWPHp65XUFAABwcHZOXkw96eyczYNRy7RdchUC2aHs4BUUxBSXEhZvZvi/z8mvser8oVdYavhsjS+pm3I5Tdw90tY2s01meh8xo5AEyYMKHapnQiIiKt0bBpXWDTOhERke5oeo1cXweEYSInIiKTYKyJXOdDtBIRERm7zz77DCKRCJMnT5aXlZSUICIiAs7OzrC1tcWQIUOUbsdWBRM5ERGZBh09NOXkyZNYtWoVWrdurVA+ZcoU7NmzB9u3b0dcXBzS09MRGhqq9vaZyImIyCTo4qEpRUVFGDVqFL777jvUqVNHXp6fn481a9Zg0aJF6NmzJwICArBu3TocPXoUx44de8IWlTGRExERqaGgoEBhevgZII+KiIhA//79FR4OBgAJCQkoLy9XKG/evDk8PT3VfmgYEzkREZkEbdXIPTw84ODgIJ+ioqKq3d+WLVtw+vTpaudnZmbC0tISjo6OCuWurq7IzMxU67jYa52IiEyCtnqtp6WlKQwIU93Q4WlpaZg0aRJiYmIgldbs8+ZZIyciIlKDvb29wlRdIk9ISEB2djbatWsHc3NzmJubIy4uDkuXLoW5uTlcXV1RVlaGvLw8hfUe99CwJ2GNnIiITEJt3kfeq1cvnDt3TqEsPDwczZs3x7Rp0+Dh4QELCwvs378fQ4YMAQAkJSXh5s2bCAwMVCsuJnIiIjINtfjQFDs7O7Rs2VKhzMbGBs7OzvLyMWPGIDIyEk5OTrC3t8fEiRMRGBiIF15Q74mWTOREREQ6sHjxYojFYgwZMgSlpaUICQnB8uXL1d4OEzkREZkEXQ/RevDgQYXXUqkU0dHRiI6O1mi7TORERGQSdJ3IawoTORERmQRjTeS8/YyIiMiAsUZORESmoRZ7rdcmJnIiIjIJbFonIiIivcMaORERmQRjrZEzkRMRkUkQQcNErqcXydm0TkREZMBYIyciIpPApnUiIiJDZqS3n7FpnYiIyICxRk5ERCaBTetEREQGjImciIjIgIlEDyZN1tdHvEZORERkwFgjJyIik/CgRq5J07oWg9EiJnIiIjINGjat8/YzIiIi0jrWyImIyCSw1zoREZEBY691IiIi0juskRMRkUkQi0UQi5+9Wi1osG5NYiInIiKTwKZ1IiIi0juskRMRkUlgr3UiIiIDZqxN60zkRERkEoy1Rs5r5ERERAaMNXIiIjIJxlojZyInIiKTYKzXyNm0TkREZMBYIyciIpMggoZN63r6HFMmciIiMglsWiciIiK9wxo5ERGZBPZaJyIiMmBsWiciIiK9wxo5ERGZBDatExERGTBjbVpnIiciIpNgrDVyXiMnIiIyYEZRI/cMmgqRmaWuw6AadvfkMl2HQLXo/V8u6joEqgVl90prb2caNq3r6cBuxpHIiYiInoZN60RERKR3WCMnIiKTwF7rREREBoxN60RERKR3WCMnIiKTwKZ1IiIiA8amdSIiItI7rJETEZFJMNYaORM5ERGZBF4jJyIiMmDGWiPnNXIiIiIDxho5ERGZBDatExERGTA2rRMREZHeYY2ciIhMgggaNq1rLRLtYiInIiKTIBaJINYgk2uybk1i0zoREZEBY42ciIhMAnutExERGTD2WiciIjJgYpHmkzpWrFiB1q1bw97eHvb29ggMDMTvv/8un19SUoKIiAg4OzvD1tYWQ4YMQVZWlvrHpfYaRERE9FQNGzbEZ599hoSEBJw6dQo9e/bEoEGDcOHCBQDAlClTsGfPHmzfvh1xcXFIT09HaGio2vth0zoREZkGkYbN42quOnDgQIXXCxYswIoVK3Ds2DE0bNgQa9aswebNm9GzZ08AwLp16+Dn54djx47hhRdeUHk/rJETEZFJqOrspskEAAUFBQpTaWnpU/ddWVmJLVu2oLi4GIGBgUhISEB5eTmCg4PlyzRv3hyenp6Ij49X67iYyImIiNTg4eEBBwcH+RQVFfXYZc+dOwdbW1tIJBK888472LVrF/z9/ZGZmQlLS0s4OjoqLO/q6orMzEy14mHTOhERmQTRf/80WR8A0tLSYG9vLy+XSCSPXcfX1xeJiYnIz8/Hjh07EBYWhri4uGeOoTpM5EREZBKepef5o+sDkPdCV4WlpSWaNGkCAAgICMDJkyfx9ddf49VXX0VZWRny8vIUauVZWVlwc3NTLy61liYiIqJnJpPJUFpaioCAAFhYWGD//v3yeUlJSbh58yYCAwPV2iZr5EREZBJqe0CYGTNmoG/fvvD09ERhYSE2b96MgwcPYt++fXBwcMCYMWMQGRkJJycn2NvbY+LEiQgMDFSrxzqgYiL/5ZdfVN7gSy+9pFYAREREtaG2h2jNzs7GG2+8gYyMDDg4OKB169bYt28fevfuDQBYvHgxxGIxhgwZgtLSUoSEhGD58uVqx6VSIh88eLBKGxOJRKisrFQ7CCIiImOzZs2aJ86XSqWIjo5GdHS0RvtRKZHLZDKNdkJERKRrxvoYU42ukZeUlEAqlWorFiIiohpjrE8/U7vXemVlJebPn48GDRrA1tYW165dAwDMnDnzqc0IREREulLV2U2TSR+pncgXLFiA9evXY+HChbC0tJSXt2zZEqtXr9ZqcERERPRkaifyjRs34ttvv8WoUaNgZmYmL2/Tpg0uX76s1eCIiIi0RVtjresbta+R//vvv/JRah4mk8lQXl6ulaCIiIi0zVg7u6ldI/f398fhw4eVynfs2IHnnntOK0ERERGRatSukc+aNQthYWH4999/IZPJ8NNPPyEpKQkbN27E3r17ayJGIiIijYmg9iPFldbXR2rXyAcNGoQ9e/bgr7/+go2NDWbNmoVLly5hz5498tFqiIiI9I2x9lp/pvvIu3btipiYGG3HQkRERGp65gFhTp06hUuXLgF4cN08ICBAa0ERERFpm7YeY6pv1E7kt27dwogRI/D333/Ln6Gal5eHTp06YcuWLWjYsKG2YyQiItJYbT/9rLaofY187NixKC8vx6VLl5Cbm4vc3FxcunQJMpkMY8eOrYkYiYiI6DHUrpHHxcXh6NGj8PX1lZf5+vrim2++QdeuXbUaHBERkTbpaaVaI2oncg8Pj2oHfqmsrIS7u7tWgiIiItI2Nq3/54svvsDEiRNx6tQpedmpU6cwadIkfPnll1oNjoiISFuqOrtpMukjlWrkderUUfglUlxcjI4dO8Lc/MHqFRUVMDc3x5tvvonBgwfXSKBERESkTKVEvmTJkhoOg4iIqGYZa9O6Sok8LCyspuMgIiKqUcY6ROszDwgDACUlJSgrK1Mos7e31yggIiIiUp3aiby4uBjTpk3Dtm3bkJOTozS/srJSK4ERERFpEx9j+p8PP/wQsbGxWLFiBSQSCVavXo25c+fC3d0dGzdurIkYiYiINCYSaT7pI7Vr5Hv27MHGjRsRFBSE8PBwdO3aFU2aNIGXlxd++OEHjBo1qibiJCIiomqoXSPPzc1Fo0aNADy4Hp6bmwsA6NKlCw4dOqTd6IiIiLSEjzH9T6NGjZCamgpPT080b94c27ZtQ4cOHbBnzx75Q1RIc9PG9cP0t/oplF25nomOr3wCAJBYmuOTyaEI7R0AS0tzxB67hKmfb8Xt3EJdhEs14Lttcfjm+/3IzilAy6YN8PkHryCghbeuwyIN9GzijFb17VHPzhLllQJu5N7D3ovZuF38v07D73byQpO6NgrrHb2ei53/ZNZ2uEZH0+ZxPc3j6ify8PBwnD17Ft27d8f06dMxcOBALFu2DOXl5Vi0aFFNxGiyLqWkY3DEN/LXFRUy+f8/nTIEfbq0wOgZa1BQdB8LPxiGTQvH4sWxi3URKmnZT38m4OMlu7Bo+qsIaOmNlT8ewJCJ0Ti5YxZcnOx0HR49o8Z1bXD0ei5u5pVALAL6+dXDW4Ge+OJACsoqBfly8dfvYl9Stvz1w/OIHqV20/qUKVPw3nvvAQCCg4Nx+fJlbN68GWfOnMGkSZPU2tahQ4cwcOBAuLu7QyQSYffu3eqGY9QqKmXIzimUT7n5xQAAexspXhsUiI8W/4TDp67g7OU0TJj3PTq2aYznW3rrNmjSiuWbY/HG4E4Y9VIgmjeqj0UzhsNaaonvf4nXdWikge+O3cTJtHxkFZYio6AUW86kw8naEg0drBSWK6+UobC0Uj6VPvQjnp5dVa91TSZ9pNF95ADg5eUFLy+vZ1q3uLgYbdq0wZtvvonQ0FBNQzE6jTxccPG3BSgtK8fJc6mYt+wX3Mq6izZ+nrC0MMfBE0nyZa/eyEJaRi7at/LBqfPXdRc0aaysvAKJl9MwZXQfeZlYLEb3Dr44eS5Vh5GRtkktHtSl7pUr3rbbrqEDAho6oKC0AhezihBz5TbKWSvXmEk3rS9dulTlDVbV1lXRt29f9O3bV+XlTUnCheuImPs9km9kwbWuA6aN64vfvpuCTsMXwNXZHqVl5Sgouq+wTnZuAVydOSCPocvJK0JlpUypCd3FyR5Xr2fpKCrSNhGAwS3ckJpzD5mFpfLyM//m4+69cuSXVMDdXoL+/q5wsbXEhpO3dBeskTDpIVoXL1btuqtIJFIrkaurtLQUpaX/+8AXFBTU2L507a+jF+X/v5CcjlPnr+PcnnkYHNwOJaXKj5ElIsMS2toNbvYSLDtyXaH82I08+f8zC0tRUFqBdzt5w9naAjn3+LdPylRK5Kmp+tGcFxUVhblz5+o6DJ0oKLqP5JvZaOThggPHL0NiaQF7WyuFWnk9J3tk5RjvjxtT4exoCzMzsdIdCLdzC1CPLS5G4eVWbvB3tUP039eRX1LxxGVv3n3wN17XxpKJXENiPEPHsEfW10f6Gle1ZsyYgfz8fPmUlpam65BqjY2VJXwa1EXmnXycvXQTZeUV6N7eVz6/iVc9eNR34jVUI2BpYY62zT0Qd/J/fSBkMhkOnbyC9q18dBgZacPLrdzQys0OK47eQK4KidndQQoAKCh9csKnp+N95HpAIpFAIpHoOoxaMW/Sy/jj8DmkZeSivosDpr/VH5UyGXbuS0BBcQm+/zkeC6aE4m5BMQqLS7Dwg1dw4p9r7OhmJMaP7InxczfhOT9PtGvhjRU/HkDx/VKMGviCrkMjDYS2ckO7hg5YeyINpRWVsJOYAQDul8tQIRPgbG2B5xo64HJWEYrLKuFuL8FLLd2QcqcYGQWlT9k6mSqDSuSmpEE9R6z+JBxODta4c7cIx89eQ+/wr5CTVwQA+L/FOyETBGz8fKzCgDBkHEL7BOBOXhE+XfUrsnMK0apZA+xYGsGmdQPX2ccJABDR2VuhfMuZf3EyLR+VMgHN6tqgWyMnWJqJkXe/HOcyChBz5Y4OojU+IhEgNtVe6zWlqKgIycnJ8tepqalITEyEk5MTPD09dRiZ7o35aN0T55eWVeCDhdvwwcJttRQR1ba3hnXHW8O66zoM0qL3f7n4xPl5JRVYfvRGLUVjesQaJnJN1q1JOk3kp06dQo8ePeSvIyMjAQBhYWFYv369jqIiIiIyHM+UyA8fPoxVq1YhJSUFO3bsQIMGDbBp0yb4+PigS5cuKm8nKCgIgsBBDoiIqOYZ633kavda37lzJ0JCQmBlZYUzZ87I7+vOz8/Hp59+qvUAiYiItKGqaV2TSR+pncg/+eQTrFy5Et999x0sLCzk5Z07d8bp06e1GhwRERE9mdpN60lJSejWrZtSuYODA/Ly8rQRExERkdYZ61jratfI3dzcFHqaVzly5AgaNWqklaCIiIi0zViffqZ2Ih83bhwmTZqE48ePQyQSIT09HT/88AOmTp2Kd999tyZiJCIi0phYC5M+Urtpffr06ZDJZOjVqxfu3buHbt26QSKRYOrUqZg4cWJNxEhERESPoXYiF4lE+Oijj/DBBx8gOTkZRUVF8Pf3h62tbU3ER0REpBXGeo38mQeEsbS0hL+/vzZjISIiqjFiaHadWwz9zORqJ/IePXo88ab42NhYjQIiIiIi1amdyNu2bavwury8HImJiTh//jzCwsK0FRcREZFWsWn9P4sXL662fM6cOSgqKtI4ICIioppgrA9N0Vpv+tdeew1r167V1uaIiIhIBVp7+ll8fDykUqm2NkdERKRVD55HrslDU7QYjBapnchDQ0MVXguCgIyMDJw6dQozZ87UWmBERETaxGvk/3FwcFB4LRaL4evri3nz5qFPnz5aC4yIiIieTq1EXllZifDwcLRq1Qp16tSpqZiIiIi0jp3dAJiZmaFPnz58yhkRERkckRb+6SO1e623bNkS165dq4lYiIiIakxVjVyTSR+pncg/+eQTTJ06FXv37kVGRgYKCgoUJiIiIqo9Kl8jnzdvHt5//33069cPAPDSSy8pDNUqCAJEIhEqKyu1HyUREZGGjPUaucqJfO7cuXjnnXdw4MCBmoyHiIioRohEoic+K0SV9fWRyolcEAQAQPfu3WssGCIiIlKPWref6euvESIioqcx+aZ1AGjWrNlTk3lubq5GAREREdUEjuyGB9fJHx3ZjYiIiHRHrUQ+fPhw1KtXr6ZiISIiqjFikUijh6Zosm5NUvk+cl4fJyIiQ1bbA8JERUWhffv2sLOzQ7169TB48GAkJSUpLFNSUoKIiAg4OzvD1tYWQ4YMQVZWlnrHpeqCVb3WiYiI6Oni4uIQERGBY8eOISYmBuXl5ejTpw+Ki4vly0yZMgV79uzB9u3bERcXh/T0dKWnjD6Nyk3rMplMrQ0TERHpFQ07u6k71Poff/yh8Hr9+vWoV68eEhIS0K1bN+Tn52PNmjXYvHkzevbsCQBYt24d/Pz8cOzYMbzwwgsq7UftIVqJiIgMkRgijScASkOTl5aWqrT//Px8AICTkxMAICEhAeXl5QgODpYv07x5c3h6eiI+Pl6N4yIiIjIBVbefaTIBgIeHBxwcHORTVFTUU/ctk8kwefJkdO7cGS1btgQAZGZmwtLSEo6OjgrLurq6IjMzU+XjUqvXOhERkalLS0uDvb29/LVEInnqOhERETh//jyOHDmi9XiYyImIyCRoa2Q3e3t7hUT+NBMmTMDevXtx6NAhNGzYUF7u5uaGsrIy5OXlKdTKs7Ky4ObmpnpcKi9JRERkwKruI9dkUocgCJgwYQJ27dqF2NhY+Pj4KMwPCAiAhYUF9u/fLy9LSkrCzZs3ERgYqPJ+WCMnIiKqAREREdi8eTN+/vln2NnZya97Ozg4wMrKCg4ODhgzZgwiIyPh5OQEe3t7TJw4EYGBgSr3WAeYyImIyETU9ljrK1asAAAEBQUplK9btw6jR48GACxevBhisRhDhgxBaWkpQkJCsHz5crX2w0ROREQmQQwNh2hV80ZyVQZSk0qliI6ORnR09LOGxWvkREREhow1ciIiMgl8jCkREZEBE0OzZmh9bcLW17iIiIhIBayRExGRSRCJRBo9kltfH+fNRE5ERCZBBLUfYKa0vj5iIiciIpPwLKOzPbq+PuI1ciIiIgPGGjkREZkM/axTa4aJnIiITIKx3kfOpnUiIiIDxho5ERGZBN5+RkREZMA4shsRERHpHdbIiYjIJLBpnYiIyIAZ68hubFonIiIyYEZRI3/h9WEwt7LRdRhUw4asPqHrEKgW7RzbQdchUC0oKCjA6lraF5vWiYiIDJix9lpnIiciIpNgrDVyff2BQURERCpgjZyIiEyCsfZaZyInIiKTwIemEBERkd5hjZyIiEyCGCKINWgg12TdmsRETkREJoFN60RERKR3WCMnIiKTIPrvnybr6yMmciIiMglsWiciIiK9wxo5ERGZBJGGvdbZtE5ERKRDxtq0zkROREQmwVgTOa+RExERGTDWyImIyCTw9jMiIiIDJhY9mDRZXx+xaZ2IiMiAsUZOREQmgU3rREREBoy91omIiEjvsEZOREQmQQTNmsf1tELORE5ERKaBvdaJiIhI77BGTkREJoG91omIiAyYsfZaZyInIiKTIIJmHdb0NI/zGjkREZEhY42ciIhMghgiiDVoHxfraZ2ciZyIiEwCm9aJiIhI77BGTkREpsFIq+RM5EREZBKM9T5yNq0TEREZMNbIiYjINGg4IIyeVsiZyImIyDQY6SVyNq0TEREZMtbIiYjINBhplZyJnIiITIKx9lpnIiciIpNgrE8/4zVyIiIiA8YaORERmQQjvUTORE5ERCbCSDM5m9aJiIgMGBM5ERGZBJEW/qnj0KFDGDhwINzd3SESibB7926F+YIgYNasWahfvz6srKwQHByMq1evqn1cTORERGQSqnqtazKpo7i4GG3atEF0dHS18xcuXIilS5di5cqVOH78OGxsbBASEoKSkhK19sNr5ERERDWgb9++6Nu3b7XzBEHAkiVL8PHHH2PQoEEAgI0bN8LV1RW7d+/G8OHDVd4Pa+RERGQSRFqYAKCgoEBhKi0tVTuW1NRUZGZmIjg4WF7m4OCAjh07Ij4+Xq1tMZETEZFp0FIm9/DwgIODg3yKiopSO5TMzEwAgKurq0K5q6urfJ6q2LRORESkhrS0NNjb28tfSyQSHUbDGjkREZkIbfVat7e3V5ieJZG7ubkBALKyshTKs7Ky5PNUxUROREQmobZ7rT+Jj48P3NzcsH//fnlZQUEBjh8/jsDAQLW2xaZ1IiIyCbU9sFtRURGSk5Plr1NTU5GYmAgnJyd4enpi8uTJ+OSTT9C0aVP4+Phg5syZcHd3x+DBg9XaDxM5ERFRDTh16hR69Oghfx0ZGQkACAsLw/r16/Hhhx+iuLgYb731FvLy8tClSxf88ccfkEqlau2HiVxP9fV3Rb8WrnC1e3Dt5WbuffyYcAsJaXkAgBC/eghqWheN69rA2tIcr649geKySh1GTM8qxK8eQvzqwcX2wblOu3sf28/8izO38gEAFmYihHX0RJdGzjA3E+HsrXx8e/Q68u9X6DJs0rLvtsXhm+/3IzunAC2bNsDnH7yCgBbeug7LuNRylTwoKAiCIDx+cyIR5s2bh3nz5mkQFK+R662c4jJsOH4Tk3eew+Sd53A2PR8fv+gLzzpWAACJuRgJN/Ow7fS/Oo6UNJVTXIbvT6Thw93n8eHuCzifUYBpvZvCw/HBuQ5/wRPPezriy/1XMWvvJdSxtsSHwU11HDVp009/JuDjJbswbWxfHNw0DS2bNsCQidG4nVuo69CMSm0P0VpbdJrIo6Ki0L59e9jZ2aFevXoYPHgwkpKSdBmS3jhx4y5O3cxDen4J0vNLsOlEGkrKZfB1tQMA/HIuEzsS05GUXaTjSElTp27m4fStfGQUlCKjoASbT91CSbkMzerZwNrCDD2buWD9sZs4n1GIazn3EH3oGpq72qGpi42uQyctWb45Fm8M7oRRLwWieaP6WDRjOKyllvj+F/UGBiHTpNNEHhcXh4iICBw7dgwxMTEoLy9Hnz59UFxcrMuw9I5YBHRr7AyphRiXs/gL3ZiJRUDnRk6QWoiRlF2ERnWtYWEmxj/pBfJl/s0vwe3CUvi62uowUtKWsvIKJF5OQ1AHX3mZWCxG9w6+OHkuVYeRGR996rWuTTq9Rv7HH38ovF6/fj3q1auHhIQEdOvWTUdR6Q8vJ2t8+XJLWJqJcb+8Egv2JSHt7n1dh0U1wLOOFT59yR+WZmKUlFdiYcxV3MorgbezDcorZbj3SP+HvPvlcLSy0FG0pE05eUWorJTBxclOodzFyR5Xr2c9Zi16Fkb6OHL96uyWn/+gc4+Tk1O180tLSxXGtC0oKKh2OWPxb959vLf9H1hbmqFLI2dM6dEE03+5wGRuhNLzSzB113lYW5gh0McJE7o3wqxfL+k6LCIyAHrT2U0mk2Hy5Mno3LkzWrZsWe0yUVFRCuPbenh41HKUtatCJiCjoAQpd4qx4cRNpOYU46VW9XUdFtWACpmAzIJSXMu5hx9O3cKN3Hvo38INeffKYGEmhrWlmcLyjlYWyLtfrqNoSZucHW1hZiZW6th2O7cA9ZztH7MWPRNtPTVFz+hNIo+IiMD58+exZcuWxy4zY8YM5Ofny6e0tLRajFD3RCIRLMz09JNEWlV1rq/duYfyShlau//vC93dQQoXOwmSstjR0RhYWpijbXMPxJ38X0dfmUyGQyevoH0rHx1GZnyMtde6XjStT5gwAXv37sWhQ4fQsGHDxy4nkUh0Pjh9bQnr4IlTaXdxu6gMVhZmCGpSF63c7eXNrY5WFqhjbYH69g8GDvB2ssa98krcLipDUSnvLzYko55viDO38nG7qBRWFmbo2tgZLerbYf4f6bhXXonYK7cxuqMnikorcK+sEmM6eeFyViGu3manUGMxfmRPjJ+7Cc/5eaJdC2+s+PEAiu+XYtTAF3QdGhkAnSZyQRAwceJE7Nq1CwcPHoSPD399VnGwskBkzyZwsrZEcVklrucUY9avl5D43yAh/Vq4YuTz/7u08PngB5cjFh9Ixv6k2zqJmZ6Ng5UFJnZvhDrWFrhXVokbufcw/48k/PPvgz4g647dhKwjMLVXU1iYiZD4bz6++/uGjqMmbQrtE4A7eUX4dNWvyM4pRKtmDbBjaQSb1rVM057n+tprXSQ8adiZGjZ+/Hhs3rwZP//8M3x9/3frhYODA6ysrJ66fkFBARwcHNB9YQzMrXhPrbGTmJs9fSEyGjvHdtB1CFQLCgoK4OrsgPz8fIVHg2p7Hw4ODki4kgFbu2ffR1FhAQKa1a/RWJ+FTq+Rr1ixAvn5+QgKCkL9+vXl09atW3UZFhERGSMj7eym86Z1IiIienZ60dmNiIiopmna85y91omIiHRJ02FW9TOP68995ERERKQ+1siJiMgkcKx1IiIiQ2akmZxN60RERAaMNXIiIjIJ7LVORERkwIx1iFY2rRMRERkw1siJiMgkGGlfNyZyIiIyEUaayZnIiYjIJBhrZzdeIyciIjJgrJETEZFJEEHDXutai0S7mMiJiMgkGOklcjatExERGTLWyImIyCQY64AwTORERGQijLNxnU3rREREBow1ciIiMglsWiciIjJgxtmwzqZ1IiIig8YaORERmQQ2rRMRERkwYx1rnYmciIhMg5FeJOc1ciIiIgPGGjkREZkEI62QM5ETEZFpMNbObmxaJyIiMmCskRMRkUlgr3UiIiJDZqQXydm0TkREZMBYIyciIpNgpBVyJnIiIjIN7LVOREREeoc1ciIiMhGa9VrX18Z1JnIiIjIJbFonIiIivcNETkREZMDYtE5ERCbBWJvWmciJiMgkGOsQrWxaJyIiMmCskRMRkUlg0zoREZEBM9YhWtm0TkREZMBYIyciItNgpFVyJnIiIjIJ7LVOREREeoc1ciIiMgnstU5ERGTAjPQSOZvWiYjIRIi0MD2D6OhoeHt7QyqVomPHjjhx4oRmx/EIJnIiIqIasnXrVkRGRmL27Nk4ffo02rRpg5CQEGRnZ2ttH0zkRERkEkRa+KeuRYsWYdy4cQgPD4e/vz9WrlwJa2trrF27VmvHxUROREQmoaqzmyaTOsrKypCQkIDg4GB5mVgsRnBwMOLj47V2XAbd2U0QBABARUmxjiOh2iA25+9OU1JQUKDrEKgWFP53nqu+z2uSpp+pqvUf3Y5EIoFEIlFa/s6dO6isrISrq6tCuaurKy5fvqxRLA8z6EReWFgIAPh71mDdBkJEWucaqesIqDYVFhbCwcGhRrZtaWkJNzc3NPXx0Hhbtra28PBQ3M7s2bMxZ84cjbf9rAw6kbu7uyMtLQ12dnYQ6esNfjWgoKAAHh4eSEtLg729va7DoRrEc206TPVcC4KAwsJCuLu719g+pFIpUlNTUVZWpvG2BEFQyjfV1cYBoG7dujAzM0NWVpZCeVZWFtzc3DSOpYpBJ3KxWIyGDRvqOgydsbe3N6k/eFPGc206TPFc11RN/GFSqRRSqbTG9/MwS0tLBAQEYP/+/Rg8eDAAQCaTYf/+/ZgwYYLW9mPQiZyIiEifRUZGIiwsDM8//zw6dOiAJUuWoLi4GOHh4VrbBxM5ERFRDXn11Vdx+/ZtzJo1C5mZmWjbti3++OMPpQ5wmmAiN0ASiQSzZ89+7HUZMh4816aD59p4TZgwQatN6Y8SCbXR55+IiIhqBG/MJSIiMmBM5ERERAaMiZyIiMiAMZETEREZMCZyA1PTz7Ul/XDo0CEMHDgQ7u7uEIlE2L17t65DohoSFRWF9u3bw87ODvXq1cPgwYORlJSk67DIgDCRG5DaeK4t6Yfi4mK0adMG0dHRug6FalhcXBwiIiJw7NgxxMTEoLy8HH369EFxMR8GRarh7WcGpGPHjmjfvj2WLVsG4MFQfx4eHpg4cSKmT5+u4+iopohEIuzatUs+xCMZt9u3b6NevXqIi4tDt27ddB0OGQDWyA1EbT3Xloh0Kz8/HwDg5OSk40jIUDCRG4gnPdc2MzNTR1ERkTbJZDJMnjwZnTt3RsuWLXUdDhkIDtFKRKQnIiIicP78eRw5ckTXoZABYSI3ELX1XFsi0o0JEyZg7969OHTokEk/npnUx6Z1A/Hwc22rVD3XNjAwUIeREZEmBEHAhAkTsGvXLsTGxsLHx0fXIZGBYY3cgNTGc21JPxQVFSE5OVn+OjU1FYmJiXBycoKnp6cOIyNti4iIwObNm/Hzzz/Dzs5O3ufFwcEBVlZWOo6ODAFvPzMwy5YtwxdffCF/ru3SpUvRsWNHXYdFWnbw4EH06NFDqTwsLAzr16+v/YCoxohEomrL161bh9GjR9duMGSQmMiJiIgMGK+RExERGTAmciIiIgPGRE5ERGTAmMiJiIgMGBM5ERGRAWMiJyIiMmBM5ERERAaMiZxIQ6NHj1Z4VnhQUBAmT55c63EcPHgQIpEIeXl5j11GJBJh9+7dKm9zzpw5aNu2rUZxXb9+HSKRCImJiRpth4iqx0RORmn06NEQiUQQiUSwtLREkyZNMG/ePFRUVNT4vn/66SfMnz9fpWVVSb5ERE/CsdbJaL344otYt24dSktL8dtvvyEiIgIWFhaYMWOG0rJlZWWwtLTUyn6dnJy0sh0iIlWwRk5GSyKRwM3NDV5eXnj33XcRHByMX375BcD/msMXLFgAd3d3+Pr6AgDS0tIwbNgwODo6wsnJCYMGDcL169fl26ysrERkZCQcHR3h7OyMDz/8EI+Ocvxo03ppaSmmTZsGDw8PSCQSNGnSBGvWrMH169fl46nXqVMHIpFIPra2TCZDVFQUfHx8YGVlhTZt2mDHjh0K+/ntt9/QrFkzWFlZoUePHgpxqmratGlo1qwZrK2t0ahRI8ycORPl5eVKy61atQoeHh6wtrbGsGHDkJ+frzB/9erV8PPzg1QqRfPmzbF8+XK1YyGiZ8NETibDysoKZWVl8tf79+9HUlISYmJisHfvXpSXlyMkJAR2dnY4fPgw/v77b9ja2uLFF1+Ur/fVV19h/fr1WLt2LY4cOYLc3Fzs2rXrift944038OOPP2Lp0qW4dOkSVq1aBVtbW3h4eGDnzp0AgKSkJGRkZODrr78GAERFRWHjxo1YuXIlLly4gClTpuC1115DXFwcgAc/OEJDQzFw4EAkJiZi7NixmD59utrviZ2dHdavX4+LFy/i66+/xnfffYfFixcrLJOcnIxt27Zhz549+OOPP3DmzBmMHz9ePv+HH37ArFmzsGDBAly6dAmffvopZs6ciQ0bNqgdDxE9A4HICIWFhQmDBg0SBEEQZDKZEBMTI0gkEmHq1Kny+a6urkJpaal8nU2bNgm+vr6CTCaTl5WWlgpWVlbCvn37BEEQhPr16wsLFy6Uzy8vLxcaNmwo35cgCEL37t2FSZMmCYIgCElJSQIAISYmpto4Dxw4IAAQ7t69Ky8rKSkRrK2thaNHjyosO2bMGGHEiBGCIAjCjBkzBH9/f4X506ZNU9rWowAIu3bteuz8L774QggICJC/nj17tmBmZibcunVLXvb7778LYrFYyMjIEARBEBo3bixs3rxZYTvz588XAgMDBUEQhNTUVAGAcObMmcful4ieHa+Rk9Hau3cvbG1tUV5eDplMhpEjR2LOnDny+a1atVK4Ln727FkkJyfDzs5OYTslJSVISUlBfn4+MjIyFB4ba25ujueff16peb1KYmIizMzM0L17d5XjTk5Oxr1799C7d2+F8rKyMjz33HMAgEuXLik9vjYwMFDlfVTZunUrli5dipSUFBQVFaGiogL29vYKy3h6eqJBgwYK+5HJZEhKSoKdnR1SUlIwZswYjBs3Tr5MRUUFHBwc1I6HiNTHRE5Gq0ePHlixYgUsLS3h7u4Oc3PFj7uNjY3C66KiIgQEBOCHH35Q2paLi8szxWBlZaX2OkVFRQCAX3/9VSGBAg+u+2tLfHw8Ro0ahblz5yIkJAQODg7YsmULvvrqK7Vj/e6775R+WJiZmWktViJ6PCZyMlo2NjZo0qSJysu3a9cOW7duRb169ZRqpVXq16+P48ePo1u3bgAe1DwTEhLQrl27apdv1aoVZDIZ4uLiEBwcrDS/qkWgsrJSXubv7w+JRIKbN28+tibv5+cn77hX5dixY08/yIccPXoUXl5e+Oijj+RlN27cUFru5s2bSE9Ph7u7u3w/YrEYvr6+cHV1hbu7O65du4ZRo0aptX8i0g52diP6z6hRo1C3bl0MGjQIhw8fRmpqKg4ePIj33nsPt27dAgBMmjQJn332GXbv3o3Lly9j/PjxT7wH3NvbG2FhYXjzzTexe/du+Ta3bdsGAPDy8oJIJMLevXtx+/ZtFBUVwc7ODlOnTsWUKVOwYcMGpKSk4PTp0/jmm2/kHcjeeecdXL16FR988AGSkpKwefNmrF+/Xq3jbdq0KW7evIktW7YgJSUFS5curbbjnlQqRVhYGM6ePYvDhw/jvffew7Bhw+Dm5gYAmDt3LqKiorB06VJcuXIF586dw7p167Bo0SK14iGiZ8NETvQfa2trHDp0CJ6enggNDYWfnx/GjBmDkpISeQ39/fffx+uvv46wsDAEBgbCzs4OL7/88hO3u2LFCgwdOhTjx49H8+bNMW7cOBQXFwMAGjRogLlz52L69OlwdXXFhAkTAADz58/HzJkzERUVBT8/P7z44ov49ddf4ePjA+DBdeudO3di9+7daNOmDVauXIlPP/1UreN96aWXMGXKFEyYMAFt27bF0aNHMXPmTKXlmjRpgtDQUPTr1w99+vRB69atFW4vGzt2LFavXo1169ahVatW6N69O9avXy+PlYhqlkh4XC8dIiIi0nuskRMRERkwJnIiIiIDxkRORERkwJjIiYiIDBgTORERkQFjIiciIjJgTOREREQGjImciIjIgDGRExERGTAmciIiIgPGRE5ERGTAmMiJiIgM2P8DDPRRNsiY+qwAAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R1_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r1_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dcpg8ygteAqE","executionInfo":{"status":"ok","timestamp":1733003387602,"user_tz":360,"elapsed":616848,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"7fe7481a-ba56-463a-d652-b2bc16b261a3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-30 21:39:34.125723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-30 21:39:34.139528: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-30 21:39:34.143515: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-30 21:39:34.153769: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-30 21:39:35.098772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","Generating test split: 2000 examples [00:00, 2237.93 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 3081.49 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:235: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7541.70 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7792.29 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:38<00:00,  1.28it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:38<00:00,  1.27it/s]\n","{'eval_loss': 2.541537046432495, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.271, 'eval_precision': 0.2715693645341348, 'eval_recall': 0.271, 'eval_f1': 0.26960047991675606, 'eval_runtime': 99.3713, 'eval_samples_per_second': 10.063, 'eval_steps_per_second': 1.258}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:36<00:00,  1.29it/s]\n","{'eval_loss': 2.3128268718719482, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.277, 'eval_precision': 0.2759054202532477, 'eval_recall': 0.277, 'eval_f1': 0.2754529913229174, 'eval_runtime': 97.6348, 'eval_samples_per_second': 10.242, 'eval_steps_per_second': 1.28}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:16<00:00,  1.27it/s]\n","{'eval_loss': 2.427182197570801, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.274, 'eval_precision': 0.2736779326923077, 'eval_recall': 0.274, 'eval_f1': 0.27254949145413354, 'eval_runtime': 197.3171, 'eval_samples_per_second': 10.136, 'eval_steps_per_second': 1.267}\n","100% 125/125 [01:36<00:00,  1.30it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r1_test/misclassified_English.jsonl\n","100% 125/125 [01:36<00:00,  1.29it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r1_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m:\n","\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/My Drive/nlp_final_project/wandb/offline-run-20241130_213941-2pw0ct13\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241130_213941-2pw0ct13/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","df_ru = pd.read_json('output_xnli_en_ru_bert_2_test/anli_r1_test/misclassified_Russian.jsonl', lines=True)\n","df_en = pd.read_json('output_xnli_en_ru_bert_2_test/anli_r1_test/misclassified_English.jsonl', lines=True)\n","print(df_en['true_label'].value_counts())\n","print(df_ru['true_label'].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VB97DKUjA7eG","executionInfo":{"status":"ok","timestamp":1733003387602,"user_tz":360,"elapsed":16,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"736c996f-8ed1-455f-9493-0eef6ad3a3ac"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["true_label\n","2    265\n","1    238\n","0    226\n","Name: count, dtype: int64\n","true_label\n","2    264\n","1    231\n","0    228\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","cm_ru = confusion_matrix(df_ru['true_label'], df_ru['predicted_label'])\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm_ru)\n","disp.plot(cmap=plt.cm.Blues)\n","plt.title('Confusion Matrix for Misclassified Russian Examples')\n","plt.show()\n","\n","cm_en = confusion_matrix(df_en['true_label'], df_en['predicted_label'])\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm_en)\n","disp.plot(cmap=plt.cm.Blues)\n","plt.title('Confusion Matrix for Misclassified English Examples')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":927},"id":"MZuc8OPIB-pL","executionInfo":{"status":"ok","timestamp":1733003388416,"user_tz":360,"elapsed":821,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"0d94c5dd-9e14-453c-9d8f-89c668bc5581"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R2_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r2_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nYWUklpvCAnB","executionInfo":{"status":"ok","timestamp":1733004146484,"user_tz":360,"elapsed":668149,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"4bb98c4a-caec-469a-a5d0-b8a924e49783"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-30 21:51:21.893965: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-30 21:51:21.907679: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-30 21:51:21.911724: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-30 21:51:21.921515: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-30 21:51:22.880199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","Generating test split: 2000 examples [00:00, 2412.18 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 3118.49 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:235: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7171.83 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7641.78 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:38<00:00,  1.30it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:38<00:00,  1.27it/s]\n","{'eval_loss': 2.3473029136657715, 'eval_model_preparation_time': 0.0031, 'eval_accuracy': 0.323, 'eval_precision': 0.3231628236245954, 'eval_recall': 0.323, 'eval_f1': 0.3228476983494107, 'eval_runtime': 99.4692, 'eval_samples_per_second': 10.053, 'eval_steps_per_second': 1.257}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:35<00:00,  1.31it/s]\n","{'eval_loss': 2.095353126525879, 'eval_model_preparation_time': 0.0031, 'eval_accuracy': 0.328, 'eval_precision': 0.32825731804203667, 'eval_recall': 0.328, 'eval_f1': 0.3280788008863872, 'eval_runtime': 96.3196, 'eval_samples_per_second': 10.382, 'eval_steps_per_second': 1.298}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:13<00:00,  1.29it/s]\n","{'eval_loss': 2.221328020095825, 'eval_model_preparation_time': 0.0031, 'eval_accuracy': 0.3255, 'eval_precision': 0.325739035884919, 'eval_recall': 0.3255, 'eval_f1': 0.3255243059980868, 'eval_runtime': 194.4853, 'eval_samples_per_second': 10.284, 'eval_steps_per_second': 1.285}\n","100% 125/125 [01:36<00:00,  1.29it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r2_test/misclassified_English.jsonl\n","100% 125/125 [01:36<00:00,  1.30it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r2_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m:\n","\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/nlp_final_project/wandb/offline-run-20241130_215225-llpc6u9x\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241130_215225-llpc6u9x/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","df_ru = pd.read_json('output_xnli_en_ru_bert_2_test/anli_r2_test/misclassified_Russian.jsonl', lines=True)\n","df_en = pd.read_json('output_xnli_en_ru_bert_2_test/anli_r2_test/misclassified_English.jsonl', lines=True)\n","print(df_en['true_label'].value_counts())\n","print(df_ru['true_label'].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWqFbP-tDoQw","executionInfo":{"status":"ok","timestamp":1733004146485,"user_tz":360,"elapsed":37,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"642a645e-a05c-4ccd-cd5f-90d0728eba54"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["true_label\n","2    233\n","1    223\n","0    221\n","Name: count, dtype: int64\n","true_label\n","1    225\n","0    224\n","2    223\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","cm_ru = confusion_matrix(df_ru['true_label'], df_ru['predicted_label'])\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm_ru)\n","disp.plot(cmap=plt.cm.Blues)\n","plt.title('Confusion Matrix for Misclassified Russian Examples')\n","plt.show()\n","\n","cm_en = confusion_matrix(df_en['true_label'], df_en['predicted_label'])\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm_en)\n","disp.plot(cmap=plt.cm.Blues)\n","plt.title('Confusion Matrix for Misclassified English Examples')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":927},"id":"kQXLz0YoD-WM","executionInfo":{"status":"ok","timestamp":1733004146777,"user_tz":360,"elapsed":299,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"07a0d7af-2b7c-4d32-c755-9f4a53e9d1fa"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["df_ru.to_csv('output_xnli_en_ru_bert_2_test/anli_r2_test/misclassified_Russian.csv', index=False)\n","df_en.to_csv('output_xnli_en_ru_bert_2_test/anli_r2_test/misclassified_English.csv', index=False)"],"metadata":{"id":"eDcS9WwBFPtR","executionInfo":{"status":"ok","timestamp":1733005211183,"user_tz":360,"elapsed":3,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset negation_examples_combined.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_anli_en_ru_bert_2/negation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5wVA0zUPJTUq","executionInfo":{"status":"ok","timestamp":1733161424055,"user_tz":360,"elapsed":393382,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"717eb143-7615-4192-d396-c8920ed0a577"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 17:37:20.865694: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-02 17:37:20.882806: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 17:37:20.905108: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 17:37:20.911712: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 17:37:20.927810: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 17:37:22.222869: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241202_173748-j5uuodqa\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-nagation-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/j5uuodqa\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 6552 examples [00:00, 10476.61 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language']\n","Map (num_proc=2): 100% 6552/6552 [00:02<00:00, 2828.67 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language']\n","/content/drive/MyDrive/nlp_final_project/run.py:325: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.6814, 'grad_norm': 7.800747394561768, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 410/2050 [00:40<02:34, 10.63it/s]\n","  0% 0/819 [00:00<?, ?it/s]\u001b[A\n","  1% 7/819 [00:00<00:11, 68.34it/s]\u001b[A\n","  2% 14/819 [00:00<00:12, 62.46it/s]\u001b[A\n","  3% 21/819 [00:00<00:13, 60.67it/s]\u001b[A\n","  3% 28/819 [00:00<00:13, 59.24it/s]\u001b[A\n","  4% 34/819 [00:00<00:13, 59.04it/s]\u001b[A\n","  5% 40/819 [00:00<00:13, 58.76it/s]\u001b[A\n","  6% 46/819 [00:00<00:13, 58.46it/s]\u001b[A\n","  6% 52/819 [00:00<00:13, 58.23it/s]\u001b[A\n","  7% 58/819 [00:00<00:13, 58.11it/s]\u001b[A\n","  8% 64/819 [00:01<00:12, 58.25it/s]\u001b[A\n","  9% 70/819 [00:01<00:12, 58.13it/s]\u001b[A\n","  9% 76/819 [00:01<00:12, 58.03it/s]\u001b[A\n"," 10% 82/819 [00:01<00:12, 58.09it/s]\u001b[A\n"," 11% 88/819 [00:01<00:12, 58.33it/s]\u001b[A\n"," 11% 94/819 [00:01<00:12, 58.49it/s]\u001b[A\n"," 12% 100/819 [00:01<00:12, 58.72it/s]\u001b[A\n"," 13% 106/819 [00:01<00:12, 59.01it/s]\u001b[A\n"," 14% 112/819 [00:01<00:11, 58.93it/s]\u001b[A\n"," 14% 118/819 [00:02<00:11, 58.94it/s]\u001b[A\n"," 15% 124/819 [00:02<00:11, 58.75it/s]\u001b[A\n"," 16% 130/819 [00:02<00:11, 58.76it/s]\u001b[A\n"," 17% 136/819 [00:02<00:11, 58.79it/s]\u001b[A\n"," 17% 142/819 [00:02<00:11, 58.84it/s]\u001b[A\n"," 18% 148/819 [00:02<00:11, 58.84it/s]\u001b[A\n"," 19% 155/819 [00:02<00:11, 59.28it/s]\u001b[A\n"," 20% 161/819 [00:02<00:11, 59.08it/s]\u001b[A\n"," 20% 167/819 [00:02<00:11, 58.97it/s]\u001b[A\n"," 21% 173/819 [00:02<00:11, 58.46it/s]\u001b[A\n"," 22% 179/819 [00:03<00:11, 57.96it/s]\u001b[A\n"," 23% 185/819 [00:03<00:10, 58.22it/s]\u001b[A\n"," 23% 191/819 [00:03<00:10, 58.01it/s]\u001b[A\n"," 24% 197/819 [00:03<00:10, 57.88it/s]\u001b[A\n"," 25% 203/819 [00:03<00:10, 58.18it/s]\u001b[A\n"," 26% 209/819 [00:03<00:10, 57.75it/s]\u001b[A\n"," 26% 215/819 [00:03<00:10, 57.88it/s]\u001b[A\n"," 27% 221/819 [00:03<00:10, 57.83it/s]\u001b[A\n"," 28% 227/819 [00:03<00:10, 57.81it/s]\u001b[A\n"," 28% 233/819 [00:03<00:10, 57.79it/s]\u001b[A\n"," 29% 239/819 [00:04<00:09, 58.05it/s]\u001b[A\n"," 30% 245/819 [00:04<00:09, 58.13it/s]\u001b[A\n"," 31% 251/819 [00:04<00:09, 58.13it/s]\u001b[A\n"," 31% 257/819 [00:04<00:09, 58.34it/s]\u001b[A\n"," 32% 263/819 [00:04<00:09, 58.71it/s]\u001b[A\n"," 33% 269/819 [00:04<00:09, 58.78it/s]\u001b[A\n"," 34% 275/819 [00:04<00:09, 58.46it/s]\u001b[A\n"," 34% 281/819 [00:04<00:09, 58.53it/s]\u001b[A\n"," 35% 288/819 [00:04<00:08, 59.08it/s]\u001b[A\n"," 36% 295/819 [00:05<00:08, 59.50it/s]\u001b[A\n"," 37% 302/819 [00:05<00:08, 59.68it/s]\u001b[A\n"," 38% 308/819 [00:05<00:08, 59.16it/s]\u001b[A\n"," 38% 314/819 [00:05<00:08, 57.82it/s]\u001b[A\n"," 39% 320/819 [00:05<00:08, 58.01it/s]\u001b[A\n"," 40% 326/819 [00:05<00:08, 57.80it/s]\u001b[A\n"," 41% 332/819 [00:05<00:08, 57.98it/s]\u001b[A\n"," 41% 338/819 [00:05<00:08, 58.41it/s]\u001b[A\n"," 42% 344/819 [00:05<00:08, 58.35it/s]\u001b[A\n"," 43% 350/819 [00:05<00:07, 58.79it/s]\u001b[A\n"," 44% 357/819 [00:06<00:07, 59.22it/s]\u001b[A\n"," 44% 363/819 [00:06<00:07, 59.41it/s]\u001b[A\n"," 45% 369/819 [00:06<00:07, 59.46it/s]\u001b[A\n"," 46% 375/819 [00:06<00:07, 59.30it/s]\u001b[A\n"," 47% 381/819 [00:06<00:07, 58.88it/s]\u001b[A\n"," 47% 387/819 [00:06<00:07, 58.38it/s]\u001b[A\n"," 48% 393/819 [00:06<00:07, 58.39it/s]\u001b[A\n"," 49% 399/819 [00:06<00:07, 58.04it/s]\u001b[A\n"," 49% 405/819 [00:06<00:07, 57.77it/s]\u001b[A\n"," 50% 411/819 [00:07<00:07, 57.73it/s]\u001b[A\n"," 51% 417/819 [00:07<00:06, 57.60it/s]\u001b[A\n"," 52% 423/819 [00:07<00:06, 57.95it/s]\u001b[A\n"," 52% 429/819 [00:07<00:06, 58.17it/s]\u001b[A\n"," 53% 435/819 [00:07<00:06, 58.29it/s]\u001b[A\n"," 54% 441/819 [00:07<00:06, 58.35it/s]\u001b[A\n"," 55% 447/819 [00:07<00:06, 57.87it/s]\u001b[A\n"," 55% 453/819 [00:07<00:06, 57.59it/s]\u001b[A\n"," 56% 459/819 [00:07<00:06, 57.59it/s]\u001b[A\n"," 57% 465/819 [00:07<00:06, 57.37it/s]\u001b[A\n"," 58% 471/819 [00:08<00:06, 56.54it/s]\u001b[A\n"," 58% 477/819 [00:08<00:06, 56.64it/s]\u001b[A\n"," 59% 483/819 [00:08<00:05, 57.07it/s]\u001b[A\n"," 60% 489/819 [00:08<00:05, 57.18it/s]\u001b[A\n"," 60% 495/819 [00:08<00:05, 57.37it/s]\u001b[A\n"," 61% 501/819 [00:08<00:05, 56.34it/s]\u001b[A\n"," 62% 507/819 [00:08<00:05, 56.37it/s]\u001b[A\n"," 63% 513/819 [00:08<00:05, 56.88it/s]\u001b[A\n"," 63% 519/819 [00:08<00:05, 57.46it/s]\u001b[A\n"," 64% 525/819 [00:09<00:05, 57.59it/s]\u001b[A\n"," 65% 531/819 [00:09<00:04, 57.77it/s]\u001b[A\n"," 66% 537/819 [00:09<00:04, 57.97it/s]\u001b[A\n"," 66% 543/819 [00:09<00:04, 58.24it/s]\u001b[A\n"," 67% 549/819 [00:09<00:04, 58.34it/s]\u001b[A\n"," 68% 556/819 [00:09<00:04, 58.96it/s]\u001b[A\n"," 69% 562/819 [00:09<00:04, 58.89it/s]\u001b[A\n"," 69% 568/819 [00:09<00:04, 58.83it/s]\u001b[A\n"," 70% 574/819 [00:09<00:04, 58.83it/s]\u001b[A\n"," 71% 580/819 [00:09<00:04, 58.73it/s]\u001b[A\n"," 72% 586/819 [00:10<00:03, 58.65it/s]\u001b[A\n"," 72% 592/819 [00:10<00:03, 58.25it/s]\u001b[A\n"," 73% 598/819 [00:10<00:03, 58.20it/s]\u001b[A\n"," 74% 604/819 [00:10<00:03, 58.27it/s]\u001b[A\n"," 74% 610/819 [00:10<00:03, 58.36it/s]\u001b[A\n"," 75% 616/819 [00:10<00:03, 58.41it/s]\u001b[A\n"," 76% 622/819 [00:10<00:03, 57.91it/s]\u001b[A\n"," 77% 628/819 [00:10<00:03, 58.01it/s]\u001b[A\n"," 77% 634/819 [00:10<00:03, 57.89it/s]\u001b[A\n"," 78% 640/819 [00:10<00:03, 57.83it/s]\u001b[A\n"," 79% 646/819 [00:11<00:02, 57.84it/s]\u001b[A\n"," 80% 652/819 [00:11<00:02, 57.88it/s]\u001b[A\n"," 80% 658/819 [00:11<00:02, 57.73it/s]\u001b[A\n"," 81% 664/819 [00:11<00:02, 57.89it/s]\u001b[A\n"," 82% 670/819 [00:11<00:02, 57.66it/s]\u001b[A\n"," 83% 676/819 [00:11<00:02, 57.55it/s]\u001b[A\n"," 83% 682/819 [00:11<00:02, 57.83it/s]\u001b[A\n"," 84% 688/819 [00:11<00:02, 58.01it/s]\u001b[A\n"," 85% 694/819 [00:11<00:02, 58.20it/s]\u001b[A\n"," 85% 700/819 [00:12<00:02, 58.39it/s]\u001b[A\n"," 86% 706/819 [00:12<00:01, 58.49it/s]\u001b[A\n"," 87% 712/819 [00:12<00:01, 58.62it/s]\u001b[A\n"," 88% 719/819 [00:12<00:01, 59.23it/s]\u001b[A\n"," 89% 726/819 [00:12<00:01, 59.55it/s]\u001b[A\n"," 89% 733/819 [00:12<00:01, 59.80it/s]\u001b[A\n"," 90% 739/819 [00:12<00:01, 59.81it/s]\u001b[A\n"," 91% 745/819 [00:12<00:01, 50.70it/s]\u001b[A\n"," 92% 751/819 [00:12<00:01, 52.82it/s]\u001b[A\n"," 93% 758/819 [00:13<00:01, 55.01it/s]\u001b[A\n"," 93% 764/819 [00:13<00:00, 56.21it/s]\u001b[A\n"," 94% 770/819 [00:13<00:00, 56.95it/s]\u001b[A\n"," 95% 777/819 [00:13<00:00, 57.97it/s]\u001b[A\n"," 96% 784/819 [00:13<00:00, 58.65it/s]\u001b[A\n"," 97% 791/819 [00:13<00:00, 59.09it/s]\u001b[A\n"," 97% 797/819 [00:13<00:00, 59.30it/s]\u001b[A\n"," 98% 803/819 [00:13<00:00, 59.28it/s]\u001b[A\n"," 99% 809/819 [00:13<00:00, 59.04it/s]\u001b[A\n","                                      \n","\u001b[A{'eval_loss': 0.3343295753002167, 'eval_accuracy': 0.8898046398046398, 'eval_precision': 0.8918420468376754, 'eval_recall': 0.8898046398046398, 'eval_f1': 0.8901744000631193, 'eval_runtime': 14.1113, 'eval_samples_per_second': 464.309, 'eval_steps_per_second': 58.039, 'epoch': 1.0}\n"," 20% 410/2050 [00:54<02:34, 10.63it/s]\n","100% 819/819 [00:14<00:00, 58.75it/s]\u001b[A\n","{'loss': 0.3415, 'grad_norm': 28.899391174316406, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 820/2050 [01:42<01:48, 11.32it/s]\n","  0% 0/819 [00:00<?, ?it/s]\u001b[A\n","  1% 7/819 [00:00<00:11, 68.42it/s]\u001b[A\n","  2% 14/819 [00:00<00:12, 62.65it/s]\u001b[A\n","  3% 21/819 [00:00<00:13, 60.97it/s]\u001b[A\n","  3% 28/819 [00:00<00:13, 59.89it/s]\u001b[A\n","  4% 35/819 [00:00<00:13, 59.68it/s]\u001b[A\n","  5% 41/819 [00:00<00:13, 59.25it/s]\u001b[A\n","  6% 47/819 [00:00<00:12, 59.40it/s]\u001b[A\n","  7% 54/819 [00:00<00:12, 59.68it/s]\u001b[A\n","  7% 61/819 [00:01<00:12, 59.93it/s]\u001b[A\n","  8% 67/819 [00:01<00:12, 59.72it/s]\u001b[A\n","  9% 74/819 [00:01<00:12, 59.90it/s]\u001b[A\n"," 10% 81/819 [00:01<00:12, 60.06it/s]\u001b[A\n"," 11% 88/819 [00:01<00:12, 59.91it/s]\u001b[A\n"," 11% 94/819 [00:01<00:12, 59.89it/s]\u001b[A\n"," 12% 100/819 [00:01<00:12, 59.73it/s]\u001b[A\n"," 13% 106/819 [00:01<00:11, 59.63it/s]\u001b[A\n"," 14% 112/819 [00:01<00:11, 59.60it/s]\u001b[A\n"," 14% 118/819 [00:01<00:11, 59.68it/s]\u001b[A\n"," 15% 124/819 [00:02<00:11, 59.51it/s]\u001b[A\n"," 16% 130/819 [00:02<00:11, 59.47it/s]\u001b[A\n"," 17% 136/819 [00:02<00:11, 59.35it/s]\u001b[A\n"," 17% 142/819 [00:02<00:11, 59.30it/s]\u001b[A\n"," 18% 148/819 [00:02<00:11, 59.42it/s]\u001b[A\n"," 19% 154/819 [00:02<00:11, 59.42it/s]\u001b[A\n"," 20% 160/819 [00:02<00:11, 59.22it/s]\u001b[A\n"," 20% 166/819 [00:02<00:11, 59.01it/s]\u001b[A\n"," 21% 172/819 [00:02<00:10, 58.93it/s]\u001b[A\n"," 22% 178/819 [00:02<00:10, 58.88it/s]\u001b[A\n"," 22% 184/819 [00:03<00:10, 59.21it/s]\u001b[A\n"," 23% 191/819 [00:03<00:10, 59.66it/s]\u001b[A\n"," 24% 198/819 [00:03<00:10, 59.95it/s]\u001b[A\n"," 25% 205/819 [00:03<00:10, 60.15it/s]\u001b[A\n"," 26% 212/819 [00:03<00:10, 60.20it/s]\u001b[A\n"," 27% 219/819 [00:03<00:09, 60.28it/s]\u001b[A\n"," 28% 226/819 [00:03<00:09, 60.40it/s]\u001b[A\n"," 28% 233/819 [00:03<00:09, 60.40it/s]\u001b[A\n"," 29% 240/819 [00:04<00:09, 60.40it/s]\u001b[A\n"," 30% 247/819 [00:04<00:09, 60.26it/s]\u001b[A\n"," 31% 254/819 [00:04<00:09, 60.14it/s]\u001b[A\n"," 32% 261/819 [00:04<00:09, 60.08it/s]\u001b[A\n"," 33% 268/819 [00:04<00:09, 60.11it/s]\u001b[A\n"," 34% 275/819 [00:04<00:09, 60.28it/s]\u001b[A\n"," 34% 282/819 [00:04<00:08, 60.01it/s]\u001b[A\n"," 35% 289/819 [00:04<00:08, 59.97it/s]\u001b[A\n"," 36% 295/819 [00:04<00:08, 59.63it/s]\u001b[A\n"," 37% 301/819 [00:05<00:08, 59.40it/s]\u001b[A\n"," 37% 307/819 [00:05<00:08, 59.46it/s]\u001b[A\n"," 38% 313/819 [00:05<00:08, 59.60it/s]\u001b[A\n"," 39% 319/819 [00:05<00:08, 59.58it/s]\u001b[A\n"," 40% 325/819 [00:05<00:08, 59.45it/s]\u001b[A\n"," 40% 331/819 [00:05<00:08, 59.37it/s]\u001b[A\n"," 41% 337/819 [00:05<00:08, 59.33it/s]\u001b[A\n"," 42% 344/819 [00:05<00:07, 59.59it/s]\u001b[A\n"," 43% 351/819 [00:05<00:07, 59.75it/s]\u001b[A\n"," 44% 357/819 [00:05<00:07, 59.77it/s]\u001b[A\n"," 44% 363/819 [00:06<00:07, 59.42it/s]\u001b[A\n"," 45% 369/819 [00:06<00:07, 59.21it/s]\u001b[A\n"," 46% 375/819 [00:06<00:07, 58.89it/s]\u001b[A\n"," 47% 381/819 [00:06<00:07, 58.89it/s]\u001b[A\n"," 47% 387/819 [00:06<00:07, 58.75it/s]\u001b[A\n"," 48% 393/819 [00:06<00:07, 58.87it/s]\u001b[A\n"," 49% 399/819 [00:06<00:07, 59.14it/s]\u001b[A\n"," 49% 405/819 [00:06<00:07, 59.13it/s]\u001b[A\n"," 50% 411/819 [00:06<00:06, 59.18it/s]\u001b[A\n"," 51% 417/819 [00:06<00:06, 59.41it/s]\u001b[A\n"," 52% 423/819 [00:07<00:06, 59.22it/s]\u001b[A\n"," 52% 429/819 [00:07<00:06, 58.97it/s]\u001b[A\n"," 53% 435/819 [00:07<00:06, 59.25it/s]\u001b[A\n"," 54% 441/819 [00:07<00:06, 58.83it/s]\u001b[A\n"," 55% 447/819 [00:07<00:06, 58.85it/s]\u001b[A\n"," 55% 453/819 [00:07<00:06, 59.02it/s]\u001b[A\n"," 56% 459/819 [00:07<00:06, 59.25it/s]\u001b[A\n"," 57% 465/819 [00:07<00:05, 59.16it/s]\u001b[A\n"," 58% 471/819 [00:07<00:05, 59.29it/s]\u001b[A\n"," 58% 477/819 [00:08<00:05, 59.46it/s]\u001b[A\n"," 59% 483/819 [00:08<00:05, 59.29it/s]\u001b[A\n"," 60% 489/819 [00:08<00:05, 59.43it/s]\u001b[A\n"," 60% 495/819 [00:08<00:05, 59.52it/s]\u001b[A\n"," 61% 501/819 [00:08<00:05, 59.53it/s]\u001b[A\n"," 62% 507/819 [00:08<00:05, 58.95it/s]\u001b[A\n"," 63% 513/819 [00:08<00:05, 58.25it/s]\u001b[A\n"," 63% 519/819 [00:08<00:05, 57.97it/s]\u001b[A\n"," 64% 525/819 [00:08<00:05, 57.50it/s]\u001b[A\n"," 65% 531/819 [00:08<00:05, 57.25it/s]\u001b[A\n"," 66% 537/819 [00:09<00:04, 57.31it/s]\u001b[A\n"," 66% 543/819 [00:09<00:04, 57.26it/s]\u001b[A\n"," 67% 549/819 [00:09<00:04, 57.39it/s]\u001b[A\n"," 68% 555/819 [00:09<00:04, 57.26it/s]\u001b[A\n"," 68% 561/819 [00:09<00:04, 57.12it/s]\u001b[A\n"," 69% 567/819 [00:09<00:04, 56.93it/s]\u001b[A\n"," 70% 573/819 [00:09<00:04, 56.89it/s]\u001b[A\n"," 71% 579/819 [00:09<00:04, 56.92it/s]\u001b[A\n"," 71% 585/819 [00:09<00:04, 56.93it/s]\u001b[A\n"," 72% 591/819 [00:09<00:04, 56.97it/s]\u001b[A\n"," 73% 597/819 [00:10<00:03, 57.00it/s]\u001b[A\n"," 74% 603/819 [00:10<00:03, 56.97it/s]\u001b[A\n"," 74% 609/819 [00:10<00:03, 57.55it/s]\u001b[A\n"," 75% 615/819 [00:10<00:03, 57.93it/s]\u001b[A\n"," 76% 621/819 [00:10<00:03, 57.76it/s]\u001b[A\n"," 77% 627/819 [00:10<00:03, 58.01it/s]\u001b[A\n"," 77% 633/819 [00:10<00:03, 58.13it/s]\u001b[A\n"," 78% 639/819 [00:10<00:03, 58.03it/s]\u001b[A\n"," 79% 645/819 [00:10<00:02, 58.18it/s]\u001b[A\n"," 79% 651/819 [00:11<00:02, 58.38it/s]\u001b[A\n"," 80% 657/819 [00:11<00:02, 58.45it/s]\u001b[A\n"," 81% 663/819 [00:11<00:02, 58.47it/s]\u001b[A\n"," 82% 669/819 [00:11<00:02, 58.09it/s]\u001b[A\n"," 82% 675/819 [00:11<00:02, 57.65it/s]\u001b[A\n"," 83% 681/819 [00:11<00:02, 58.00it/s]\u001b[A\n"," 84% 687/819 [00:11<00:02, 57.56it/s]\u001b[A\n"," 85% 693/819 [00:11<00:02, 57.43it/s]\u001b[A\n"," 85% 699/819 [00:11<00:02, 57.12it/s]\u001b[A\n"," 86% 705/819 [00:11<00:01, 57.30it/s]\u001b[A\n"," 87% 711/819 [00:12<00:01, 57.71it/s]\u001b[A\n"," 88% 717/819 [00:12<00:02, 47.38it/s]\u001b[A\n"," 88% 723/819 [00:12<00:01, 50.18it/s]\u001b[A\n"," 89% 729/819 [00:12<00:01, 52.50it/s]\u001b[A\n"," 90% 735/819 [00:12<00:01, 54.13it/s]\u001b[A\n"," 90% 741/819 [00:12<00:01, 55.16it/s]\u001b[A\n"," 91% 747/819 [00:12<00:01, 56.34it/s]\u001b[A\n"," 92% 753/819 [00:12<00:01, 57.21it/s]\u001b[A\n"," 93% 759/819 [00:12<00:01, 57.91it/s]\u001b[A\n"," 93% 765/819 [00:13<00:00, 58.35it/s]\u001b[A\n"," 94% 771/819 [00:13<00:00, 58.66it/s]\u001b[A\n"," 95% 777/819 [00:13<00:00, 59.02it/s]\u001b[A\n"," 96% 784/819 [00:13<00:00, 59.45it/s]\u001b[A\n"," 97% 791/819 [00:13<00:00, 59.70it/s]\u001b[A\n"," 97% 798/819 [00:13<00:00, 59.85it/s]\u001b[A\n"," 98% 805/819 [00:13<00:00, 60.01it/s]\u001b[A\n"," 99% 812/819 [00:13<00:00, 59.86it/s]\u001b[A\n","                                      \n","\u001b[A{'eval_loss': 0.12307537347078323, 'eval_accuracy': 0.9658119658119658, 'eval_precision': 0.9662387607642824, 'eval_recall': 0.9658119658119658, 'eval_f1': 0.9658927899737274, 'eval_runtime': 13.9786, 'eval_samples_per_second': 468.715, 'eval_steps_per_second': 58.589, 'epoch': 2.0}\n"," 40% 820/2050 [01:56<01:48, 11.32it/s]\n","100% 819/819 [00:13<00:00, 59.68it/s]\u001b[A\n","{'loss': 0.1965, 'grad_norm': 102.90592193603516, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 1230/2050 [02:41<01:12, 11.26it/s]\n","  0% 0/819 [00:00<?, ?it/s]\u001b[A\n","  1% 8/819 [00:00<00:11, 68.67it/s]\u001b[A\n","  2% 15/819 [00:00<00:12, 63.83it/s]\u001b[A\n","  3% 22/819 [00:00<00:12, 62.27it/s]\u001b[A\n","  4% 29/819 [00:00<00:12, 61.65it/s]\u001b[A\n","  4% 36/819 [00:00<00:12, 61.24it/s]\u001b[A\n","  5% 43/819 [00:00<00:12, 61.07it/s]\u001b[A\n","  6% 50/819 [00:00<00:12, 60.94it/s]\u001b[A\n","  7% 57/819 [00:00<00:12, 60.80it/s]\u001b[A\n","  8% 64/819 [00:01<00:12, 60.72it/s]\u001b[A\n","  9% 71/819 [00:01<00:12, 60.63it/s]\u001b[A\n"," 10% 78/819 [00:01<00:12, 60.29it/s]\u001b[A\n"," 10% 85/819 [00:01<00:12, 59.68it/s]\u001b[A\n"," 11% 91/819 [00:01<00:12, 59.31it/s]\u001b[A\n"," 12% 97/819 [00:01<00:12, 59.46it/s]\u001b[A\n"," 13% 104/819 [00:01<00:11, 59.70it/s]\u001b[A\n"," 13% 110/819 [00:01<00:11, 59.74it/s]\u001b[A\n"," 14% 117/819 [00:01<00:11, 59.92it/s]\u001b[A\n"," 15% 124/819 [00:02<00:11, 60.00it/s]\u001b[A\n"," 16% 130/819 [00:02<00:11, 59.96it/s]\u001b[A\n"," 17% 137/819 [00:02<00:11, 59.99it/s]\u001b[A\n"," 18% 144/819 [00:02<00:11, 60.06it/s]\u001b[A\n"," 18% 151/819 [00:02<00:11, 59.80it/s]\u001b[A\n"," 19% 157/819 [00:02<00:11, 59.52it/s]\u001b[A\n"," 20% 163/819 [00:02<00:11, 59.61it/s]\u001b[A\n"," 21% 170/819 [00:02<00:10, 59.85it/s]\u001b[A\n"," 22% 177/819 [00:02<00:10, 60.01it/s]\u001b[A\n"," 22% 184/819 [00:03<00:10, 60.12it/s]\u001b[A\n"," 23% 191/819 [00:03<00:10, 59.84it/s]\u001b[A\n"," 24% 197/819 [00:03<00:10, 59.64it/s]\u001b[A\n"," 25% 203/819 [00:03<00:10, 59.51it/s]\u001b[A\n"," 26% 209/819 [00:03<00:10, 59.20it/s]\u001b[A\n"," 26% 215/819 [00:03<00:10, 59.08it/s]\u001b[A\n"," 27% 221/819 [00:03<00:10, 58.71it/s]\u001b[A\n"," 28% 227/819 [00:03<00:10, 58.40it/s]\u001b[A\n"," 28% 233/819 [00:03<00:10, 58.51it/s]\u001b[A\n"," 29% 240/819 [00:04<00:09, 59.04it/s]\u001b[A\n"," 30% 247/819 [00:04<00:09, 59.42it/s]\u001b[A\n"," 31% 254/819 [00:04<00:09, 59.72it/s]\u001b[A\n"," 32% 261/819 [00:04<00:09, 60.03it/s]\u001b[A\n"," 33% 268/819 [00:04<00:09, 60.23it/s]\u001b[A\n"," 34% 275/819 [00:04<00:09, 60.11it/s]\u001b[A\n"," 34% 282/819 [00:04<00:08, 60.24it/s]\u001b[A\n"," 35% 289/819 [00:04<00:08, 60.25it/s]\u001b[A\n"," 36% 296/819 [00:04<00:08, 60.32it/s]\u001b[A\n"," 37% 303/819 [00:05<00:08, 60.36it/s]\u001b[A\n"," 38% 310/819 [00:05<00:08, 60.38it/s]\u001b[A\n"," 39% 317/819 [00:05<00:08, 60.51it/s]\u001b[A\n"," 40% 324/819 [00:05<00:08, 60.57it/s]\u001b[A\n"," 40% 331/819 [00:05<00:08, 60.61it/s]\u001b[A\n"," 41% 338/819 [00:05<00:07, 60.58it/s]\u001b[A\n"," 42% 345/819 [00:05<00:07, 60.55it/s]\u001b[A\n"," 43% 352/819 [00:05<00:07, 60.53it/s]\u001b[A\n"," 44% 359/819 [00:05<00:07, 60.57it/s]\u001b[A\n"," 45% 366/819 [00:06<00:07, 60.46it/s]\u001b[A\n"," 46% 373/819 [00:06<00:07, 60.40it/s]\u001b[A\n"," 46% 380/819 [00:06<00:07, 60.46it/s]\u001b[A\n"," 47% 387/819 [00:06<00:07, 60.31it/s]\u001b[A\n"," 48% 394/819 [00:06<00:07, 60.19it/s]\u001b[A\n"," 49% 401/819 [00:06<00:06, 60.23it/s]\u001b[A\n"," 50% 408/819 [00:06<00:06, 60.16it/s]\u001b[A\n"," 51% 415/819 [00:06<00:06, 60.14it/s]\u001b[A\n"," 52% 422/819 [00:07<00:06, 60.03it/s]\u001b[A\n"," 52% 429/819 [00:07<00:06, 60.08it/s]\u001b[A\n"," 53% 436/819 [00:07<00:06, 60.08it/s]\u001b[A\n"," 54% 443/819 [00:07<00:06, 60.15it/s]\u001b[A\n"," 55% 450/819 [00:07<00:06, 59.98it/s]\u001b[A\n"," 56% 457/819 [00:07<00:06, 60.08it/s]\u001b[A\n"," 57% 464/819 [00:07<00:05, 59.57it/s]\u001b[A\n"," 57% 470/819 [00:07<00:05, 59.51it/s]\u001b[A\n"," 58% 476/819 [00:07<00:05, 59.45it/s]\u001b[A\n"," 59% 483/819 [00:08<00:05, 59.66it/s]\u001b[A\n"," 60% 489/819 [00:08<00:05, 59.75it/s]\u001b[A\n"," 61% 496/819 [00:08<00:05, 59.89it/s]\u001b[A\n"," 61% 502/819 [00:08<00:05, 59.90it/s]\u001b[A\n"," 62% 508/819 [00:08<00:05, 59.80it/s]\u001b[A\n"," 63% 514/819 [00:08<00:05, 59.83it/s]\u001b[A\n"," 64% 521/819 [00:08<00:04, 59.92it/s]\u001b[A\n"," 64% 528/819 [00:08<00:04, 59.99it/s]\u001b[A\n"," 65% 534/819 [00:08<00:04, 59.77it/s]\u001b[A\n"," 66% 540/819 [00:08<00:04, 59.37it/s]\u001b[A\n"," 67% 546/819 [00:09<00:04, 59.34it/s]\u001b[A\n"," 67% 552/819 [00:09<00:04, 58.78it/s]\u001b[A\n"," 68% 558/819 [00:09<00:04, 59.10it/s]\u001b[A\n"," 69% 564/819 [00:09<00:04, 58.98it/s]\u001b[A\n"," 70% 570/819 [00:09<00:04, 58.70it/s]\u001b[A\n"," 70% 577/819 [00:09<00:04, 59.13it/s]\u001b[A\n"," 71% 583/819 [00:09<00:04, 57.43it/s]\u001b[A\n"," 72% 589/819 [00:09<00:03, 57.75it/s]\u001b[A\n"," 73% 595/819 [00:09<00:03, 58.20it/s]\u001b[A\n"," 73% 601/819 [00:10<00:03, 58.44it/s]\u001b[A\n"," 74% 607/819 [00:10<00:03, 58.73it/s]\u001b[A\n"," 75% 613/819 [00:10<00:03, 58.75it/s]\u001b[A\n"," 76% 619/819 [00:10<00:03, 58.97it/s]\u001b[A\n"," 76% 625/819 [00:10<00:03, 58.76it/s]\u001b[A\n"," 77% 631/819 [00:10<00:03, 58.44it/s]\u001b[A\n"," 78% 637/819 [00:10<00:03, 58.49it/s]\u001b[A\n"," 79% 643/819 [00:10<00:03, 58.42it/s]\u001b[A\n"," 79% 649/819 [00:10<00:02, 58.39it/s]\u001b[A\n"," 80% 655/819 [00:10<00:02, 58.07it/s]\u001b[A\n"," 81% 661/819 [00:11<00:02, 57.83it/s]\u001b[A\n"," 81% 667/819 [00:11<00:02, 58.17it/s]\u001b[A\n"," 82% 673/819 [00:11<00:02, 58.58it/s]\u001b[A\n"," 83% 679/819 [00:11<00:02, 58.72it/s]\u001b[A\n"," 84% 685/819 [00:11<00:02, 59.01it/s]\u001b[A\n"," 84% 691/819 [00:11<00:02, 59.07it/s]\u001b[A\n"," 85% 697/819 [00:11<00:02, 58.68it/s]\u001b[A\n"," 86% 703/819 [00:11<00:01, 59.00it/s]\u001b[A\n"," 87% 710/819 [00:11<00:01, 59.50it/s]\u001b[A\n"," 88% 717/819 [00:12<00:01, 59.75it/s]\u001b[A\n"," 88% 723/819 [00:12<00:01, 59.67it/s]\u001b[A\n"," 89% 730/819 [00:12<00:01, 59.89it/s]\u001b[A\n"," 90% 737/819 [00:12<00:01, 60.07it/s]\u001b[A\n"," 91% 744/819 [00:12<00:01, 60.03it/s]\u001b[A\n"," 92% 751/819 [00:12<00:01, 60.09it/s]\u001b[A\n"," 93% 758/819 [00:12<00:01, 60.06it/s]\u001b[A\n"," 93% 765/819 [00:12<00:00, 60.22it/s]\u001b[A\n"," 94% 772/819 [00:12<00:00, 60.34it/s]\u001b[A\n"," 95% 779/819 [00:13<00:00, 60.07it/s]\u001b[A\n"," 96% 786/819 [00:13<00:00, 59.78it/s]\u001b[A\n"," 97% 793/819 [00:13<00:00, 59.88it/s]\u001b[A\n"," 98% 799/819 [00:13<00:00, 59.78it/s]\u001b[A\n"," 98% 805/819 [00:13<00:00, 59.58it/s]\u001b[A\n"," 99% 811/819 [00:13<00:00, 59.42it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 0.05578092485666275, 'eval_accuracy': 0.9851953601953602, 'eval_precision': 0.9852574199614689, 'eval_recall': 0.9851953601953602, 'eval_f1': 0.9852080541168562, 'eval_runtime': 13.7335, 'eval_samples_per_second': 477.08, 'eval_steps_per_second': 59.635, 'epoch': 3.0}\n"," 60% 1230/2050 [02:55<01:12, 11.26it/s]\n","100% 819/819 [00:13<00:00, 59.37it/s]\u001b[A\n","{'loss': 0.1129, 'grad_norm': 19.939228057861328, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 1640/2050 [03:40<00:36, 11.33it/s]\n","  0% 0/819 [00:00<?, ?it/s]\u001b[A\n","  1% 7/819 [00:00<00:11, 69.61it/s]\u001b[A\n","  2% 14/819 [00:00<00:12, 63.47it/s]\u001b[A\n","  3% 21/819 [00:00<00:12, 62.22it/s]\u001b[A\n","  3% 28/819 [00:00<00:12, 61.58it/s]\u001b[A\n","  4% 35/819 [00:00<00:12, 61.17it/s]\u001b[A\n","  5% 42/819 [00:00<00:12, 61.06it/s]\u001b[A\n","  6% 49/819 [00:00<00:12, 60.95it/s]\u001b[A\n","  7% 56/819 [00:00<00:12, 60.61it/s]\u001b[A\n","  8% 63/819 [00:01<00:12, 60.08it/s]\u001b[A\n","  9% 70/819 [00:01<00:12, 60.05it/s]\u001b[A\n","  9% 77/819 [00:01<00:12, 59.95it/s]\u001b[A\n"," 10% 84/819 [00:01<00:12, 60.11it/s]\u001b[A\n"," 11% 91/819 [00:01<00:12, 60.15it/s]\u001b[A\n"," 12% 98/819 [00:01<00:11, 60.13it/s]\u001b[A\n"," 13% 105/819 [00:01<00:11, 60.11it/s]\u001b[A\n"," 14% 112/819 [00:01<00:11, 60.14it/s]\u001b[A\n"," 15% 119/819 [00:01<00:11, 59.90it/s]\u001b[A\n"," 15% 125/819 [00:02<00:11, 59.86it/s]\u001b[A\n"," 16% 131/819 [00:02<00:11, 59.81it/s]\u001b[A\n"," 17% 137/819 [00:02<00:11, 59.76it/s]\u001b[A\n"," 17% 143/819 [00:02<00:11, 59.80it/s]\u001b[A\n"," 18% 149/819 [00:02<00:11, 59.78it/s]\u001b[A\n"," 19% 156/819 [00:02<00:11, 59.99it/s]\u001b[A\n"," 20% 162/819 [00:02<00:10, 59.93it/s]\u001b[A\n"," 21% 168/819 [00:02<00:10, 59.80it/s]\u001b[A\n"," 21% 174/819 [00:02<00:10, 59.69it/s]\u001b[A\n"," 22% 181/819 [00:03<00:10, 59.79it/s]\u001b[A\n"," 23% 187/819 [00:03<00:10, 59.44it/s]\u001b[A\n"," 24% 193/819 [00:03<00:10, 59.06it/s]\u001b[A\n"," 24% 199/819 [00:03<00:10, 59.28it/s]\u001b[A\n"," 25% 206/819 [00:03<00:10, 59.53it/s]\u001b[A\n"," 26% 212/819 [00:03<00:10, 59.55it/s]\u001b[A\n"," 27% 218/819 [00:03<00:10, 59.57it/s]\u001b[A\n"," 27% 224/819 [00:03<00:10, 59.31it/s]\u001b[A\n"," 28% 230/819 [00:03<00:10, 58.87it/s]\u001b[A\n"," 29% 236/819 [00:03<00:09, 58.53it/s]\u001b[A\n"," 30% 242/819 [00:04<00:09, 58.24it/s]\u001b[A\n"," 30% 248/819 [00:04<00:09, 58.12it/s]\u001b[A\n"," 31% 254/819 [00:04<00:09, 58.01it/s]\u001b[A\n"," 32% 261/819 [00:04<00:09, 58.78it/s]\u001b[A\n"," 33% 268/819 [00:04<00:09, 59.21it/s]\u001b[A\n"," 33% 274/819 [00:04<00:09, 59.22it/s]\u001b[A\n"," 34% 280/819 [00:04<00:09, 58.80it/s]\u001b[A\n"," 35% 286/819 [00:04<00:09, 58.60it/s]\u001b[A\n"," 36% 292/819 [00:04<00:09, 58.51it/s]\u001b[A\n"," 36% 298/819 [00:04<00:08, 58.54it/s]\u001b[A\n"," 37% 304/819 [00:05<00:08, 58.47it/s]\u001b[A\n"," 38% 310/819 [00:05<00:08, 58.36it/s]\u001b[A\n"," 39% 316/819 [00:05<00:08, 57.80it/s]\u001b[A\n"," 39% 322/819 [00:05<00:08, 57.92it/s]\u001b[A\n"," 40% 328/819 [00:05<00:08, 58.18it/s]\u001b[A\n"," 41% 334/819 [00:05<00:08, 58.22it/s]\u001b[A\n"," 42% 340/819 [00:05<00:08, 58.29it/s]\u001b[A\n"," 42% 346/819 [00:05<00:08, 58.45it/s]\u001b[A\n"," 43% 352/819 [00:05<00:07, 58.55it/s]\u001b[A\n"," 44% 358/819 [00:06<00:07, 58.39it/s]\u001b[A\n"," 44% 364/819 [00:06<00:07, 58.41it/s]\u001b[A\n"," 45% 370/819 [00:06<00:07, 58.31it/s]\u001b[A\n"," 46% 376/819 [00:06<00:07, 58.40it/s]\u001b[A\n"," 47% 382/819 [00:06<00:07, 58.59it/s]\u001b[A\n"," 47% 388/819 [00:06<00:07, 58.39it/s]\u001b[A\n"," 48% 394/819 [00:06<00:07, 58.40it/s]\u001b[A\n"," 49% 400/819 [00:06<00:07, 58.39it/s]\u001b[A\n"," 50% 406/819 [00:06<00:07, 58.46it/s]\u001b[A\n"," 50% 412/819 [00:06<00:06, 58.49it/s]\u001b[A\n"," 51% 418/819 [00:07<00:06, 58.42it/s]\u001b[A\n"," 52% 424/819 [00:07<00:06, 58.54it/s]\u001b[A\n"," 53% 430/819 [00:07<00:06, 58.50it/s]\u001b[A\n"," 53% 436/819 [00:07<00:06, 58.59it/s]\u001b[A\n"," 54% 442/819 [00:07<00:06, 58.01it/s]\u001b[A\n"," 55% 448/819 [00:07<00:06, 58.02it/s]\u001b[A\n"," 55% 454/819 [00:07<00:06, 58.14it/s]\u001b[A\n"," 56% 460/819 [00:07<00:06, 58.35it/s]\u001b[A\n"," 57% 466/819 [00:07<00:06, 58.47it/s]\u001b[A\n"," 58% 472/819 [00:07<00:05, 58.51it/s]\u001b[A\n"," 58% 478/819 [00:08<00:05, 58.53it/s]\u001b[A\n"," 59% 484/819 [00:08<00:05, 58.54it/s]\u001b[A\n"," 60% 490/819 [00:08<00:05, 58.59it/s]\u001b[A\n"," 61% 496/819 [00:08<00:05, 58.60it/s]\u001b[A\n"," 61% 503/819 [00:08<00:05, 59.12it/s]\u001b[A\n"," 62% 510/819 [00:08<00:05, 59.54it/s]\u001b[A\n"," 63% 517/819 [00:08<00:05, 59.88it/s]\u001b[A\n"," 64% 524/819 [00:08<00:04, 59.93it/s]\u001b[A\n"," 65% 530/819 [00:08<00:04, 59.75it/s]\u001b[A\n"," 65% 536/819 [00:09<00:04, 59.74it/s]\u001b[A\n"," 66% 542/819 [00:09<00:04, 59.77it/s]\u001b[A\n"," 67% 548/819 [00:09<00:04, 59.73it/s]\u001b[A\n"," 68% 554/819 [00:09<00:04, 59.73it/s]\u001b[A\n"," 68% 560/819 [00:09<00:04, 59.57it/s]\u001b[A\n"," 69% 566/819 [00:09<00:04, 59.24it/s]\u001b[A\n"," 70% 572/819 [00:09<00:04, 59.31it/s]\u001b[A\n"," 71% 578/819 [00:09<00:04, 58.67it/s]\u001b[A\n"," 71% 584/819 [00:09<00:03, 59.01it/s]\u001b[A\n"," 72% 590/819 [00:09<00:03, 58.53it/s]\u001b[A\n"," 73% 596/819 [00:10<00:03, 58.46it/s]\u001b[A\n"," 74% 602/819 [00:10<00:03, 58.48it/s]\u001b[A\n"," 74% 608/819 [00:10<00:03, 58.16it/s]\u001b[A\n"," 75% 614/819 [00:10<00:03, 57.94it/s]\u001b[A\n"," 76% 620/819 [00:10<00:03, 57.78it/s]\u001b[A\n"," 76% 626/819 [00:10<00:03, 57.64it/s]\u001b[A\n"," 77% 632/819 [00:10<00:03, 57.67it/s]\u001b[A\n"," 78% 638/819 [00:10<00:03, 57.83it/s]\u001b[A\n"," 79% 644/819 [00:10<00:03, 57.50it/s]\u001b[A\n"," 79% 650/819 [00:11<00:02, 57.41it/s]\u001b[A\n"," 80% 656/819 [00:11<00:02, 57.69it/s]\u001b[A\n"," 81% 662/819 [00:11<00:02, 57.80it/s]\u001b[A\n"," 82% 668/819 [00:11<00:02, 57.70it/s]\u001b[A\n"," 82% 674/819 [00:11<00:02, 58.01it/s]\u001b[A\n"," 83% 680/819 [00:11<00:02, 58.53it/s]\u001b[A\n"," 84% 686/819 [00:11<00:02, 58.40it/s]\u001b[A\n"," 84% 692/819 [00:11<00:02, 58.47it/s]\u001b[A\n"," 85% 698/819 [00:11<00:02, 58.77it/s]\u001b[A\n"," 86% 704/819 [00:11<00:01, 59.03it/s]\u001b[A\n"," 87% 710/819 [00:12<00:01, 59.18it/s]\u001b[A\n"," 88% 717/819 [00:12<00:01, 59.45it/s]\u001b[A\n"," 88% 723/819 [00:12<00:01, 59.48it/s]\u001b[A\n"," 89% 729/819 [00:12<00:01, 59.28it/s]\u001b[A\n"," 90% 735/819 [00:12<00:01, 59.24it/s]\u001b[A\n"," 91% 742/819 [00:12<00:01, 59.52it/s]\u001b[A\n"," 91% 748/819 [00:12<00:01, 59.62it/s]\u001b[A\n"," 92% 755/819 [00:12<00:01, 59.80it/s]\u001b[A\n"," 93% 761/819 [00:12<00:00, 59.64it/s]\u001b[A\n"," 94% 768/819 [00:12<00:00, 59.88it/s]\u001b[A\n"," 95% 775/819 [00:13<00:00, 59.89it/s]\u001b[A\n"," 95% 781/819 [00:13<00:00, 59.92it/s]\u001b[A\n"," 96% 788/819 [00:13<00:00, 60.05it/s]\u001b[A\n"," 97% 795/819 [00:13<00:00, 60.12it/s]\u001b[A\n"," 98% 802/819 [00:13<00:00, 60.19it/s]\u001b[A\n"," 99% 809/819 [00:13<00:00, 60.17it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 0.034338902682065964, 'eval_accuracy': 0.9934371184371185, 'eval_precision': 0.9934505499331763, 'eval_recall': 0.9934371184371185, 'eval_f1': 0.9934376012786749, 'eval_runtime': 13.8719, 'eval_samples_per_second': 472.323, 'eval_steps_per_second': 59.04, 'epoch': 4.0}\n"," 80% 1640/2050 [03:54<00:36, 11.33it/s]\n","100% 819/819 [00:13<00:00, 59.82it/s]\u001b[A\n","{'loss': 0.0775, 'grad_norm': 0.043836869299411774, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 2050/2050 [04:47<00:00, 11.34it/s]\n","  0% 0/819 [00:00<?, ?it/s]\u001b[A\n","  1% 6/819 [00:00<00:13, 58.64it/s]\u001b[A\n","  1% 12/819 [00:00<00:15, 52.45it/s]\u001b[A\n","  2% 18/819 [00:00<00:15, 52.89it/s]\u001b[A\n","  3% 24/819 [00:00<00:14, 55.29it/s]\u001b[A\n","  4% 30/819 [00:00<00:13, 56.47it/s]\u001b[A\n","  4% 36/819 [00:00<00:13, 57.00it/s]\u001b[A\n","  5% 42/819 [00:00<00:13, 57.68it/s]\u001b[A\n","  6% 48/819 [00:00<00:13, 58.03it/s]\u001b[A\n","  7% 54/819 [00:00<00:13, 58.10it/s]\u001b[A\n","  7% 60/819 [00:01<00:13, 58.19it/s]\u001b[A\n","  8% 66/819 [00:01<00:12, 58.18it/s]\u001b[A\n","  9% 72/819 [00:01<00:12, 58.49it/s]\u001b[A\n"," 10% 78/819 [00:01<00:12, 58.30it/s]\u001b[A\n"," 10% 84/819 [00:01<00:12, 57.98it/s]\u001b[A\n"," 11% 90/819 [00:01<00:12, 58.11it/s]\u001b[A\n"," 12% 96/819 [00:01<00:12, 57.56it/s]\u001b[A\n"," 12% 102/819 [00:01<00:12, 58.05it/s]\u001b[A\n"," 13% 108/819 [00:01<00:12, 58.19it/s]\u001b[A\n"," 14% 114/819 [00:01<00:12, 58.26it/s]\u001b[A\n"," 15% 120/819 [00:02<00:11, 58.76it/s]\u001b[A\n"," 16% 127/819 [00:02<00:11, 59.20it/s]\u001b[A\n"," 16% 133/819 [00:02<00:11, 59.37it/s]\u001b[A\n"," 17% 139/819 [00:02<00:11, 59.53it/s]\u001b[A\n"," 18% 145/819 [00:02<00:11, 59.64it/s]\u001b[A\n"," 19% 152/819 [00:02<00:11, 59.79it/s]\u001b[A\n"," 19% 158/819 [00:02<00:11, 59.71it/s]\u001b[A\n"," 20% 165/819 [00:02<00:10, 59.86it/s]\u001b[A\n"," 21% 171/819 [00:02<00:10, 59.86it/s]\u001b[A\n"," 22% 177/819 [00:03<00:10, 59.69it/s]\u001b[A\n"," 22% 183/819 [00:03<00:10, 59.42it/s]\u001b[A\n"," 23% 189/819 [00:03<00:10, 59.20it/s]\u001b[A\n"," 24% 195/819 [00:03<00:10, 59.36it/s]\u001b[A\n"," 25% 201/819 [00:03<00:10, 59.49it/s]\u001b[A\n"," 25% 207/819 [00:03<00:10, 59.50it/s]\u001b[A\n"," 26% 213/819 [00:03<00:10, 59.49it/s]\u001b[A\n"," 27% 219/819 [00:03<00:10, 59.20it/s]\u001b[A\n"," 27% 225/819 [00:03<00:10, 59.09it/s]\u001b[A\n"," 28% 231/819 [00:03<00:09, 59.28it/s]\u001b[A\n"," 29% 237/819 [00:04<00:09, 59.41it/s]\u001b[A\n"," 30% 243/819 [00:04<00:09, 59.42it/s]\u001b[A\n"," 30% 249/819 [00:04<00:09, 59.51it/s]\u001b[A\n"," 31% 255/819 [00:04<00:09, 59.58it/s]\u001b[A\n"," 32% 261/819 [00:04<00:09, 59.46it/s]\u001b[A\n"," 33% 267/819 [00:04<00:09, 59.35it/s]\u001b[A\n"," 33% 273/819 [00:04<00:09, 59.41it/s]\u001b[A\n"," 34% 279/819 [00:04<00:09, 59.39it/s]\u001b[A\n"," 35% 285/819 [00:04<00:09, 59.29it/s]\u001b[A\n"," 36% 291/819 [00:04<00:08, 59.36it/s]\u001b[A\n"," 36% 297/819 [00:05<00:08, 59.38it/s]\u001b[A\n"," 37% 303/819 [00:05<00:08, 59.18it/s]\u001b[A\n"," 38% 309/819 [00:05<00:08, 59.09it/s]\u001b[A\n"," 38% 315/819 [00:05<00:08, 59.06it/s]\u001b[A\n"," 39% 321/819 [00:05<00:08, 59.07it/s]\u001b[A\n"," 40% 327/819 [00:05<00:08, 59.20it/s]\u001b[A\n"," 41% 333/819 [00:05<00:08, 59.25it/s]\u001b[A\n"," 41% 339/819 [00:05<00:08, 59.11it/s]\u001b[A\n"," 42% 345/819 [00:05<00:08, 58.91it/s]\u001b[A\n"," 43% 351/819 [00:05<00:07, 58.69it/s]\u001b[A\n"," 44% 357/819 [00:06<00:07, 59.03it/s]\u001b[A\n","100% 2050/2050 [04:54<00:00, 11.34it/s]\n"," 45% 369/819 [00:06<00:07, 59.20it/s]\u001b[A\n"," 46% 375/819 [00:06<00:07, 59.42it/s]\u001b[A\n"," 47% 381/819 [00:06<00:07, 59.20it/s]\u001b[A\n"," 47% 387/819 [00:06<00:07, 58.84it/s]\u001b[A\n"," 48% 393/819 [00:06<00:07, 58.53it/s]\u001b[A\n"," 49% 399/819 [00:06<00:07, 58.22it/s]\u001b[A\n"," 49% 405/819 [00:06<00:07, 57.87it/s]\u001b[A\n"," 50% 411/819 [00:06<00:07, 57.86it/s]\u001b[A\n"," 51% 417/819 [00:07<00:06, 57.87it/s]\u001b[A\n"," 52% 423/819 [00:07<00:06, 57.84it/s]\u001b[A\n"," 52% 429/819 [00:07<00:06, 57.94it/s]\u001b[A\n"," 53% 435/819 [00:07<00:06, 58.26it/s]\u001b[A\n"," 54% 441/819 [00:07<00:06, 58.34it/s]\u001b[A\n"," 55% 447/819 [00:07<00:06, 58.33it/s]\u001b[A\n"," 55% 453/819 [00:07<00:06, 58.34it/s]\u001b[A\n"," 56% 459/819 [00:07<00:06, 58.45it/s]\u001b[A\n"," 57% 465/819 [00:07<00:06, 58.56it/s]\u001b[A\n"," 58% 471/819 [00:08<00:05, 58.69it/s]\u001b[A\n"," 58% 477/819 [00:08<00:05, 58.46it/s]\u001b[A\n"," 59% 483/819 [00:08<00:05, 58.47it/s]\u001b[A\n"," 60% 489/819 [00:08<00:05, 58.68it/s]\u001b[A\n"," 60% 495/819 [00:08<00:05, 58.83it/s]\u001b[A\n"," 61% 501/819 [00:08<00:05, 57.57it/s]\u001b[A\n"," 62% 507/819 [00:08<00:05, 57.07it/s]\u001b[A\n"," 63% 513/819 [00:08<00:05, 57.29it/s]\u001b[A\n"," 63% 519/819 [00:08<00:05, 57.94it/s]\u001b[A\n"," 64% 525/819 [00:08<00:05, 57.79it/s]\u001b[A\n"," 65% 531/819 [00:09<00:05, 57.18it/s]\u001b[A\n"," 66% 537/819 [00:09<00:04, 56.78it/s]\u001b[A\n"," 66% 543/819 [00:09<00:04, 56.80it/s]\u001b[A\n"," 67% 549/819 [00:09<00:04, 57.49it/s]\u001b[A\n"," 68% 555/819 [00:09<00:04, 58.04it/s]\u001b[A\n"," 68% 561/819 [00:09<00:04, 58.50it/s]\u001b[A\n"," 69% 567/819 [00:09<00:04, 58.90it/s]\u001b[A\n"," 70% 573/819 [00:09<00:04, 59.13it/s]\u001b[A\n"," 71% 579/819 [00:09<00:04, 59.38it/s]\u001b[A\n"," 71% 585/819 [00:09<00:03, 59.30it/s]\u001b[A\n"," 72% 591/819 [00:10<00:03, 57.87it/s]\u001b[A\n"," 73% 597/819 [00:10<00:03, 57.34it/s]\u001b[A\n"," 74% 603/819 [00:10<00:03, 57.56it/s]\u001b[A\n"," 74% 609/819 [00:10<00:03, 57.83it/s]\u001b[A\n"," 75% 615/819 [00:10<00:03, 57.66it/s]\u001b[A\n"," 76% 621/819 [00:10<00:03, 57.55it/s]\u001b[A\n"," 77% 627/819 [00:10<00:03, 57.61it/s]\u001b[A\n"," 77% 633/819 [00:10<00:03, 57.36it/s]\u001b[A\n"," 78% 639/819 [00:10<00:03, 56.85it/s]\u001b[A\n"," 79% 645/819 [00:11<00:03, 56.78it/s]\u001b[A\n"," 79% 651/819 [00:11<00:02, 56.55it/s]\u001b[A\n"," 80% 657/819 [00:11<00:03, 48.84it/s]\u001b[A\n"," 81% 663/819 [00:11<00:03, 50.77it/s]\u001b[A\n"," 82% 669/819 [00:11<00:02, 52.60it/s]\u001b[A\n"," 82% 675/819 [00:11<00:02, 54.12it/s]\u001b[A\n"," 83% 681/819 [00:11<00:02, 55.41it/s]\u001b[A\n"," 84% 687/819 [00:11<00:02, 56.41it/s]\u001b[A\n"," 85% 693/819 [00:11<00:02, 57.19it/s]\u001b[A\n"," 85% 699/819 [00:12<00:02, 57.63it/s]\u001b[A\n"," 86% 705/819 [00:12<00:01, 57.87it/s]\u001b[A\n"," 87% 711/819 [00:12<00:01, 58.12it/s]\u001b[A\n"," 88% 717/819 [00:12<00:01, 58.10it/s]\u001b[A\n"," 88% 723/819 [00:12<00:01, 58.15it/s]\u001b[A\n"," 89% 729/819 [00:12<00:01, 57.91it/s]\u001b[A\n"," 90% 735/819 [00:12<00:01, 57.78it/s]\u001b[A\n"," 90% 741/819 [00:12<00:01, 57.62it/s]\u001b[A\n"," 91% 747/819 [00:12<00:01, 57.84it/s]\u001b[A\n"," 92% 753/819 [00:12<00:01, 57.76it/s]\u001b[A\n"," 93% 759/819 [00:13<00:01, 57.51it/s]\u001b[A\n"," 93% 765/819 [00:13<00:00, 57.12it/s]\u001b[A\n"," 94% 771/819 [00:13<00:00, 57.24it/s]\u001b[A\n"," 95% 777/819 [00:13<00:00, 57.20it/s]\u001b[A\n"," 96% 783/819 [00:13<00:00, 56.98it/s]\u001b[A\n"," 96% 789/819 [00:13<00:00, 56.93it/s]\u001b[A\n"," 97% 795/819 [00:13<00:00, 56.98it/s]\u001b[A\n"," 98% 801/819 [00:13<00:00, 56.93it/s]\u001b[A\n"," 99% 807/819 [00:13<00:00, 56.74it/s]\u001b[A\n"," 99% 813/819 [00:14<00:00, 56.53it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 0.02434544451534748, 'eval_accuracy': 0.9957264957264957, 'eval_precision': 0.9957414865603129, 'eval_recall': 0.9957264957264957, 'eval_f1': 0.9957276460118648, 'eval_runtime': 14.1579, 'eval_samples_per_second': 462.781, 'eval_steps_per_second': 57.848, 'epoch': 5.0}\n","100% 2050/2050 [05:02<00:00, 11.34it/s]\n","100% 819/819 [00:14<00:00, 57.03it/s]\u001b[A\n","{'train_runtime': 311.5486, 'train_samples_per_second': 105.152, 'train_steps_per_second': 6.58, 'train_loss': 0.28194816682396867, 'epoch': 5.0}\n","100% 2050/2050 [05:11<00:00,  6.58it/s]\n","100% 819/819 [00:14<00:00, 57.16it/s]\n","Evaluation results:\n","{'eval_loss': 0.02434544451534748, 'eval_accuracy': 0.9957264957264957, 'eval_precision': 0.9957414865603129, 'eval_recall': 0.9957264957264957, 'eval_f1': 0.9957276460118648, 'eval_runtime': 14.3465, 'eval_samples_per_second': 456.696, 'eval_steps_per_second': 57.087, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-nagation-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/j5uuodqa\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241202_173748-j5uuodqa/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/negation \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R2_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/negation_anli_r2_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aL7Jned0RTX5","executionInfo":{"status":"ok","timestamp":1733163202792,"user_tz":360,"elapsed":65834,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"42faf6b4-14f6-4265-83bb-d7fd780ecfd3"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 18:12:21.312091: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-02 18:12:21.328580: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 18:12:21.349403: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 18:12:21.355648: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 18:12:21.370600: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 18:12:22.461466: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241202_181225-3gvelood\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-nagation-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/3gvelood\u001b[0m\n","README.md: 100% 20.8k/20.8k [00:00<00:00, 63.5MB/s]\n","train-00000-of-00001.parquet: 100% 50.2M/50.2M [00:00<00:00, 139MB/s]\n","test-00000-of-00001.parquet: 100% 308k/308k [00:00<00:00, 136MB/s]\n","validation-00000-of-00001.parquet: 100% 157k/157k [00:00<00:00, 229MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 1034871.99 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 656445.07 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 662678.74 examples/s]\n","train-00000-of-00001.parquet: 100% 70.0M/70.0M [00:00<00:00, 185MB/s]\n","test-00000-of-00001.parquet: 100% 477k/477k [00:00<00:00, 125MB/s]\n","validation-00000-of-00001.parquet: 100% 239k/239k [00:00<00:00, 161MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 769406.49 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 701735.28 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 565968.51 examples/s]\n","Map: 100% 392702/392702 [00:14<00:00, 27192.64 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 28388.63 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 29380.22 examples/s]\n","Map: 100% 392702/392702 [00:14<00:00, 26270.65 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 29095.09 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 28137.10 examples/s]\n","Generating test split: 2000 examples [00:00, 14341.95 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2557.05 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:329: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 5429.69 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 5714.52 examples/s]\n","\n","Evaluation on English test set:\n"," 96% 120/125 [00:02<00:00, 59.04it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [00:02<00:00, 58.60it/s]\n","{'eval_loss': 3.976501941680908, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.35, 'eval_precision': 0.3498345306796195, 'eval_recall': 0.35, 'eval_f1': 0.3393751296614554, 'eval_runtime': 2.8856, 'eval_samples_per_second': 346.544, 'eval_steps_per_second': 43.318}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [00:02<00:00, 59.79it/s]\n","{'eval_loss': 3.7811005115509033, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.368, 'eval_precision': 0.37349863810997447, 'eval_recall': 0.368, 'eval_f1': 0.3565207185058731, 'eval_runtime': 2.1071, 'eval_samples_per_second': 474.582, 'eval_steps_per_second': 59.323}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [00:04<00:00, 59.60it/s]\n","{'eval_loss': 3.8788013458251953, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.359, 'eval_precision': 0.36118423432758884, 'eval_recall': 0.35900000000000004, 'eval_f1': 0.348171909450663, 'eval_runtime': 4.2106, 'eval_samples_per_second': 474.989, 'eval_steps_per_second': 59.374}\n","100% 125/125 [00:02<00:00, 59.79it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/negation_anli_r2_test/misclassified_English.jsonl\n","100% 125/125 [00:02<00:00, 59.74it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/negation_anli_r2_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-nagation-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/3gvelood\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241202_181225-3gvelood/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/negation \\\n","    --task nli \\\n","    --dataset attribution_examples_combined.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_anli_en_ru_bert_2/negation_attribution"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"td59AZ0_gV-k","executionInfo":{"status":"ok","timestamp":1733164032617,"user_tz":360,"elapsed":0,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"292ec1a4-6617-49aa-f300-2d8ebec56411"},"execution_count":16,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2024-12-02 18:15:38.781921: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-02 18:15:38.798957: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 18:15:38.819974: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 18:15:38.826522: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 18:15:38.842379: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 18:15:39.930212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241202_181542-xy8wuta5\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-nagation-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/xy8wuta5\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 14630 examples [00:00, 56711.21 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language']\n","Map (num_proc=2): 100% 14630/14630 [00:03<00:00, 4078.84 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language']\n","/content/drive/MyDrive/nlp_final_project/run.py:329: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.637, 'grad_norm': 22.792858123779297, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 915/4575 [01:27<05:42, 10.69it/s]\n","  0% 0/1829 [00:00<?, ?it/s]\u001b[A\n","  0% 8/1829 [00:00<00:26, 68.84it/s]\u001b[A\n","  1% 15/1829 [00:00<00:28, 63.19it/s]\u001b[A\n","  1% 22/1829 [00:00<00:29, 61.64it/s]\u001b[A\n","  2% 29/1829 [00:00<00:29, 60.94it/s]\u001b[A\n","  2% 36/1829 [00:00<00:29, 60.54it/s]\u001b[A\n","  2% 43/1829 [00:00<00:29, 60.06it/s]\u001b[A\n","  3% 50/1829 [00:00<00:29, 59.91it/s]\u001b[A\n","  3% 56/1829 [00:00<00:29, 59.93it/s]\u001b[A\n","  3% 63/1829 [00:01<00:29, 60.07it/s]\u001b[A\n","  4% 70/1829 [00:01<00:29, 60.24it/s]\u001b[A\n","  4% 77/1829 [00:01<00:29, 60.29it/s]\u001b[A\n","  5% 84/1829 [00:01<00:28, 60.40it/s]\u001b[A\n","  5% 91/1829 [00:01<00:28, 60.20it/s]\u001b[A\n","  5% 98/1829 [00:01<00:28, 60.42it/s]\u001b[A\n","  6% 105/1829 [00:01<00:28, 60.43it/s]\u001b[A\n","  6% 112/1829 [00:01<00:28, 60.51it/s]\u001b[A\n","  7% 119/1829 [00:01<00:28, 60.21it/s]\u001b[A\n","  7% 126/1829 [00:02<00:28, 60.03it/s]\u001b[A\n","  7% 133/1829 [00:02<00:28, 60.00it/s]\u001b[A\n","  8% 140/1829 [00:02<00:28, 60.17it/s]\u001b[A\n","  8% 147/1829 [00:02<00:27, 60.24it/s]\u001b[A\n","  8% 154/1829 [00:02<00:27, 60.27it/s]\u001b[A\n","  9% 161/1829 [00:02<00:27, 60.40it/s]\u001b[A\n","  9% 168/1829 [00:02<00:27, 60.49it/s]\u001b[A\n"," 10% 175/1829 [00:02<00:27, 60.43it/s]\u001b[A\n"," 10% 182/1829 [00:03<00:27, 60.29it/s]\u001b[A\n"," 10% 189/1829 [00:03<00:27, 60.37it/s]\u001b[A\n"," 11% 196/1829 [00:03<00:27, 60.42it/s]\u001b[A\n"," 11% 203/1829 [00:03<00:26, 60.36it/s]\u001b[A\n"," 11% 210/1829 [00:03<00:26, 60.10it/s]\u001b[A\n"," 12% 217/1829 [00:03<00:26, 60.04it/s]\u001b[A\n"," 12% 224/1829 [00:03<00:26, 59.85it/s]\u001b[A\n"," 13% 230/1829 [00:03<00:26, 59.60it/s]\u001b[A\n"," 13% 236/1829 [00:03<00:26, 59.49it/s]\u001b[A\n"," 13% 242/1829 [00:04<00:26, 59.15it/s]\u001b[A\n"," 14% 248/1829 [00:04<00:26, 58.84it/s]\u001b[A\n"," 14% 254/1829 [00:04<00:26, 58.52it/s]\u001b[A\n"," 14% 260/1829 [00:04<00:26, 58.74it/s]\u001b[A\n"," 15% 266/1829 [00:04<00:26, 58.83it/s]\u001b[A\n"," 15% 272/1829 [00:04<00:26, 58.64it/s]\u001b[A\n"," 15% 278/1829 [00:04<00:26, 58.61it/s]\u001b[A\n"," 16% 284/1829 [00:04<00:26, 58.77it/s]\u001b[A\n"," 16% 290/1829 [00:04<00:26, 58.61it/s]\u001b[A\n"," 16% 296/1829 [00:04<00:26, 58.63it/s]\u001b[A\n"," 17% 302/1829 [00:05<00:25, 58.77it/s]\u001b[A\n"," 17% 308/1829 [00:05<00:25, 58.89it/s]\u001b[A\n"," 17% 314/1829 [00:05<00:25, 58.96it/s]\u001b[A\n"," 17% 320/1829 [00:05<00:25, 59.13it/s]\u001b[A\n"," 18% 326/1829 [00:05<00:25, 59.29it/s]\u001b[A\n"," 18% 332/1829 [00:05<00:25, 59.14it/s]\u001b[A\n"," 18% 338/1829 [00:05<00:25, 59.10it/s]\u001b[A\n"," 19% 344/1829 [00:05<00:25, 59.14it/s]\u001b[A\n"," 19% 350/1829 [00:05<00:25, 59.16it/s]\u001b[A\n"," 19% 356/1829 [00:05<00:25, 58.69it/s]\u001b[A\n"," 20% 362/1829 [00:06<00:25, 57.04it/s]\u001b[A\n"," 20% 368/1829 [00:06<00:25, 57.02it/s]\u001b[A\n"," 20% 374/1829 [00:06<00:25, 57.15it/s]\u001b[A\n"," 21% 380/1829 [00:06<00:25, 57.18it/s]\u001b[A\n"," 21% 386/1829 [00:06<00:25, 57.41it/s]\u001b[A\n"," 21% 392/1829 [00:06<00:24, 57.74it/s]\u001b[A\n"," 22% 398/1829 [00:06<00:24, 58.19it/s]\u001b[A\n"," 22% 404/1829 [00:06<00:24, 58.26it/s]\u001b[A\n"," 22% 410/1829 [00:06<00:24, 58.32it/s]\u001b[A\n"," 23% 416/1829 [00:06<00:24, 58.58it/s]\u001b[A\n"," 23% 422/1829 [00:07<00:23, 58.82it/s]\u001b[A\n"," 23% 428/1829 [00:07<00:23, 59.12it/s]\u001b[A\n"," 24% 434/1829 [00:07<00:23, 59.35it/s]\u001b[A\n"," 24% 440/1829 [00:07<00:23, 59.53it/s]\u001b[A\n"," 24% 446/1829 [00:07<00:23, 59.59it/s]\u001b[A\n"," 25% 452/1829 [00:07<00:23, 59.26it/s]\u001b[A\n"," 25% 458/1829 [00:07<00:23, 59.13it/s]\u001b[A\n"," 25% 464/1829 [00:07<00:23, 58.97it/s]\u001b[A\n"," 26% 470/1829 [00:07<00:23, 58.45it/s]\u001b[A\n"," 26% 476/1829 [00:08<00:23, 58.48it/s]\u001b[A\n"," 26% 482/1829 [00:08<00:22, 58.88it/s]\u001b[A\n"," 27% 488/1829 [00:08<00:22, 58.70it/s]\u001b[A\n"," 27% 494/1829 [00:08<00:22, 59.00it/s]\u001b[A\n"," 27% 500/1829 [00:08<00:22, 58.89it/s]\u001b[A\n"," 28% 506/1829 [00:08<00:22, 59.12it/s]\u001b[A\n"," 28% 512/1829 [00:08<00:22, 59.09it/s]\u001b[A\n"," 28% 518/1829 [00:08<00:22, 59.13it/s]\u001b[A\n"," 29% 524/1829 [00:08<00:22, 59.07it/s]\u001b[A\n"," 29% 530/1829 [00:08<00:22, 58.88it/s]\u001b[A\n"," 29% 536/1829 [00:09<00:21, 58.81it/s]\u001b[A\n"," 30% 542/1829 [00:09<00:21, 58.97it/s]\u001b[A\n"," 30% 548/1829 [00:09<00:21, 59.08it/s]\u001b[A\n"," 30% 554/1829 [00:09<00:21, 59.08it/s]\u001b[A\n"," 31% 560/1829 [00:09<00:21, 59.20it/s]\u001b[A\n"," 31% 566/1829 [00:09<00:21, 59.27it/s]\u001b[A\n"," 31% 573/1829 [00:09<00:21, 59.56it/s]\u001b[A\n"," 32% 580/1829 [00:09<00:20, 59.86it/s]\u001b[A\n"," 32% 586/1829 [00:09<00:20, 59.83it/s]\u001b[A\n"," 32% 593/1829 [00:09<00:20, 59.92it/s]\u001b[A\n"," 33% 599/1829 [00:10<00:20, 59.71it/s]\u001b[A\n"," 33% 605/1829 [00:10<00:20, 59.73it/s]\u001b[A\n"," 33% 612/1829 [00:10<00:20, 59.85it/s]\u001b[A\n"," 34% 618/1829 [00:10<00:20, 59.44it/s]\u001b[A\n"," 34% 624/1829 [00:10<00:20, 59.32it/s]\u001b[A\n"," 34% 630/1829 [00:10<00:20, 59.44it/s]\u001b[A\n"," 35% 637/1829 [00:10<00:19, 59.68it/s]\u001b[A\n"," 35% 643/1829 [00:10<00:19, 59.69it/s]\u001b[A\n"," 35% 649/1829 [00:10<00:19, 59.65it/s]\u001b[A\n"," 36% 655/1829 [00:11<00:19, 59.75it/s]\u001b[A\n"," 36% 661/1829 [00:11<00:19, 59.68it/s]\u001b[A\n"," 36% 667/1829 [00:11<00:19, 59.56it/s]\u001b[A\n"," 37% 673/1829 [00:11<00:19, 59.52it/s]\u001b[A\n"," 37% 679/1829 [00:11<00:19, 59.35it/s]\u001b[A\n"," 37% 685/1829 [00:11<00:19, 59.46it/s]\u001b[A\n"," 38% 692/1829 [00:11<00:19, 59.75it/s]\u001b[A\n"," 38% 699/1829 [00:11<00:18, 59.96it/s]\u001b[A\n"," 39% 706/1829 [00:11<00:18, 60.08it/s]\u001b[A\n"," 39% 713/1829 [00:11<00:18, 60.14it/s]\u001b[A\n"," 39% 720/1829 [00:12<00:18, 60.12it/s]\u001b[A\n"," 40% 727/1829 [00:12<00:18, 60.17it/s]\u001b[A\n"," 40% 734/1829 [00:12<00:18, 60.31it/s]\u001b[A\n"," 41% 741/1829 [00:12<00:18, 60.19it/s]\u001b[A\n"," 41% 748/1829 [00:12<00:17, 60.25it/s]\u001b[A\n"," 20% 915/4575 [01:40<05:42, 10.69it/s]\n"," 42% 762/1829 [00:12<00:17, 59.80it/s]\u001b[A\n"," 42% 768/1829 [00:12<00:17, 59.66it/s]\u001b[A\n"," 42% 774/1829 [00:13<00:17, 59.37it/s]\u001b[A\n"," 43% 780/1829 [00:13<00:17, 59.18it/s]\u001b[A\n"," 43% 786/1829 [00:13<00:17, 59.29it/s]\u001b[A\n"," 43% 793/1829 [00:13<00:17, 59.54it/s]\u001b[A\n"," 44% 799/1829 [00:13<00:17, 59.64it/s]\u001b[A\n"," 44% 805/1829 [00:13<00:17, 59.61it/s]\u001b[A\n"," 44% 811/1829 [00:13<00:17, 59.57it/s]\u001b[A\n"," 45% 817/1829 [00:13<00:16, 59.62it/s]\u001b[A\n"," 45% 824/1829 [00:13<00:16, 59.84it/s]\u001b[A\n"," 45% 830/1829 [00:13<00:16, 59.84it/s]\u001b[A\n"," 46% 836/1829 [00:14<00:16, 59.79it/s]\u001b[A\n"," 46% 842/1829 [00:14<00:16, 59.56it/s]\u001b[A\n"," 46% 848/1829 [00:14<00:16, 59.24it/s]\u001b[A\n"," 47% 854/1829 [00:14<00:16, 59.10it/s]\u001b[A\n"," 47% 860/1829 [00:14<00:16, 59.14it/s]\u001b[A\n"," 47% 866/1829 [00:14<00:16, 59.36it/s]\u001b[A\n"," 48% 873/1829 [00:14<00:16, 59.73it/s]\u001b[A\n"," 48% 880/1829 [00:14<00:15, 59.95it/s]\u001b[A\n"," 48% 886/1829 [00:14<00:15, 59.83it/s]\u001b[A\n"," 49% 892/1829 [00:14<00:15, 59.53it/s]\u001b[A\n"," 49% 898/1829 [00:15<00:15, 59.47it/s]\u001b[A\n"," 49% 904/1829 [00:15<00:15, 59.48it/s]\u001b[A\n"," 50% 911/1829 [00:15<00:15, 59.67it/s]\u001b[A\n"," 50% 917/1829 [00:15<00:15, 59.66it/s]\u001b[A\n"," 51% 924/1829 [00:15<00:15, 59.96it/s]\u001b[A\n"," 51% 931/1829 [00:15<00:14, 60.17it/s]\u001b[A\n"," 51% 938/1829 [00:15<00:14, 60.31it/s]\u001b[A\n"," 52% 945/1829 [00:15<00:14, 60.21it/s]\u001b[A\n"," 52% 952/1829 [00:15<00:14, 60.06it/s]\u001b[A\n"," 52% 959/1829 [00:16<00:14, 59.88it/s]\u001b[A\n"," 53% 965/1829 [00:16<00:14, 59.87it/s]\u001b[A\n"," 53% 971/1829 [00:16<00:14, 59.90it/s]\u001b[A\n"," 53% 978/1829 [00:16<00:14, 59.99it/s]\u001b[A\n"," 54% 984/1829 [00:16<00:14, 59.85it/s]\u001b[A\n"," 54% 991/1829 [00:16<00:13, 60.03it/s]\u001b[A\n"," 55% 998/1829 [00:16<00:13, 60.28it/s]\u001b[A\n"," 55% 1005/1829 [00:16<00:13, 60.05it/s]\u001b[A\n"," 55% 1012/1829 [00:16<00:13, 60.20it/s]\u001b[A\n"," 56% 1019/1829 [00:17<00:13, 60.26it/s]\u001b[A\n"," 56% 1026/1829 [00:17<00:13, 60.10it/s]\u001b[A\n"," 56% 1033/1829 [00:17<00:13, 60.15it/s]\u001b[A\n"," 57% 1040/1829 [00:17<00:13, 59.89it/s]\u001b[A\n"," 57% 1046/1829 [00:17<00:13, 59.77it/s]\u001b[A\n"," 58% 1052/1829 [00:17<00:13, 59.72it/s]\u001b[A\n"," 58% 1059/1829 [00:17<00:12, 59.86it/s]\u001b[A\n"," 58% 1066/1829 [00:17<00:12, 60.02it/s]\u001b[A\n"," 59% 1073/1829 [00:18<00:12, 59.91it/s]\u001b[A\n"," 59% 1080/1829 [00:18<00:12, 60.06it/s]\u001b[A\n"," 59% 1087/1829 [00:18<00:12, 60.16it/s]\u001b[A\n"," 60% 1094/1829 [00:18<00:12, 60.23it/s]\u001b[A\n"," 60% 1101/1829 [00:18<00:12, 60.32it/s]\u001b[A\n"," 61% 1108/1829 [00:18<00:11, 60.40it/s]\u001b[A\n"," 61% 1115/1829 [00:18<00:11, 60.39it/s]\u001b[A\n"," 61% 1122/1829 [00:18<00:11, 60.23it/s]\u001b[A\n"," 62% 1129/1829 [00:18<00:11, 59.91it/s]\u001b[A\n"," 62% 1135/1829 [00:19<00:11, 59.50it/s]\u001b[A\n"," 62% 1141/1829 [00:19<00:11, 59.17it/s]\u001b[A\n"," 63% 1147/1829 [00:19<00:11, 59.03it/s]\u001b[A\n"," 63% 1153/1829 [00:19<00:11, 59.17it/s]\u001b[A\n"," 63% 1159/1829 [00:19<00:11, 59.22it/s]\u001b[A\n"," 64% 1165/1829 [00:19<00:11, 59.29it/s]\u001b[A\n"," 64% 1171/1829 [00:19<00:11, 59.43it/s]\u001b[A\n"," 64% 1177/1829 [00:19<00:10, 59.52it/s]\u001b[A\n"," 65% 1183/1829 [00:19<00:10, 59.58it/s]\u001b[A\n"," 65% 1189/1829 [00:19<00:10, 59.57it/s]\u001b[A\n"," 65% 1195/1829 [00:20<00:10, 59.32it/s]\u001b[A\n"," 66% 1201/1829 [00:20<00:10, 59.33it/s]\u001b[A\n"," 66% 1207/1829 [00:20<00:10, 59.17it/s]\u001b[A\n"," 66% 1213/1829 [00:20<00:10, 58.91it/s]\u001b[A\n"," 67% 1219/1829 [00:20<00:10, 58.71it/s]\u001b[A\n"," 67% 1225/1829 [00:20<00:10, 58.39it/s]\u001b[A\n"," 67% 1231/1829 [00:20<00:10, 58.46it/s]\u001b[A\n"," 68% 1237/1829 [00:20<00:10, 58.37it/s]\u001b[A\n"," 68% 1243/1829 [00:20<00:10, 58.42it/s]\u001b[A\n"," 68% 1249/1829 [00:20<00:09, 58.48it/s]\u001b[A\n"," 69% 1255/1829 [00:21<00:09, 58.67it/s]\u001b[A\n"," 69% 1261/1829 [00:21<00:09, 58.99it/s]\u001b[A\n"," 69% 1267/1829 [00:21<00:09, 59.20it/s]\u001b[A\n"," 70% 1273/1829 [00:21<00:09, 59.26it/s]\u001b[A\n"," 70% 1279/1829 [00:21<00:09, 59.08it/s]\u001b[A\n"," 70% 1285/1829 [00:21<00:09, 58.79it/s]\u001b[A\n"," 71% 1291/1829 [00:21<00:09, 58.55it/s]\u001b[A\n"," 71% 1297/1829 [00:21<00:09, 58.58it/s]\u001b[A\n"," 71% 1303/1829 [00:21<00:08, 58.82it/s]\u001b[A\n"," 72% 1309/1829 [00:21<00:08, 58.65it/s]\u001b[A\n"," 72% 1315/1829 [00:22<00:08, 58.56it/s]\u001b[A\n"," 72% 1321/1829 [00:22<00:08, 58.54it/s]\u001b[A\n"," 73% 1327/1829 [00:22<00:08, 58.73it/s]\u001b[A\n"," 73% 1333/1829 [00:22<00:08, 58.74it/s]\u001b[A\n"," 73% 1339/1829 [00:22<00:08, 58.78it/s]\u001b[A\n"," 74% 1345/1829 [00:22<00:08, 58.89it/s]\u001b[A\n"," 74% 1351/1829 [00:22<00:08, 59.12it/s]\u001b[A\n"," 74% 1357/1829 [00:22<00:07, 59.13it/s]\u001b[A\n"," 75% 1363/1829 [00:22<00:07, 59.04it/s]\u001b[A\n"," 75% 1369/1829 [00:23<00:07, 58.87it/s]\u001b[A\n"," 75% 1375/1829 [00:23<00:07, 58.98it/s]\u001b[A\n"," 76% 1381/1829 [00:23<00:07, 58.97it/s]\u001b[A\n"," 76% 1387/1829 [00:23<00:07, 59.07it/s]\u001b[A\n"," 76% 1393/1829 [00:23<00:07, 59.00it/s]\u001b[A\n"," 76% 1399/1829 [00:23<00:07, 59.02it/s]\u001b[A\n"," 77% 1405/1829 [00:23<00:07, 59.12it/s]\u001b[A\n"," 77% 1411/1829 [00:23<00:07, 59.12it/s]\u001b[A\n"," 77% 1417/1829 [00:23<00:06, 59.20it/s]\u001b[A\n"," 78% 1423/1829 [00:23<00:06, 59.29it/s]\u001b[A\n"," 78% 1429/1829 [00:24<00:06, 59.33it/s]\u001b[A\n"," 78% 1435/1829 [00:24<00:06, 59.23it/s]\u001b[A\n"," 79% 1441/1829 [00:24<00:06, 59.18it/s]\u001b[A\n"," 79% 1447/1829 [00:24<00:06, 59.12it/s]\u001b[A\n"," 79% 1453/1829 [00:24<00:06, 59.18it/s]\u001b[A\n"," 80% 1460/1829 [00:24<00:06, 59.60it/s]\u001b[A\n"," 80% 1467/1829 [00:24<00:06, 59.97it/s]\u001b[A\n"," 81% 1474/1829 [00:24<00:05, 60.21it/s]\u001b[A\n"," 81% 1481/1829 [00:24<00:05, 60.43it/s]\u001b[A\n"," 81% 1488/1829 [00:25<00:05, 60.38it/s]\u001b[A\n"," 82% 1495/1829 [00:25<00:05, 60.23it/s]\u001b[A\n"," 82% 1502/1829 [00:25<00:05, 60.20it/s]\u001b[A\n"," 83% 1509/1829 [00:25<00:05, 59.91it/s]\u001b[A\n"," 83% 1515/1829 [00:25<00:05, 59.88it/s]\u001b[A\n"," 83% 1521/1829 [00:25<00:05, 59.75it/s]\u001b[A\n"," 83% 1527/1829 [00:25<00:05, 59.73it/s]\u001b[A\n"," 84% 1534/1829 [00:25<00:04, 59.95it/s]\u001b[A\n"," 84% 1541/1829 [00:25<00:04, 60.10it/s]\u001b[A\n"," 85% 1548/1829 [00:26<00:04, 60.25it/s]\u001b[A\n"," 85% 1555/1829 [00:26<00:04, 60.33it/s]\u001b[A\n"," 85% 1562/1829 [00:26<00:04, 60.23it/s]\u001b[A\n"," 86% 1569/1829 [00:26<00:04, 60.19it/s]\u001b[A\n"," 86% 1576/1829 [00:26<00:04, 60.18it/s]\u001b[A\n"," 87% 1583/1829 [00:26<00:04, 60.01it/s]\u001b[A\n"," 87% 1590/1829 [00:26<00:03, 59.88it/s]\u001b[A\n"," 87% 1596/1829 [00:26<00:03, 59.66it/s]\u001b[A\n"," 88% 1602/1829 [00:26<00:03, 59.74it/s]\u001b[A\n"," 88% 1608/1829 [00:27<00:03, 59.81it/s]\u001b[A\n"," 88% 1614/1829 [00:27<00:03, 59.81it/s]\u001b[A\n"," 89% 1620/1829 [00:27<00:03, 59.86it/s]\u001b[A\n"," 89% 1626/1829 [00:27<00:03, 59.82it/s]\u001b[A\n"," 89% 1632/1829 [00:27<00:03, 59.71it/s]\u001b[A\n"," 90% 1638/1829 [00:27<00:03, 59.60it/s]\u001b[A\n"," 90% 1645/1829 [00:27<00:03, 59.82it/s]\u001b[A\n"," 90% 1652/1829 [00:27<00:02, 59.94it/s]\u001b[A\n"," 91% 1658/1829 [00:27<00:02, 59.86it/s]\u001b[A\n"," 91% 1664/1829 [00:27<00:02, 59.70it/s]\u001b[A\n"," 91% 1671/1829 [00:28<00:02, 59.79it/s]\u001b[A\n"," 92% 1678/1829 [00:28<00:02, 59.90it/s]\u001b[A\n"," 92% 1684/1829 [00:28<00:02, 59.77it/s]\u001b[A\n"," 92% 1690/1829 [00:28<00:02, 59.67it/s]\u001b[A\n"," 93% 1696/1829 [00:28<00:02, 59.73it/s]\u001b[A\n"," 93% 1702/1829 [00:28<00:02, 59.69it/s]\u001b[A\n"," 93% 1708/1829 [00:28<00:02, 59.49it/s]\u001b[A\n"," 94% 1714/1829 [00:28<00:01, 59.42it/s]\u001b[A\n"," 94% 1720/1829 [00:28<00:01, 59.44it/s]\u001b[A\n"," 94% 1726/1829 [00:28<00:01, 59.28it/s]\u001b[A\n"," 95% 1732/1829 [00:29<00:01, 59.46it/s]\u001b[A\n"," 95% 1738/1829 [00:29<00:01, 59.52it/s]\u001b[A\n"," 95% 1744/1829 [00:29<00:01, 59.49it/s]\u001b[A\n"," 96% 1750/1829 [00:29<00:01, 59.45it/s]\u001b[A\n"," 96% 1756/1829 [00:29<00:01, 59.50it/s]\u001b[A\n"," 96% 1762/1829 [00:29<00:01, 59.07it/s]\u001b[A\n"," 97% 1768/1829 [00:29<00:01, 58.88it/s]\u001b[A\n"," 97% 1774/1829 [00:29<00:00, 58.99it/s]\u001b[A\n"," 97% 1781/1829 [00:29<00:00, 59.34it/s]\u001b[A\n"," 98% 1788/1829 [00:30<00:00, 59.70it/s]\u001b[A\n"," 98% 1794/1829 [00:30<00:00, 59.56it/s]\u001b[A\n"," 98% 1801/1829 [00:30<00:00, 59.75it/s]\u001b[A\n"," 99% 1807/1829 [00:30<00:00, 59.72it/s]\u001b[A\n"," 99% 1813/1829 [00:30<00:00, 59.72it/s]\u001b[A\n"," 99% 1819/1829 [00:30<00:00, 59.80it/s]\u001b[A\n","                                      \n","\u001b[A{'eval_loss': 0.31393030285835266, 'eval_accuracy': 0.8849624060150376, 'eval_precision': 0.8842885078002102, 'eval_recall': 0.8849624060150376, 'eval_f1': 0.8837391246046035, 'eval_runtime': 30.7463, 'eval_samples_per_second': 475.829, 'eval_steps_per_second': 59.487, 'epoch': 1.0}\n"," 20% 915/4575 [01:57<05:42, 10.69it/s]\n","100% 1829/1829 [00:30<00:00, 59.78it/s]\u001b[A\n","{'loss': 0.3548, 'grad_norm': 28.665769577026367, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 1830/4575 [03:32<04:18, 10.62it/s]\n","  0% 0/1829 [00:00<?, ?it/s]\u001b[A\n","  0% 8/1829 [00:00<00:26, 69.06it/s]\u001b[A\n","  1% 15/1829 [00:00<00:28, 63.90it/s]\u001b[A\n","  1% 22/1829 [00:00<00:29, 61.87it/s]\u001b[A\n","  2% 29/1829 [00:00<00:29, 60.89it/s]\u001b[A\n","  2% 36/1829 [00:00<00:29, 60.67it/s]\u001b[A\n","  2% 43/1829 [00:00<00:29, 60.48it/s]\u001b[A\n","  3% 50/1829 [00:00<00:29, 60.27it/s]\u001b[A\n","  3% 57/1829 [00:00<00:29, 60.08it/s]\u001b[A\n","  3% 64/1829 [00:01<00:29, 60.25it/s]\u001b[A\n","  4% 71/1829 [00:01<00:29, 60.14it/s]\u001b[A\n","  4% 78/1829 [00:01<00:29, 60.07it/s]\u001b[A\n","  5% 85/1829 [00:01<00:29, 59.84it/s]\u001b[A\n","  5% 91/1829 [00:01<00:29, 59.84it/s]\u001b[A\n","  5% 97/1829 [00:01<00:28, 59.82it/s]\u001b[A\n","  6% 103/1829 [00:01<00:28, 59.64it/s]\u001b[A\n","  6% 109/1829 [00:01<00:28, 59.41it/s]\u001b[A\n","  6% 115/1829 [00:01<00:28, 59.54it/s]\u001b[A\n","  7% 122/1829 [00:02<00:28, 59.73it/s]\u001b[A\n","  7% 129/1829 [00:02<00:28, 59.87it/s]\u001b[A\n","  7% 136/1829 [00:02<00:28, 60.05it/s]\u001b[A\n","  8% 143/1829 [00:02<00:27, 60.22it/s]\u001b[A\n","  8% 150/1829 [00:02<00:27, 60.29it/s]\u001b[A\n","  9% 157/1829 [00:02<00:27, 60.08it/s]\u001b[A\n","  9% 164/1829 [00:02<00:27, 60.03it/s]\u001b[A\n","  9% 171/1829 [00:02<00:27, 59.96it/s]\u001b[A\n"," 10% 177/1829 [00:02<00:27, 59.94it/s]\u001b[A\n"," 10% 184/1829 [00:03<00:27, 60.05it/s]\u001b[A\n"," 10% 191/1829 [00:03<00:27, 59.94it/s]\u001b[A\n"," 11% 198/1829 [00:03<00:27, 60.18it/s]\u001b[A\n"," 11% 205/1829 [00:03<00:26, 60.38it/s]\u001b[A\n"," 12% 212/1829 [00:03<00:26, 60.31it/s]\u001b[A\n"," 12% 219/1829 [00:03<00:26, 60.35it/s]\u001b[A\n"," 12% 226/1829 [00:03<00:26, 60.32it/s]\u001b[A\n"," 13% 233/1829 [00:03<00:26, 60.03it/s]\u001b[A\n"," 13% 240/1829 [00:03<00:26, 60.12it/s]\u001b[A\n"," 14% 247/1829 [00:04<00:26, 60.21it/s]\u001b[A\n"," 14% 254/1829 [00:04<00:26, 60.23it/s]\u001b[A\n"," 14% 261/1829 [00:04<00:26, 60.22it/s]\u001b[A\n"," 15% 268/1829 [00:04<00:25, 60.29it/s]\u001b[A\n"," 15% 275/1829 [00:04<00:25, 60.37it/s]\u001b[A\n"," 15% 282/1829 [00:04<00:25, 59.96it/s]\u001b[A\n"," 16% 288/1829 [00:04<00:25, 59.92it/s]\u001b[A\n"," 16% 295/1829 [00:04<00:25, 60.04it/s]\u001b[A\n"," 17% 302/1829 [00:05<00:25, 60.17it/s]\u001b[A\n"," 17% 309/1829 [00:05<00:25, 60.12it/s]\u001b[A\n"," 17% 316/1829 [00:05<00:25, 60.06it/s]\u001b[A\n"," 18% 323/1829 [00:05<00:25, 60.13it/s]\u001b[A\n"," 18% 330/1829 [00:05<00:24, 60.10it/s]\u001b[A\n"," 18% 337/1829 [00:05<00:24, 60.03it/s]\u001b[A\n"," 19% 344/1829 [00:05<00:24, 60.00it/s]\u001b[A\n"," 19% 351/1829 [00:05<00:24, 60.11it/s]\u001b[A\n"," 20% 358/1829 [00:05<00:24, 60.22it/s]\u001b[A\n"," 20% 365/1829 [00:06<00:24, 60.28it/s]\u001b[A\n"," 20% 372/1829 [00:06<00:24, 60.32it/s]\u001b[A\n"," 21% 379/1829 [00:06<00:24, 60.41it/s]\u001b[A\n"," 21% 386/1829 [00:06<00:23, 60.44it/s]\u001b[A\n"," 21% 393/1829 [00:06<00:23, 60.01it/s]\u001b[A\n"," 22% 400/1829 [00:06<00:23, 59.91it/s]\u001b[A\n"," 22% 407/1829 [00:06<00:23, 60.03it/s]\u001b[A\n"," 23% 414/1829 [00:06<00:23, 59.97it/s]\u001b[A\n"," 23% 421/1829 [00:06<00:23, 60.12it/s]\u001b[A\n"," 23% 428/1829 [00:07<00:23, 60.10it/s]\u001b[A\n"," 24% 435/1829 [00:07<00:23, 60.09it/s]\u001b[A\n"," 24% 442/1829 [00:07<00:23, 60.01it/s]\u001b[A\n"," 25% 449/1829 [00:07<00:23, 59.98it/s]\u001b[A\n"," 25% 456/1829 [00:07<00:22, 60.05it/s]\u001b[A\n"," 25% 463/1829 [00:07<00:22, 60.13it/s]\u001b[A\n"," 26% 470/1829 [00:07<00:22, 60.18it/s]\u001b[A\n"," 26% 477/1829 [00:07<00:22, 60.15it/s]\u001b[A\n"," 26% 484/1829 [00:08<00:22, 60.14it/s]\u001b[A\n"," 27% 491/1829 [00:08<00:22, 60.24it/s]\u001b[A\n"," 27% 498/1829 [00:08<00:22, 60.28it/s]\u001b[A\n"," 28% 505/1829 [00:08<00:21, 60.40it/s]\u001b[A\n"," 28% 512/1829 [00:08<00:21, 60.10it/s]\u001b[A\n"," 28% 519/1829 [00:08<00:21, 60.13it/s]\u001b[A\n"," 29% 526/1829 [00:08<00:21, 60.29it/s]\u001b[A\n"," 29% 533/1829 [00:08<00:21, 60.39it/s]\u001b[A\n"," 30% 540/1829 [00:08<00:21, 60.37it/s]\u001b[A\n"," 30% 547/1829 [00:09<00:21, 60.50it/s]\u001b[A\n"," 30% 554/1829 [00:09<00:21, 60.55it/s]\u001b[A\n"," 31% 561/1829 [00:09<00:20, 60.60it/s]\u001b[A\n"," 31% 568/1829 [00:09<00:20, 60.57it/s]\u001b[A\n"," 31% 575/1829 [00:09<00:20, 60.53it/s]\u001b[A\n"," 32% 582/1829 [00:09<00:20, 60.28it/s]\u001b[A\n"," 32% 589/1829 [00:09<00:20, 60.24it/s]\u001b[A\n"," 33% 596/1829 [00:09<00:20, 60.17it/s]\u001b[A\n"," 33% 603/1829 [00:10<00:20, 59.77it/s]\u001b[A\n"," 33% 610/1829 [00:10<00:20, 59.88it/s]\u001b[A\n"," 34% 616/1829 [00:10<00:20, 59.65it/s]\u001b[A\n"," 34% 622/1829 [00:10<00:20, 59.03it/s]\u001b[A\n"," 34% 628/1829 [00:10<00:20, 58.23it/s]\u001b[A\n"," 35% 634/1829 [00:10<00:20, 57.85it/s]\u001b[A\n"," 35% 640/1829 [00:10<00:20, 58.04it/s]\u001b[A\n"," 35% 646/1829 [00:10<00:20, 58.05it/s]\u001b[A\n"," 36% 653/1829 [00:10<00:20, 58.77it/s]\u001b[A\n"," 36% 659/1829 [00:10<00:19, 58.71it/s]\u001b[A\n"," 36% 665/1829 [00:11<00:19, 58.73it/s]\u001b[A\n"," 37% 671/1829 [00:11<00:19, 58.41it/s]\u001b[A\n"," 37% 677/1829 [00:11<00:19, 58.38it/s]\u001b[A\n"," 37% 683/1829 [00:11<00:19, 58.29it/s]\u001b[A\n"," 38% 689/1829 [00:11<00:19, 58.18it/s]\u001b[A\n"," 38% 695/1829 [00:11<00:19, 57.97it/s]\u001b[A\n"," 38% 701/1829 [00:11<00:19, 58.00it/s]\u001b[A\n"," 39% 707/1829 [00:11<00:19, 57.95it/s]\u001b[A\n"," 39% 713/1829 [00:11<00:19, 57.81it/s]\u001b[A\n"," 39% 719/1829 [00:12<00:19, 57.51it/s]\u001b[A\n"," 40% 725/1829 [00:12<00:19, 58.05it/s]\u001b[A\n"," 40% 731/1829 [00:12<00:18, 58.30it/s]\u001b[A\n"," 40% 737/1829 [00:12<00:18, 58.09it/s]\u001b[A\n"," 41% 743/1829 [00:12<00:18, 58.05it/s]\u001b[A\n"," 41% 749/1829 [00:12<00:18, 58.28it/s]\u001b[A\n"," 41% 755/1829 [00:12<00:18, 58.34it/s]\u001b[A\n"," 42% 761/1829 [00:12<00:18, 58.30it/s]\u001b[A\n"," 42% 767/1829 [00:12<00:18, 58.53it/s]\u001b[A\n"," 42% 773/1829 [00:12<00:18, 58.52it/s]\u001b[A\n"," 43% 779/1829 [00:13<00:17, 58.75it/s]\u001b[A\n"," 43% 785/1829 [00:13<00:17, 58.91it/s]\u001b[A\n"," 43% 792/1829 [00:13<00:17, 59.39it/s]\u001b[A\n"," 44% 798/1829 [00:13<00:17, 59.50it/s]\u001b[A\n"," 40% 1830/4575 [03:45<04:18, 10.62it/s]\n"," 44% 810/1829 [00:13<00:17, 59.36it/s]\u001b[A\n"," 45% 816/1829 [00:13<00:17, 59.48it/s]\u001b[A\n"," 45% 823/1829 [00:13<00:16, 59.85it/s]\u001b[A\n"," 45% 829/1829 [00:13<00:16, 59.82it/s]\u001b[A\n"," 46% 836/1829 [00:13<00:16, 59.95it/s]\u001b[A\n"," 46% 842/1829 [00:14<00:16, 59.89it/s]\u001b[A\n"," 46% 849/1829 [00:14<00:16, 60.02it/s]\u001b[A\n"," 47% 855/1829 [00:14<00:16, 59.99it/s]\u001b[A\n"," 47% 862/1829 [00:14<00:16, 60.11it/s]\u001b[A\n"," 48% 869/1829 [00:14<00:15, 60.23it/s]\u001b[A\n"," 48% 876/1829 [00:14<00:15, 60.30it/s]\u001b[A\n"," 48% 883/1829 [00:14<00:15, 60.35it/s]\u001b[A\n"," 49% 890/1829 [00:14<00:15, 60.41it/s]\u001b[A\n"," 49% 897/1829 [00:14<00:15, 60.45it/s]\u001b[A\n"," 49% 904/1829 [00:15<00:15, 60.50it/s]\u001b[A\n"," 50% 911/1829 [00:15<00:15, 60.50it/s]\u001b[A\n"," 50% 918/1829 [00:15<00:15, 60.57it/s]\u001b[A\n"," 51% 925/1829 [00:15<00:14, 60.56it/s]\u001b[A\n"," 51% 932/1829 [00:15<00:14, 60.50it/s]\u001b[A\n"," 51% 939/1829 [00:15<00:14, 60.48it/s]\u001b[A\n"," 52% 946/1829 [00:15<00:14, 60.49it/s]\u001b[A\n"," 52% 953/1829 [00:15<00:14, 60.48it/s]\u001b[A\n"," 52% 960/1829 [00:16<00:14, 60.42it/s]\u001b[A\n"," 53% 967/1829 [00:16<00:14, 59.99it/s]\u001b[A\n"," 53% 974/1829 [00:16<00:14, 60.05it/s]\u001b[A\n"," 54% 981/1829 [00:16<00:14, 60.13it/s]\u001b[A\n"," 54% 988/1829 [00:16<00:13, 60.20it/s]\u001b[A\n"," 54% 995/1829 [00:16<00:13, 60.25it/s]\u001b[A\n"," 55% 1002/1829 [00:16<00:13, 60.15it/s]\u001b[A\n"," 55% 1009/1829 [00:16<00:13, 60.13it/s]\u001b[A\n"," 56% 1016/1829 [00:16<00:13, 60.12it/s]\u001b[A\n"," 56% 1023/1829 [00:17<00:13, 59.92it/s]\u001b[A\n"," 56% 1030/1829 [00:17<00:13, 60.03it/s]\u001b[A\n"," 57% 1037/1829 [00:17<00:13, 60.18it/s]\u001b[A\n"," 57% 1044/1829 [00:17<00:13, 60.10it/s]\u001b[A\n"," 57% 1051/1829 [00:17<00:12, 60.06it/s]\u001b[A\n"," 58% 1058/1829 [00:17<00:12, 60.14it/s]\u001b[A\n"," 58% 1065/1829 [00:17<00:12, 60.19it/s]\u001b[A\n"," 59% 1072/1829 [00:17<00:12, 60.16it/s]\u001b[A\n"," 59% 1079/1829 [00:18<00:12, 59.91it/s]\u001b[A\n"," 59% 1085/1829 [00:18<00:12, 59.81it/s]\u001b[A\n"," 60% 1092/1829 [00:18<00:12, 59.93it/s]\u001b[A\n"," 60% 1099/1829 [00:18<00:12, 60.21it/s]\u001b[A\n"," 60% 1106/1829 [00:18<00:11, 60.43it/s]\u001b[A\n"," 61% 1113/1829 [00:18<00:11, 60.43it/s]\u001b[A\n"," 61% 1120/1829 [00:18<00:11, 60.41it/s]\u001b[A\n"," 62% 1127/1829 [00:18<00:11, 60.41it/s]\u001b[A\n"," 62% 1134/1829 [00:18<00:11, 60.48it/s]\u001b[A\n"," 62% 1141/1829 [00:19<00:11, 60.46it/s]\u001b[A\n"," 63% 1148/1829 [00:19<00:11, 60.32it/s]\u001b[A\n"," 63% 1155/1829 [00:19<00:11, 60.35it/s]\u001b[A\n"," 64% 1162/1829 [00:19<00:11, 60.34it/s]\u001b[A\n"," 64% 1169/1829 [00:19<00:10, 60.47it/s]\u001b[A\n"," 64% 1176/1829 [00:19<00:10, 60.49it/s]\u001b[A\n"," 65% 1183/1829 [00:19<00:10, 60.56it/s]\u001b[A\n"," 65% 1190/1829 [00:19<00:10, 60.54it/s]\u001b[A\n"," 65% 1197/1829 [00:19<00:10, 60.04it/s]\u001b[A\n"," 66% 1204/1829 [00:20<00:10, 60.08it/s]\u001b[A\n"," 66% 1211/1829 [00:20<00:10, 60.15it/s]\u001b[A\n"," 67% 1218/1829 [00:20<00:10, 60.32it/s]\u001b[A\n"," 67% 1225/1829 [00:20<00:10, 60.36it/s]\u001b[A\n"," 67% 1232/1829 [00:20<00:09, 60.44it/s]\u001b[A\n"," 68% 1239/1829 [00:20<00:09, 60.40it/s]\u001b[A\n"," 68% 1246/1829 [00:20<00:09, 60.43it/s]\u001b[A\n"," 69% 1253/1829 [00:20<00:09, 60.56it/s]\u001b[A\n"," 69% 1260/1829 [00:21<00:09, 60.28it/s]\u001b[A\n"," 69% 1267/1829 [00:21<00:09, 60.14it/s]\u001b[A\n"," 70% 1274/1829 [00:21<00:09, 60.20it/s]\u001b[A\n"," 70% 1281/1829 [00:21<00:09, 60.28it/s]\u001b[A\n"," 70% 1288/1829 [00:21<00:08, 60.25it/s]\u001b[A\n"," 71% 1295/1829 [00:21<00:08, 60.26it/s]\u001b[A\n"," 71% 1302/1829 [00:21<00:08, 60.30it/s]\u001b[A\n"," 72% 1309/1829 [00:21<00:08, 59.97it/s]\u001b[A\n"," 72% 1316/1829 [00:21<00:08, 60.09it/s]\u001b[A\n"," 72% 1323/1829 [00:22<00:08, 60.15it/s]\u001b[A\n"," 73% 1330/1829 [00:22<00:08, 59.97it/s]\u001b[A\n"," 73% 1337/1829 [00:22<00:08, 60.04it/s]\u001b[A\n"," 73% 1344/1829 [00:22<00:08, 60.13it/s]\u001b[A\n"," 74% 1351/1829 [00:22<00:07, 59.99it/s]\u001b[A\n"," 74% 1357/1829 [00:22<00:07, 59.88it/s]\u001b[A\n"," 75% 1364/1829 [00:22<00:07, 60.05it/s]\u001b[A\n"," 75% 1371/1829 [00:22<00:07, 60.15it/s]\u001b[A\n"," 75% 1378/1829 [00:22<00:07, 60.00it/s]\u001b[A\n"," 76% 1385/1829 [00:23<00:07, 60.05it/s]\u001b[A\n"," 76% 1392/1829 [00:23<00:07, 59.95it/s]\u001b[A\n"," 76% 1399/1829 [00:23<00:07, 59.97it/s]\u001b[A\n"," 77% 1406/1829 [00:23<00:07, 60.06it/s]\u001b[A\n"," 77% 1413/1829 [00:23<00:06, 59.96it/s]\u001b[A\n"," 78% 1419/1829 [00:23<00:06, 59.96it/s]\u001b[A\n"," 78% 1425/1829 [00:23<00:06, 59.79it/s]\u001b[A\n"," 78% 1432/1829 [00:23<00:06, 59.99it/s]\u001b[A\n"," 79% 1438/1829 [00:23<00:06, 59.95it/s]\u001b[A\n"," 79% 1444/1829 [00:24<00:06, 59.87it/s]\u001b[A\n"," 79% 1450/1829 [00:24<00:06, 59.54it/s]\u001b[A\n"," 80% 1456/1829 [00:24<00:06, 59.56it/s]\u001b[A\n"," 80% 1462/1829 [00:24<00:06, 59.42it/s]\u001b[A\n"," 80% 1468/1829 [00:24<00:06, 59.38it/s]\u001b[A\n"," 81% 1474/1829 [00:24<00:05, 59.32it/s]\u001b[A\n"," 81% 1480/1829 [00:24<00:05, 59.38it/s]\u001b[A\n"," 81% 1487/1829 [00:24<00:05, 59.65it/s]\u001b[A\n"," 82% 1493/1829 [00:24<00:05, 59.70it/s]\u001b[A\n"," 82% 1499/1829 [00:25<00:05, 59.53it/s]\u001b[A\n"," 82% 1505/1829 [00:25<00:05, 59.47it/s]\u001b[A\n"," 83% 1511/1829 [00:25<00:05, 59.32it/s]\u001b[A\n"," 83% 1517/1829 [00:25<00:05, 59.50it/s]\u001b[A\n"," 83% 1524/1829 [00:25<00:05, 59.81it/s]\u001b[A\n"," 84% 1530/1829 [00:25<00:04, 59.86it/s]\u001b[A\n"," 84% 1536/1829 [00:25<00:04, 59.73it/s]\u001b[A\n"," 84% 1542/1829 [00:25<00:04, 59.75it/s]\u001b[A\n"," 85% 1549/1829 [00:25<00:04, 60.03it/s]\u001b[A\n"," 85% 1556/1829 [00:25<00:04, 60.00it/s]\u001b[A\n"," 85% 1563/1829 [00:26<00:04, 60.10it/s]\u001b[A\n"," 86% 1570/1829 [00:26<00:04, 60.02it/s]\u001b[A\n"," 86% 1577/1829 [00:26<00:04, 59.82it/s]\u001b[A\n"," 87% 1584/1829 [00:26<00:04, 59.95it/s]\u001b[A\n"," 87% 1591/1829 [00:26<00:03, 60.08it/s]\u001b[A\n"," 87% 1598/1829 [00:26<00:03, 60.05it/s]\u001b[A\n"," 88% 1605/1829 [00:26<00:03, 60.12it/s]\u001b[A\n"," 88% 1612/1829 [00:26<00:03, 60.17it/s]\u001b[A\n"," 89% 1619/1829 [00:27<00:03, 60.12it/s]\u001b[A\n"," 89% 1626/1829 [00:27<00:03, 60.17it/s]\u001b[A\n"," 89% 1633/1829 [00:27<00:03, 60.23it/s]\u001b[A\n"," 90% 1640/1829 [00:27<00:03, 60.34it/s]\u001b[A\n"," 90% 1647/1829 [00:27<00:03, 60.45it/s]\u001b[A\n"," 90% 1654/1829 [00:27<00:02, 60.08it/s]\u001b[A\n"," 91% 1661/1829 [00:27<00:02, 60.29it/s]\u001b[A\n"," 91% 1668/1829 [00:27<00:02, 60.31it/s]\u001b[A\n"," 92% 1675/1829 [00:27<00:02, 60.08it/s]\u001b[A\n"," 92% 1682/1829 [00:28<00:02, 60.11it/s]\u001b[A\n"," 92% 1689/1829 [00:28<00:02, 60.06it/s]\u001b[A\n"," 93% 1696/1829 [00:28<00:02, 60.20it/s]\u001b[A\n"," 93% 1703/1829 [00:28<00:02, 60.32it/s]\u001b[A\n"," 93% 1710/1829 [00:28<00:01, 60.46it/s]\u001b[A\n"," 94% 1717/1829 [00:28<00:01, 60.50it/s]\u001b[A\n"," 94% 1724/1829 [00:28<00:01, 60.50it/s]\u001b[A\n"," 95% 1731/1829 [00:28<00:01, 60.40it/s]\u001b[A\n"," 95% 1738/1829 [00:28<00:01, 60.35it/s]\u001b[A\n"," 95% 1745/1829 [00:29<00:01, 60.18it/s]\u001b[A\n"," 96% 1752/1829 [00:29<00:01, 60.21it/s]\u001b[A\n"," 96% 1759/1829 [00:29<00:01, 60.19it/s]\u001b[A\n"," 97% 1766/1829 [00:29<00:01, 59.84it/s]\u001b[A\n"," 97% 1772/1829 [00:29<00:00, 59.80it/s]\u001b[A\n"," 97% 1779/1829 [00:29<00:00, 59.95it/s]\u001b[A\n"," 98% 1786/1829 [00:29<00:00, 60.08it/s]\u001b[A\n"," 98% 1793/1829 [00:29<00:00, 59.85it/s]\u001b[A\n"," 98% 1800/1829 [00:30<00:00, 60.01it/s]\u001b[A\n"," 99% 1807/1829 [00:30<00:00, 59.99it/s]\u001b[A\n"," 99% 1814/1829 [00:30<00:00, 60.16it/s]\u001b[A\n","100% 1821/1829 [00:30<00:00, 60.25it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 0.13125285506248474, 'eval_accuracy': 0.955434039644566, 'eval_precision': 0.9561050307923934, 'eval_recall': 0.955434039644566, 'eval_f1': 0.9552147098088424, 'eval_runtime': 30.5233, 'eval_samples_per_second': 479.306, 'eval_steps_per_second': 59.921, 'epoch': 2.0}\n"," 40% 1830/4575 [04:02<04:18, 10.62it/s]\n","100% 1829/1829 [00:30<00:00, 60.40it/s]\u001b[A\n","{'loss': 0.2124, 'grad_norm': 0.23293758928775787, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 2745/4575 [05:34<02:40, 11.43it/s]\n","  0% 0/1829 [00:00<?, ?it/s]\u001b[A\n","  0% 7/1829 [00:00<00:26, 69.69it/s]\u001b[A\n","  1% 14/1829 [00:00<00:28, 63.13it/s]\u001b[A\n","  1% 21/1829 [00:00<00:29, 60.45it/s]\u001b[A\n","  2% 28/1829 [00:00<00:30, 59.51it/s]\u001b[A\n","  2% 34/1829 [00:00<00:30, 59.46it/s]\u001b[A\n","  2% 41/1829 [00:00<00:29, 59.87it/s]\u001b[A\n","  3% 48/1829 [00:00<00:29, 60.08it/s]\u001b[A\n","  3% 55/1829 [00:00<00:29, 60.12it/s]\u001b[A\n","  3% 62/1829 [00:01<00:29, 60.02it/s]\u001b[A\n","  4% 69/1829 [00:01<00:29, 59.97it/s]\u001b[A\n","  4% 75/1829 [00:01<00:29, 59.88it/s]\u001b[A\n","  4% 81/1829 [00:01<00:29, 59.68it/s]\u001b[A\n","  5% 87/1829 [00:01<00:29, 59.63it/s]\u001b[A\n","  5% 94/1829 [00:01<00:29, 59.82it/s]\u001b[A\n","  5% 100/1829 [00:01<00:29, 59.52it/s]\u001b[A\n","  6% 106/1829 [00:01<00:29, 59.11it/s]\u001b[A\n","  6% 113/1829 [00:01<00:28, 59.55it/s]\u001b[A\n","  7% 120/1829 [00:02<00:28, 59.71it/s]\u001b[A\n","  7% 127/1829 [00:02<00:28, 60.11it/s]\u001b[A\n","  7% 134/1829 [00:02<00:28, 60.20it/s]\u001b[A\n","  8% 141/1829 [00:02<00:28, 60.20it/s]\u001b[A\n","  8% 148/1829 [00:02<00:27, 60.13it/s]\u001b[A\n","  8% 155/1829 [00:02<00:27, 60.22it/s]\u001b[A\n","  9% 162/1829 [00:02<00:27, 60.27it/s]\u001b[A\n","  9% 169/1829 [00:02<00:27, 60.21it/s]\u001b[A\n"," 10% 176/1829 [00:02<00:27, 60.27it/s]\u001b[A\n"," 10% 183/1829 [00:03<00:27, 60.11it/s]\u001b[A\n"," 10% 190/1829 [00:03<00:27, 59.59it/s]\u001b[A\n"," 11% 196/1829 [00:03<00:27, 59.66it/s]\u001b[A\n"," 11% 203/1829 [00:03<00:27, 59.82it/s]\u001b[A\n"," 11% 210/1829 [00:03<00:26, 60.02it/s]\u001b[A\n"," 12% 217/1829 [00:03<00:26, 60.02it/s]\u001b[A\n"," 12% 224/1829 [00:03<00:26, 59.83it/s]\u001b[A\n"," 13% 230/1829 [00:03<00:26, 59.87it/s]\u001b[A\n"," 13% 236/1829 [00:03<00:26, 59.64it/s]\u001b[A\n"," 13% 242/1829 [00:04<00:26, 59.61it/s]\u001b[A\n"," 14% 248/1829 [00:04<00:26, 59.30it/s]\u001b[A\n"," 14% 254/1829 [00:04<00:26, 59.25it/s]\u001b[A\n"," 14% 260/1829 [00:04<00:26, 59.34it/s]\u001b[A\n"," 15% 266/1829 [00:04<00:26, 59.05it/s]\u001b[A\n"," 15% 272/1829 [00:04<00:26, 58.79it/s]\u001b[A\n"," 15% 278/1829 [00:04<00:26, 58.83it/s]\u001b[A\n"," 16% 284/1829 [00:04<00:26, 59.12it/s]\u001b[A\n"," 16% 290/1829 [00:04<00:25, 59.35it/s]\u001b[A\n"," 16% 296/1829 [00:04<00:25, 59.24it/s]\u001b[A\n"," 17% 302/1829 [00:05<00:25, 58.91it/s]\u001b[A\n"," 17% 308/1829 [00:05<00:25, 58.80it/s]\u001b[A\n"," 17% 314/1829 [00:05<00:25, 58.96it/s]\u001b[A\n"," 17% 320/1829 [00:05<00:25, 58.96it/s]\u001b[A\n"," 18% 326/1829 [00:05<00:25, 58.97it/s]\u001b[A\n"," 18% 332/1829 [00:05<00:25, 58.85it/s]\u001b[A\n"," 18% 338/1829 [00:05<00:25, 58.90it/s]\u001b[A\n"," 19% 344/1829 [00:05<00:25, 58.82it/s]\u001b[A\n"," 19% 350/1829 [00:05<00:25, 58.38it/s]\u001b[A\n"," 19% 356/1829 [00:05<00:25, 57.99it/s]\u001b[A\n"," 20% 362/1829 [00:06<00:25, 58.16it/s]\u001b[A\n"," 20% 368/1829 [00:06<00:25, 58.33it/s]\u001b[A\n"," 20% 374/1829 [00:06<00:24, 58.39it/s]\u001b[A\n"," 21% 380/1829 [00:06<00:24, 58.56it/s]\u001b[A\n"," 21% 386/1829 [00:06<00:24, 58.61it/s]\u001b[A\n"," 21% 392/1829 [00:06<00:24, 58.70it/s]\u001b[A\n"," 22% 398/1829 [00:06<00:24, 58.73it/s]\u001b[A\n"," 22% 404/1829 [00:06<00:24, 58.53it/s]\u001b[A\n"," 22% 410/1829 [00:06<00:24, 58.32it/s]\u001b[A\n"," 23% 416/1829 [00:06<00:24, 58.45it/s]\u001b[A\n"," 23% 422/1829 [00:07<00:24, 58.57it/s]\u001b[A\n"," 23% 428/1829 [00:07<00:24, 58.19it/s]\u001b[A\n"," 24% 434/1829 [00:07<00:23, 58.42it/s]\u001b[A\n"," 24% 440/1829 [00:07<00:23, 58.63it/s]\u001b[A\n"," 24% 447/1829 [00:07<00:23, 59.30it/s]\u001b[A\n"," 25% 454/1829 [00:07<00:22, 59.78it/s]\u001b[A\n"," 25% 461/1829 [00:07<00:22, 59.91it/s]\u001b[A\n"," 26% 468/1829 [00:07<00:22, 60.11it/s]\u001b[A\n"," 26% 475/1829 [00:07<00:22, 60.06it/s]\u001b[A\n"," 26% 482/1829 [00:08<00:22, 60.11it/s]\u001b[A\n"," 27% 489/1829 [00:08<00:22, 59.81it/s]\u001b[A\n"," 27% 496/1829 [00:08<00:22, 59.96it/s]\u001b[A\n"," 27% 502/1829 [00:08<00:22, 59.91it/s]\u001b[A\n"," 28% 509/1829 [00:08<00:21, 60.15it/s]\u001b[A\n"," 28% 516/1829 [00:08<00:21, 59.94it/s]\u001b[A\n"," 29% 522/1829 [00:08<00:21, 59.42it/s]\u001b[A\n"," 29% 528/1829 [00:08<00:21, 59.43it/s]\u001b[A\n"," 29% 534/1829 [00:08<00:21, 59.25it/s]\u001b[A\n"," 30% 541/1829 [00:09<00:21, 59.48it/s]\u001b[A\n"," 30% 548/1829 [00:09<00:21, 59.72it/s]\u001b[A\n"," 30% 554/1829 [00:09<00:21, 59.67it/s]\u001b[A\n"," 31% 560/1829 [00:09<00:21, 59.28it/s]\u001b[A\n"," 31% 566/1829 [00:09<00:21, 59.12it/s]\u001b[A\n"," 31% 572/1829 [00:09<00:21, 59.04it/s]\u001b[A\n"," 32% 578/1829 [00:09<00:21, 58.83it/s]\u001b[A\n"," 32% 584/1829 [00:09<00:21, 58.76it/s]\u001b[A\n"," 32% 590/1829 [00:09<00:21, 58.80it/s]\u001b[A\n"," 33% 596/1829 [00:10<00:21, 58.67it/s]\u001b[A\n"," 33% 602/1829 [00:10<00:20, 58.49it/s]\u001b[A\n"," 33% 608/1829 [00:10<00:20, 58.32it/s]\u001b[A\n"," 34% 614/1829 [00:10<00:20, 58.44it/s]\u001b[A\n"," 34% 620/1829 [00:10<00:20, 58.33it/s]\u001b[A\n"," 34% 626/1829 [00:10<00:20, 58.55it/s]\u001b[A\n"," 60% 2745/4575 [05:45<02:40, 11.43it/s]\n"," 35% 638/1829 [00:10<00:20, 58.42it/s]\u001b[A\n"," 35% 645/1829 [00:10<00:20, 59.10it/s]\u001b[A\n"," 36% 651/1829 [00:10<00:19, 59.10it/s]\u001b[A\n"," 36% 657/1829 [00:11<00:19, 59.05it/s]\u001b[A\n"," 36% 663/1829 [00:11<00:19, 58.91it/s]\u001b[A\n"," 37% 669/1829 [00:11<00:19, 58.84it/s]\u001b[A\n"," 37% 675/1829 [00:11<00:19, 58.81it/s]\u001b[A\n"," 37% 681/1829 [00:11<00:19, 58.38it/s]\u001b[A\n"," 38% 687/1829 [00:11<00:19, 58.02it/s]\u001b[A\n"," 38% 693/1829 [00:11<00:19, 58.07it/s]\u001b[A\n"," 38% 699/1829 [00:11<00:19, 58.12it/s]\u001b[A\n"," 39% 705/1829 [00:11<00:19, 58.66it/s]\u001b[A\n"," 39% 711/1829 [00:11<00:19, 58.65it/s]\u001b[A\n"," 39% 717/1829 [00:12<00:18, 58.65it/s]\u001b[A\n"," 40% 723/1829 [00:12<00:18, 58.49it/s]\u001b[A\n"," 40% 729/1829 [00:12<00:18, 58.25it/s]\u001b[A\n"," 40% 735/1829 [00:12<00:18, 58.22it/s]\u001b[A\n"," 41% 741/1829 [00:12<00:18, 58.31it/s]\u001b[A\n"," 41% 747/1829 [00:12<00:18, 58.44it/s]\u001b[A\n"," 41% 753/1829 [00:12<00:18, 58.17it/s]\u001b[A\n"," 41% 759/1829 [00:12<00:18, 58.27it/s]\u001b[A\n"," 42% 765/1829 [00:12<00:18, 58.36it/s]\u001b[A\n"," 42% 771/1829 [00:13<00:18, 58.40it/s]\u001b[A\n"," 42% 777/1829 [00:13<00:18, 58.28it/s]\u001b[A\n"," 43% 783/1829 [00:13<00:17, 58.24it/s]\u001b[A\n"," 43% 789/1829 [00:13<00:17, 58.32it/s]\u001b[A\n"," 43% 795/1829 [00:13<00:17, 58.48it/s]\u001b[A\n"," 44% 801/1829 [00:13<00:17, 58.53it/s]\u001b[A\n"," 44% 807/1829 [00:13<00:17, 58.33it/s]\u001b[A\n"," 44% 813/1829 [00:13<00:17, 58.30it/s]\u001b[A\n"," 45% 819/1829 [00:13<00:17, 58.24it/s]\u001b[A\n"," 45% 825/1829 [00:13<00:17, 58.36it/s]\u001b[A\n"," 45% 831/1829 [00:14<00:17, 58.47it/s]\u001b[A\n"," 46% 837/1829 [00:14<00:16, 58.51it/s]\u001b[A\n"," 46% 843/1829 [00:14<00:16, 58.05it/s]\u001b[A\n"," 46% 849/1829 [00:14<00:16, 57.92it/s]\u001b[A\n"," 47% 855/1829 [00:14<00:16, 58.25it/s]\u001b[A\n"," 47% 861/1829 [00:14<00:16, 58.53it/s]\u001b[A\n"," 47% 867/1829 [00:14<00:16, 58.69it/s]\u001b[A\n"," 48% 873/1829 [00:14<00:16, 58.82it/s]\u001b[A\n"," 48% 879/1829 [00:14<00:16, 58.89it/s]\u001b[A\n"," 48% 885/1829 [00:14<00:16, 58.53it/s]\u001b[A\n"," 49% 891/1829 [00:15<00:16, 58.29it/s]\u001b[A\n"," 49% 897/1829 [00:15<00:16, 58.10it/s]\u001b[A\n"," 49% 903/1829 [00:15<00:16, 57.56it/s]\u001b[A\n"," 50% 909/1829 [00:15<00:15, 57.70it/s]\u001b[A\n"," 50% 915/1829 [00:15<00:15, 57.91it/s]\u001b[A\n"," 50% 921/1829 [00:15<00:15, 58.47it/s]\u001b[A\n"," 51% 927/1829 [00:15<00:15, 58.73it/s]\u001b[A\n"," 51% 933/1829 [00:15<00:15, 58.89it/s]\u001b[A\n"," 51% 939/1829 [00:15<00:15, 59.12it/s]\u001b[A\n"," 52% 945/1829 [00:15<00:14, 58.96it/s]\u001b[A\n"," 52% 951/1829 [00:16<00:15, 58.25it/s]\u001b[A\n"," 52% 957/1829 [00:16<00:14, 58.29it/s]\u001b[A\n"," 53% 963/1829 [00:16<00:14, 58.22it/s]\u001b[A\n"," 53% 969/1829 [00:16<00:14, 58.10it/s]\u001b[A\n"," 53% 975/1829 [00:16<00:14, 58.50it/s]\u001b[A\n"," 54% 981/1829 [00:16<00:14, 58.44it/s]\u001b[A\n"," 54% 987/1829 [00:16<00:14, 58.41it/s]\u001b[A\n"," 54% 993/1829 [00:16<00:14, 58.16it/s]\u001b[A\n"," 55% 999/1829 [00:16<00:14, 57.89it/s]\u001b[A\n"," 55% 1005/1829 [00:17<00:14, 57.43it/s]\u001b[A\n"," 55% 1011/1829 [00:17<00:14, 57.22it/s]\u001b[A\n"," 56% 1017/1829 [00:17<00:14, 57.50it/s]\u001b[A\n"," 56% 1023/1829 [00:17<00:13, 57.81it/s]\u001b[A\n"," 56% 1029/1829 [00:17<00:13, 57.71it/s]\u001b[A\n"," 57% 1035/1829 [00:17<00:13, 57.98it/s]\u001b[A\n"," 57% 1041/1829 [00:17<00:13, 58.45it/s]\u001b[A\n"," 57% 1047/1829 [00:17<00:13, 58.34it/s]\u001b[A\n"," 58% 1053/1829 [00:17<00:13, 57.96it/s]\u001b[A\n"," 58% 1059/1829 [00:17<00:13, 57.65it/s]\u001b[A\n"," 58% 1065/1829 [00:18<00:13, 57.80it/s]\u001b[A\n"," 59% 1071/1829 [00:18<00:13, 57.75it/s]\u001b[A\n"," 59% 1077/1829 [00:18<00:12, 58.08it/s]\u001b[A\n"," 59% 1083/1829 [00:18<00:12, 58.23it/s]\u001b[A\n"," 60% 1089/1829 [00:18<00:12, 57.94it/s]\u001b[A\n"," 60% 1095/1829 [00:18<00:12, 58.11it/s]\u001b[A\n"," 60% 1101/1829 [00:18<00:12, 58.21it/s]\u001b[A\n"," 61% 1107/1829 [00:18<00:12, 58.33it/s]\u001b[A\n"," 61% 1113/1829 [00:18<00:12, 58.52it/s]\u001b[A\n"," 61% 1119/1829 [00:18<00:12, 58.70it/s]\u001b[A\n"," 62% 1125/1829 [00:19<00:11, 58.99it/s]\u001b[A\n"," 62% 1131/1829 [00:19<00:11, 58.92it/s]\u001b[A\n"," 62% 1137/1829 [00:19<00:11, 59.01it/s]\u001b[A\n"," 62% 1143/1829 [00:19<00:11, 59.29it/s]\u001b[A\n"," 63% 1150/1829 [00:19<00:11, 59.65it/s]\u001b[A\n"," 63% 1156/1829 [00:19<00:11, 59.73it/s]\u001b[A\n"," 64% 1163/1829 [00:19<00:11, 59.87it/s]\u001b[A\n"," 64% 1169/1829 [00:19<00:11, 59.56it/s]\u001b[A\n"," 64% 1175/1829 [00:19<00:10, 59.57it/s]\u001b[A\n"," 65% 1181/1829 [00:20<00:10, 59.66it/s]\u001b[A\n"," 65% 1188/1829 [00:20<00:10, 59.87it/s]\u001b[A\n"," 65% 1195/1829 [00:20<00:10, 60.02it/s]\u001b[A\n"," 66% 1201/1829 [00:20<00:10, 60.00it/s]\u001b[A\n"," 66% 1208/1829 [00:20<00:10, 60.10it/s]\u001b[A\n"," 66% 1215/1829 [00:20<00:10, 60.09it/s]\u001b[A\n"," 67% 1222/1829 [00:20<00:10, 60.11it/s]\u001b[A\n"," 67% 1229/1829 [00:20<00:09, 60.30it/s]\u001b[A\n"," 68% 1236/1829 [00:20<00:09, 60.39it/s]\u001b[A\n"," 68% 1243/1829 [00:21<00:09, 60.27it/s]\u001b[A\n"," 68% 1250/1829 [00:21<00:09, 60.33it/s]\u001b[A\n"," 69% 1257/1829 [00:21<00:09, 60.03it/s]\u001b[A\n"," 69% 1264/1829 [00:21<00:09, 60.06it/s]\u001b[A\n"," 69% 1271/1829 [00:21<00:09, 59.82it/s]\u001b[A\n"," 70% 1277/1829 [00:21<00:09, 59.65it/s]\u001b[A\n"," 70% 1283/1829 [00:21<00:09, 59.43it/s]\u001b[A\n"," 70% 1289/1829 [00:21<00:09, 59.33it/s]\u001b[A\n"," 71% 1295/1829 [00:21<00:09, 59.18it/s]\u001b[A\n"," 71% 1301/1829 [00:22<00:08, 58.95it/s]\u001b[A\n"," 71% 1307/1829 [00:22<00:08, 59.03it/s]\u001b[A\n"," 72% 1314/1829 [00:22<00:08, 59.46it/s]\u001b[A\n"," 72% 1321/1829 [00:22<00:08, 59.75it/s]\u001b[A\n"," 73% 1328/1829 [00:22<00:08, 59.98it/s]\u001b[A\n"," 73% 1334/1829 [00:22<00:08, 59.30it/s]\u001b[A\n"," 73% 1340/1829 [00:22<00:08, 59.02it/s]\u001b[A\n"," 74% 1346/1829 [00:22<00:08, 59.04it/s]\u001b[A\n"," 74% 1352/1829 [00:22<00:08, 58.92it/s]\u001b[A\n"," 74% 1358/1829 [00:23<00:08, 58.84it/s]\u001b[A\n"," 75% 1364/1829 [00:23<00:07, 58.76it/s]\u001b[A\n"," 75% 1370/1829 [00:23<00:07, 58.68it/s]\u001b[A\n"," 75% 1376/1829 [00:23<00:07, 58.52it/s]\u001b[A\n"," 76% 1382/1829 [00:23<00:07, 58.60it/s]\u001b[A\n"," 76% 1388/1829 [00:23<00:07, 58.74it/s]\u001b[A\n"," 76% 1394/1829 [00:23<00:07, 58.87it/s]\u001b[A\n"," 77% 1400/1829 [00:23<00:07, 58.73it/s]\u001b[A\n"," 77% 1406/1829 [00:23<00:07, 58.54it/s]\u001b[A\n"," 77% 1412/1829 [00:23<00:07, 58.56it/s]\u001b[A\n"," 78% 1418/1829 [00:24<00:07, 58.63it/s]\u001b[A\n"," 78% 1424/1829 [00:24<00:06, 58.18it/s]\u001b[A\n"," 78% 1430/1829 [00:24<00:06, 58.34it/s]\u001b[A\n"," 79% 1436/1829 [00:24<00:06, 58.26it/s]\u001b[A\n"," 79% 1442/1829 [00:24<00:06, 58.08it/s]\u001b[A\n"," 79% 1448/1829 [00:24<00:06, 58.03it/s]\u001b[A\n"," 79% 1454/1829 [00:24<00:06, 58.17it/s]\u001b[A\n"," 80% 1460/1829 [00:24<00:06, 58.23it/s]\u001b[A\n"," 80% 1466/1829 [00:24<00:06, 58.31it/s]\u001b[A\n"," 80% 1472/1829 [00:24<00:06, 58.41it/s]\u001b[A\n"," 81% 1478/1829 [00:25<00:06, 58.28it/s]\u001b[A\n"," 81% 1484/1829 [00:25<00:05, 58.30it/s]\u001b[A\n"," 81% 1490/1829 [00:25<00:05, 58.34it/s]\u001b[A\n"," 82% 1496/1829 [00:25<00:05, 57.74it/s]\u001b[A\n"," 82% 1502/1829 [00:25<00:05, 57.79it/s]\u001b[A\n"," 82% 1508/1829 [00:25<00:05, 58.14it/s]\u001b[A\n"," 83% 1514/1829 [00:25<00:05, 58.14it/s]\u001b[A\n"," 83% 1520/1829 [00:25<00:05, 58.34it/s]\u001b[A\n"," 83% 1526/1829 [00:25<00:05, 58.24it/s]\u001b[A\n"," 84% 1532/1829 [00:25<00:05, 58.36it/s]\u001b[A\n"," 84% 1538/1829 [00:26<00:04, 58.31it/s]\u001b[A\n"," 84% 1544/1829 [00:26<00:04, 58.27it/s]\u001b[A\n"," 85% 1550/1829 [00:26<00:04, 58.43it/s]\u001b[A\n"," 85% 1556/1829 [00:26<00:04, 58.34it/s]\u001b[A\n"," 85% 1562/1829 [00:26<00:04, 58.36it/s]\u001b[A\n"," 86% 1569/1829 [00:26<00:04, 59.03it/s]\u001b[A\n"," 86% 1576/1829 [00:26<00:04, 59.44it/s]\u001b[A\n"," 87% 1583/1829 [00:26<00:04, 59.72it/s]\u001b[A\n"," 87% 1590/1829 [00:26<00:03, 59.88it/s]\u001b[A\n"," 87% 1596/1829 [00:27<00:03, 59.34it/s]\u001b[A\n"," 88% 1602/1829 [00:27<00:03, 58.79it/s]\u001b[A\n"," 88% 1608/1829 [00:27<00:03, 58.86it/s]\u001b[A\n"," 88% 1614/1829 [00:27<00:03, 58.67it/s]\u001b[A\n"," 89% 1620/1829 [00:27<00:03, 58.64it/s]\u001b[A\n"," 89% 1626/1829 [00:27<00:03, 58.81it/s]\u001b[A\n"," 89% 1632/1829 [00:27<00:03, 58.83it/s]\u001b[A\n"," 90% 1638/1829 [00:27<00:03, 58.68it/s]\u001b[A\n"," 90% 1644/1829 [00:27<00:03, 58.79it/s]\u001b[A\n"," 90% 1650/1829 [00:27<00:03, 58.80it/s]\u001b[A\n"," 91% 1656/1829 [00:28<00:02, 58.51it/s]\u001b[A\n"," 91% 1662/1829 [00:28<00:02, 58.01it/s]\u001b[A\n"," 91% 1668/1829 [00:28<00:02, 58.20it/s]\u001b[A\n"," 92% 1674/1829 [00:28<00:02, 58.29it/s]\u001b[A\n"," 92% 1680/1829 [00:28<00:02, 58.41it/s]\u001b[A\n"," 92% 1686/1829 [00:28<00:02, 58.23it/s]\u001b[A\n"," 93% 1692/1829 [00:28<00:02, 58.18it/s]\u001b[A\n"," 93% 1698/1829 [00:28<00:02, 58.10it/s]\u001b[A\n"," 93% 1704/1829 [00:28<00:02, 58.14it/s]\u001b[A\n"," 93% 1710/1829 [00:29<00:02, 58.52it/s]\u001b[A\n"," 94% 1716/1829 [00:29<00:01, 58.79it/s]\u001b[A\n"," 94% 1722/1829 [00:29<00:01, 58.95it/s]\u001b[A\n"," 94% 1728/1829 [00:29<00:01, 58.93it/s]\u001b[A\n"," 95% 1734/1829 [00:29<00:01, 59.13it/s]\u001b[A\n"," 95% 1740/1829 [00:29<00:01, 59.30it/s]\u001b[A\n"," 95% 1746/1829 [00:29<00:01, 59.21it/s]\u001b[A\n"," 96% 1752/1829 [00:29<00:01, 59.03it/s]\u001b[A\n"," 96% 1758/1829 [00:29<00:01, 58.97it/s]\u001b[A\n"," 96% 1764/1829 [00:29<00:01, 58.73it/s]\u001b[A\n"," 97% 1770/1829 [00:30<00:01, 58.56it/s]\u001b[A\n"," 97% 1776/1829 [00:30<00:00, 58.49it/s]\u001b[A\n"," 97% 1782/1829 [00:30<00:00, 58.55it/s]\u001b[A\n"," 98% 1788/1829 [00:30<00:00, 58.69it/s]\u001b[A\n"," 98% 1794/1829 [00:30<00:00, 58.93it/s]\u001b[A\n"," 98% 1800/1829 [00:30<00:00, 59.20it/s]\u001b[A\n"," 99% 1806/1829 [00:30<00:00, 59.28it/s]\u001b[A\n"," 99% 1812/1829 [00:30<00:00, 59.19it/s]\u001b[A\n"," 99% 1818/1829 [00:30<00:00, 59.00it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 0.06926951557397842, 'eval_accuracy': 0.9781954887218045, 'eval_precision': 0.9784424701319111, 'eval_recall': 0.9781954887218045, 'eval_f1': 0.97826692664012, 'eval_runtime': 31.0613, 'eval_samples_per_second': 471.005, 'eval_steps_per_second': 58.884, 'epoch': 3.0}\n"," 60% 2745/4575 [06:06<02:40, 11.43it/s]\n","100% 1829/1829 [00:31<00:00, 58.94it/s]\u001b[A\n","{'loss': 0.1337, 'grad_norm': 59.36812973022461, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 3660/4575 [07:38<01:26, 10.59it/s]\n","  0% 0/1829 [00:00<?, ?it/s]\u001b[A\n","  0% 7/1829 [00:00<00:26, 69.89it/s]\u001b[A\n","  1% 14/1829 [00:00<00:29, 61.71it/s]\u001b[A\n","  1% 21/1829 [00:00<00:30, 59.14it/s]\u001b[A\n","  1% 27/1829 [00:00<00:30, 58.99it/s]\u001b[A\n","  2% 33/1829 [00:00<00:30, 58.94it/s]\u001b[A\n","  2% 40/1829 [00:00<00:30, 59.30it/s]\u001b[A\n","  3% 46/1829 [00:00<00:30, 59.22it/s]\u001b[A\n","  3% 52/1829 [00:00<00:30, 58.97it/s]\u001b[A\n","  3% 58/1829 [00:00<00:30, 58.79it/s]\u001b[A\n","  3% 64/1829 [00:01<00:30, 58.66it/s]\u001b[A\n","  4% 70/1829 [00:01<00:30, 58.56it/s]\u001b[A\n","  4% 76/1829 [00:01<00:29, 58.59it/s]\u001b[A\n","  4% 82/1829 [00:01<00:29, 58.38it/s]\u001b[A\n","  5% 88/1829 [00:01<00:29, 58.46it/s]\u001b[A\n","  5% 94/1829 [00:01<00:29, 58.47it/s]\u001b[A\n","  5% 100/1829 [00:01<00:29, 58.02it/s]\u001b[A\n","  6% 106/1829 [00:01<00:29, 58.06it/s]\u001b[A\n","  6% 113/1829 [00:01<00:29, 58.83it/s]\u001b[A\n","  7% 120/1829 [00:02<00:28, 59.31it/s]\u001b[A\n","  7% 127/1829 [00:02<00:28, 59.62it/s]\u001b[A\n","  7% 134/1829 [00:02<00:28, 59.79it/s]\u001b[A\n","  8% 141/1829 [00:02<00:28, 59.99it/s]\u001b[A\n","  8% 148/1829 [00:02<00:27, 60.11it/s]\u001b[A\n","  8% 155/1829 [00:02<00:27, 60.16it/s]\u001b[A\n","  9% 162/1829 [00:02<00:27, 60.26it/s]\u001b[A\n","  9% 169/1829 [00:02<00:27, 60.14it/s]\u001b[A\n"," 10% 176/1829 [00:02<00:27, 59.99it/s]\u001b[A\n"," 10% 183/1829 [00:03<00:27, 60.06it/s]\u001b[A\n"," 10% 190/1829 [00:03<00:27, 59.91it/s]\u001b[A\n"," 11% 197/1829 [00:03<00:27, 59.99it/s]\u001b[A\n"," 11% 203/1829 [00:03<00:27, 59.95it/s]\u001b[A\n"," 11% 209/1829 [00:03<00:27, 59.94it/s]\u001b[A\n"," 12% 215/1829 [00:03<00:26, 59.95it/s]\u001b[A\n"," 12% 222/1829 [00:03<00:26, 60.07it/s]\u001b[A\n"," 13% 229/1829 [00:03<00:26, 59.97it/s]\u001b[A\n"," 13% 235/1829 [00:03<00:26, 59.96it/s]\u001b[A\n"," 13% 242/1829 [00:04<00:26, 60.18it/s]\u001b[A\n"," 14% 249/1829 [00:04<00:26, 60.28it/s]\u001b[A\n"," 14% 256/1829 [00:04<00:26, 60.44it/s]\u001b[A\n"," 14% 263/1829 [00:04<00:25, 60.44it/s]\u001b[A\n"," 15% 270/1829 [00:04<00:26, 59.95it/s]\u001b[A\n"," 15% 277/1829 [00:04<00:25, 60.01it/s]\u001b[A\n"," 16% 284/1829 [00:04<00:25, 60.08it/s]\u001b[A\n"," 16% 291/1829 [00:04<00:25, 60.15it/s]\u001b[A\n"," 16% 298/1829 [00:04<00:25, 60.32it/s]\u001b[A\n"," 17% 305/1829 [00:05<00:25, 60.43it/s]\u001b[A\n"," 17% 312/1829 [00:05<00:25, 60.43it/s]\u001b[A\n"," 17% 319/1829 [00:05<00:24, 60.54it/s]\u001b[A\n"," 18% 326/1829 [00:05<00:24, 60.58it/s]\u001b[A\n"," 18% 333/1829 [00:05<00:24, 60.62it/s]\u001b[A\n"," 19% 340/1829 [00:05<00:24, 60.56it/s]\u001b[A\n"," 19% 347/1829 [00:05<00:24, 60.42it/s]\u001b[A\n"," 19% 354/1829 [00:05<00:24, 60.31it/s]\u001b[A\n"," 20% 361/1829 [00:06<00:24, 60.40it/s]\u001b[A\n"," 20% 368/1829 [00:06<00:24, 60.33it/s]\u001b[A\n"," 21% 375/1829 [00:06<00:24, 60.43it/s]\u001b[A\n"," 21% 382/1829 [00:06<00:23, 60.50it/s]\u001b[A\n"," 21% 389/1829 [00:06<00:23, 60.56it/s]\u001b[A\n"," 22% 396/1829 [00:06<00:23, 60.57it/s]\u001b[A\n"," 22% 403/1829 [00:06<00:23, 60.58it/s]\u001b[A\n"," 22% 410/1829 [00:06<00:23, 60.42it/s]\u001b[A\n"," 23% 417/1829 [00:06<00:23, 60.23it/s]\u001b[A\n"," 23% 424/1829 [00:07<00:23, 60.27it/s]\u001b[A\n"," 24% 431/1829 [00:07<00:23, 59.83it/s]\u001b[A\n"," 24% 437/1829 [00:07<00:23, 59.53it/s]\u001b[A\n"," 24% 443/1829 [00:07<00:23, 59.39it/s]\u001b[A\n"," 25% 449/1829 [00:07<00:23, 59.41it/s]\u001b[A\n"," 25% 455/1829 [00:07<00:23, 59.47it/s]\u001b[A\n"," 25% 461/1829 [00:07<00:22, 59.54it/s]\u001b[A\n"," 26% 467/1829 [00:07<00:22, 59.62it/s]\u001b[A\n"," 26% 473/1829 [00:07<00:22, 59.57it/s]\u001b[A\n"," 26% 479/1829 [00:08<00:22, 59.57it/s]\u001b[A\n"," 27% 485/1829 [00:08<00:22, 59.09it/s]\u001b[A\n"," 27% 491/1829 [00:08<00:22, 58.85it/s]\u001b[A\n"," 27% 497/1829 [00:08<00:22, 58.76it/s]\u001b[A\n"," 28% 503/1829 [00:08<00:22, 58.75it/s]\u001b[A\n"," 28% 509/1829 [00:08<00:22, 58.74it/s]\u001b[A\n"," 28% 515/1829 [00:08<00:22, 58.54it/s]\u001b[A\n"," 28% 521/1829 [00:08<00:22, 58.54it/s]\u001b[A\n"," 29% 527/1829 [00:08<00:22, 58.43it/s]\u001b[A\n"," 29% 533/1829 [00:08<00:22, 58.36it/s]\u001b[A\n"," 29% 539/1829 [00:09<00:21, 58.79it/s]\u001b[A\n"," 30% 545/1829 [00:09<00:21, 59.07it/s]\u001b[A\n"," 30% 551/1829 [00:09<00:21, 59.26it/s]\u001b[A\n"," 30% 557/1829 [00:09<00:21, 59.43it/s]\u001b[A\n"," 31% 563/1829 [00:09<00:21, 59.37it/s]\u001b[A\n"," 31% 569/1829 [00:09<00:21, 58.93it/s]\u001b[A\n"," 31% 575/1829 [00:09<00:21, 59.21it/s]\u001b[A\n"," 32% 581/1829 [00:09<00:21, 59.29it/s]\u001b[A\n"," 32% 587/1829 [00:09<00:20, 59.37it/s]\u001b[A\n"," 32% 593/1829 [00:09<00:20, 59.43it/s]\u001b[A\n"," 33% 599/1829 [00:10<00:20, 59.47it/s]\u001b[A\n"," 33% 605/1829 [00:10<00:20, 59.22it/s]\u001b[A\n"," 33% 611/1829 [00:10<00:20, 58.99it/s]\u001b[A\n"," 34% 617/1829 [00:10<00:20, 58.80it/s]\u001b[A\n"," 34% 623/1829 [00:10<00:20, 58.56it/s]\u001b[A\n"," 34% 629/1829 [00:10<00:20, 58.62it/s]\u001b[A\n"," 35% 635/1829 [00:10<00:20, 58.40it/s]\u001b[A\n"," 35% 641/1829 [00:10<00:20, 58.46it/s]\u001b[A\n"," 35% 647/1829 [00:10<00:20, 58.49it/s]\u001b[A\n"," 36% 653/1829 [00:10<00:20, 58.54it/s]\u001b[A\n"," 36% 659/1829 [00:11<00:19, 58.59it/s]\u001b[A\n"," 36% 665/1829 [00:11<00:19, 58.56it/s]\u001b[A\n"," 37% 671/1829 [00:11<00:19, 58.60it/s]\u001b[A\n"," 37% 678/1829 [00:11<00:19, 59.17it/s]\u001b[A\n"," 37% 684/1829 [00:11<00:19, 59.40it/s]\u001b[A\n"," 80% 3660/4575 [07:50<01:26, 10.59it/s]\n"," 38% 698/1829 [00:11<00:18, 59.88it/s]\u001b[A\n"," 38% 704/1829 [00:11<00:18, 59.62it/s]\u001b[A\n"," 39% 710/1829 [00:11<00:18, 59.47it/s]\u001b[A\n"," 39% 716/1829 [00:12<00:18, 59.27it/s]\u001b[A\n"," 39% 722/1829 [00:12<00:18, 59.22it/s]\u001b[A\n"," 40% 728/1829 [00:12<00:18, 58.89it/s]\u001b[A\n"," 40% 734/1829 [00:12<00:18, 58.72it/s]\u001b[A\n"," 40% 740/1829 [00:12<00:18, 58.53it/s]\u001b[A\n"," 41% 746/1829 [00:12<00:18, 58.71it/s]\u001b[A\n"," 41% 752/1829 [00:12<00:18, 59.03it/s]\u001b[A\n"," 41% 759/1829 [00:12<00:17, 59.54it/s]\u001b[A\n"," 42% 765/1829 [00:12<00:17, 59.54it/s]\u001b[A\n"," 42% 771/1829 [00:12<00:17, 59.47it/s]\u001b[A\n"," 42% 777/1829 [00:13<00:17, 59.40it/s]\u001b[A\n"," 43% 783/1829 [00:13<00:17, 59.31it/s]\u001b[A\n"," 43% 789/1829 [00:13<00:17, 59.26it/s]\u001b[A\n"," 43% 795/1829 [00:13<00:17, 59.00it/s]\u001b[A\n"," 44% 801/1829 [00:13<00:17, 59.04it/s]\u001b[A\n"," 44% 807/1829 [00:13<00:17, 59.09it/s]\u001b[A\n"," 44% 813/1829 [00:13<00:17, 59.13it/s]\u001b[A\n"," 45% 819/1829 [00:13<00:17, 59.11it/s]\u001b[A\n"," 45% 825/1829 [00:13<00:16, 59.07it/s]\u001b[A\n"," 45% 831/1829 [00:13<00:16, 58.99it/s]\u001b[A\n"," 46% 837/1829 [00:14<00:16, 58.99it/s]\u001b[A\n"," 46% 843/1829 [00:14<00:16, 58.92it/s]\u001b[A\n"," 46% 849/1829 [00:14<00:16, 58.96it/s]\u001b[A\n"," 47% 855/1829 [00:14<00:16, 59.02it/s]\u001b[A\n"," 47% 861/1829 [00:14<00:16, 58.86it/s]\u001b[A\n"," 47% 867/1829 [00:14<00:16, 58.99it/s]\u001b[A\n"," 48% 873/1829 [00:14<00:16, 59.07it/s]\u001b[A\n"," 48% 879/1829 [00:14<00:16, 59.15it/s]\u001b[A\n"," 48% 885/1829 [00:14<00:15, 59.19it/s]\u001b[A\n"," 49% 891/1829 [00:14<00:15, 59.26it/s]\u001b[A\n"," 49% 897/1829 [00:15<00:15, 59.23it/s]\u001b[A\n"," 49% 903/1829 [00:15<00:15, 59.19it/s]\u001b[A\n"," 50% 909/1829 [00:15<00:15, 58.78it/s]\u001b[A\n"," 50% 915/1829 [00:15<00:15, 59.10it/s]\u001b[A\n"," 50% 922/1829 [00:15<00:15, 59.55it/s]\u001b[A\n"," 51% 928/1829 [00:15<00:15, 59.12it/s]\u001b[A\n"," 51% 934/1829 [00:15<00:15, 59.01it/s]\u001b[A\n"," 51% 940/1829 [00:15<00:15, 58.81it/s]\u001b[A\n"," 52% 946/1829 [00:15<00:14, 58.90it/s]\u001b[A\n"," 52% 952/1829 [00:16<00:14, 58.95it/s]\u001b[A\n"," 52% 958/1829 [00:16<00:14, 58.91it/s]\u001b[A\n"," 53% 964/1829 [00:16<00:14, 58.90it/s]\u001b[A\n"," 53% 970/1829 [00:16<00:14, 59.00it/s]\u001b[A\n"," 53% 976/1829 [00:16<00:14, 59.03it/s]\u001b[A\n"," 54% 982/1829 [00:16<00:14, 58.96it/s]\u001b[A\n"," 54% 988/1829 [00:16<00:14, 58.87it/s]\u001b[A\n"," 54% 994/1829 [00:16<00:14, 58.53it/s]\u001b[A\n"," 55% 1000/1829 [00:16<00:14, 58.45it/s]\u001b[A\n"," 55% 1006/1829 [00:16<00:14, 58.64it/s]\u001b[A\n"," 55% 1012/1829 [00:17<00:13, 58.78it/s]\u001b[A\n"," 56% 1018/1829 [00:17<00:13, 58.83it/s]\u001b[A\n"," 56% 1024/1829 [00:17<00:13, 58.90it/s]\u001b[A\n"," 56% 1031/1829 [00:17<00:13, 59.41it/s]\u001b[A\n"," 57% 1037/1829 [00:17<00:13, 58.62it/s]\u001b[A\n"," 57% 1043/1829 [00:17<00:13, 58.25it/s]\u001b[A\n"," 57% 1049/1829 [00:17<00:13, 58.41it/s]\u001b[A\n"," 58% 1055/1829 [00:17<00:13, 58.57it/s]\u001b[A\n"," 58% 1061/1829 [00:17<00:13, 58.51it/s]\u001b[A\n"," 58% 1067/1829 [00:17<00:12, 58.73it/s]\u001b[A\n"," 59% 1073/1829 [00:18<00:12, 58.88it/s]\u001b[A\n"," 59% 1079/1829 [00:18<00:12, 59.00it/s]\u001b[A\n"," 59% 1085/1829 [00:18<00:12, 59.13it/s]\u001b[A\n"," 60% 1091/1829 [00:18<00:12, 59.05it/s]\u001b[A\n"," 60% 1097/1829 [00:18<00:12, 59.09it/s]\u001b[A\n"," 60% 1103/1829 [00:18<00:12, 59.14it/s]\u001b[A\n"," 61% 1109/1829 [00:18<00:12, 59.15it/s]\u001b[A\n"," 61% 1115/1829 [00:18<00:12, 59.20it/s]\u001b[A\n"," 61% 1121/1829 [00:18<00:11, 59.19it/s]\u001b[A\n"," 62% 1127/1829 [00:18<00:11, 59.04it/s]\u001b[A\n"," 62% 1133/1829 [00:19<00:11, 59.20it/s]\u001b[A\n"," 62% 1139/1829 [00:19<00:11, 58.97it/s]\u001b[A\n"," 63% 1146/1829 [00:19<00:11, 59.38it/s]\u001b[A\n"," 63% 1153/1829 [00:19<00:11, 59.65it/s]\u001b[A\n"," 63% 1159/1829 [00:19<00:11, 59.41it/s]\u001b[A\n"," 64% 1166/1829 [00:19<00:11, 59.59it/s]\u001b[A\n"," 64% 1172/1829 [00:19<00:11, 59.65it/s]\u001b[A\n"," 64% 1179/1829 [00:19<00:10, 59.97it/s]\u001b[A\n"," 65% 1186/1829 [00:19<00:10, 60.11it/s]\u001b[A\n"," 65% 1193/1829 [00:20<00:10, 59.66it/s]\u001b[A\n"," 66% 1199/1829 [00:20<00:10, 59.16it/s]\u001b[A\n"," 66% 1205/1829 [00:20<00:10, 59.03it/s]\u001b[A\n"," 66% 1211/1829 [00:20<00:10, 58.92it/s]\u001b[A\n"," 67% 1217/1829 [00:20<00:10, 58.80it/s]\u001b[A\n"," 67% 1223/1829 [00:20<00:10, 58.98it/s]\u001b[A\n"," 67% 1229/1829 [00:20<00:10, 59.03it/s]\u001b[A\n"," 68% 1235/1829 [00:20<00:10, 58.81it/s]\u001b[A\n"," 68% 1241/1829 [00:20<00:10, 58.39it/s]\u001b[A\n"," 68% 1247/1829 [00:21<00:09, 58.44it/s]\u001b[A\n"," 69% 1253/1829 [00:21<00:09, 58.53it/s]\u001b[A\n"," 69% 1259/1829 [00:21<00:09, 58.37it/s]\u001b[A\n"," 69% 1265/1829 [00:21<00:09, 58.27it/s]\u001b[A\n"," 69% 1271/1829 [00:21<00:09, 57.99it/s]\u001b[A\n"," 70% 1277/1829 [00:21<00:09, 58.10it/s]\u001b[A\n"," 70% 1283/1829 [00:21<00:09, 58.05it/s]\u001b[A\n"," 70% 1289/1829 [00:21<00:09, 58.01it/s]\u001b[A\n"," 71% 1295/1829 [00:21<00:09, 57.75it/s]\u001b[A\n"," 71% 1301/1829 [00:21<00:09, 56.27it/s]\u001b[A\n"," 71% 1307/1829 [00:22<00:09, 56.54it/s]\u001b[A\n"," 72% 1313/1829 [00:22<00:09, 56.54it/s]\u001b[A\n"," 72% 1319/1829 [00:22<00:08, 56.67it/s]\u001b[A\n"," 72% 1325/1829 [00:22<00:08, 57.40it/s]\u001b[A\n"," 73% 1331/1829 [00:22<00:08, 57.82it/s]\u001b[A\n"," 73% 1337/1829 [00:22<00:08, 57.82it/s]\u001b[A\n"," 73% 1343/1829 [00:22<00:08, 57.39it/s]\u001b[A\n"," 74% 1349/1829 [00:22<00:08, 57.53it/s]\u001b[A\n"," 74% 1355/1829 [00:22<00:08, 57.86it/s]\u001b[A\n"," 74% 1361/1829 [00:22<00:08, 58.01it/s]\u001b[A\n"," 75% 1367/1829 [00:23<00:07, 58.24it/s]\u001b[A\n"," 75% 1373/1829 [00:23<00:07, 58.26it/s]\u001b[A\n"," 75% 1379/1829 [00:23<00:07, 58.14it/s]\u001b[A\n"," 76% 1385/1829 [00:23<00:07, 58.15it/s]\u001b[A\n"," 76% 1391/1829 [00:23<00:07, 58.18it/s]\u001b[A\n"," 76% 1397/1829 [00:23<00:07, 58.34it/s]\u001b[A\n"," 77% 1403/1829 [00:23<00:07, 58.26it/s]\u001b[A\n"," 77% 1409/1829 [00:23<00:07, 58.47it/s]\u001b[A\n"," 77% 1415/1829 [00:23<00:07, 58.67it/s]\u001b[A\n"," 78% 1422/1829 [00:24<00:06, 59.22it/s]\u001b[A\n"," 78% 1428/1829 [00:24<00:06, 59.13it/s]\u001b[A\n"," 78% 1434/1829 [00:24<00:06, 59.11it/s]\u001b[A\n"," 79% 1440/1829 [00:24<00:06, 59.23it/s]\u001b[A\n"," 79% 1447/1829 [00:24<00:06, 59.57it/s]\u001b[A\n"," 79% 1454/1829 [00:24<00:06, 59.71it/s]\u001b[A\n"," 80% 1460/1829 [00:24<00:06, 59.58it/s]\u001b[A\n"," 80% 1466/1829 [00:24<00:06, 59.58it/s]\u001b[A\n"," 80% 1472/1829 [00:24<00:05, 59.63it/s]\u001b[A\n"," 81% 1479/1829 [00:24<00:05, 59.82it/s]\u001b[A\n"," 81% 1485/1829 [00:25<00:05, 59.85it/s]\u001b[A\n"," 82% 1491/1829 [00:25<00:05, 59.79it/s]\u001b[A\n"," 82% 1497/1829 [00:25<00:05, 59.74it/s]\u001b[A\n"," 82% 1504/1829 [00:25<00:05, 59.89it/s]\u001b[A\n"," 83% 1510/1829 [00:25<00:05, 59.77it/s]\u001b[A\n"," 83% 1516/1829 [00:25<00:05, 59.72it/s]\u001b[A\n"," 83% 1522/1829 [00:25<00:05, 59.69it/s]\u001b[A\n"," 84% 1528/1829 [00:25<00:05, 59.61it/s]\u001b[A\n"," 84% 1534/1829 [00:25<00:04, 59.55it/s]\u001b[A\n"," 84% 1540/1829 [00:26<00:04, 59.54it/s]\u001b[A\n"," 85% 1546/1829 [00:26<00:04, 59.55it/s]\u001b[A\n"," 85% 1552/1829 [00:26<00:04, 59.60it/s]\u001b[A\n"," 85% 1558/1829 [00:26<00:04, 59.42it/s]\u001b[A\n"," 86% 1564/1829 [00:26<00:04, 59.42it/s]\u001b[A\n"," 86% 1570/1829 [00:26<00:04, 59.21it/s]\u001b[A\n"," 86% 1576/1829 [00:26<00:04, 59.33it/s]\u001b[A\n"," 86% 1582/1829 [00:26<00:04, 59.34it/s]\u001b[A\n"," 87% 1588/1829 [00:26<00:04, 59.37it/s]\u001b[A\n"," 87% 1594/1829 [00:26<00:03, 59.37it/s]\u001b[A\n"," 87% 1600/1829 [00:27<00:03, 59.39it/s]\u001b[A\n"," 88% 1606/1829 [00:27<00:03, 59.28it/s]\u001b[A\n"," 88% 1612/1829 [00:27<00:03, 59.13it/s]\u001b[A\n"," 88% 1618/1829 [00:27<00:03, 59.22it/s]\u001b[A\n"," 89% 1624/1829 [00:27<00:03, 59.29it/s]\u001b[A\n"," 89% 1630/1829 [00:27<00:03, 59.26it/s]\u001b[A\n"," 89% 1636/1829 [00:27<00:03, 59.37it/s]\u001b[A\n"," 90% 1643/1829 [00:27<00:03, 59.67it/s]\u001b[A\n"," 90% 1650/1829 [00:27<00:02, 60.02it/s]\u001b[A\n"," 91% 1657/1829 [00:27<00:02, 60.13it/s]\u001b[A\n"," 91% 1664/1829 [00:28<00:02, 60.26it/s]\u001b[A\n"," 91% 1671/1829 [00:28<00:02, 60.40it/s]\u001b[A\n"," 92% 1678/1829 [00:28<00:02, 60.31it/s]\u001b[A\n"," 92% 1685/1829 [00:28<00:02, 60.29it/s]\u001b[A\n"," 93% 1692/1829 [00:28<00:02, 60.30it/s]\u001b[A\n"," 93% 1699/1829 [00:28<00:02, 60.33it/s]\u001b[A\n"," 93% 1706/1829 [00:28<00:02, 60.27it/s]\u001b[A\n"," 94% 1713/1829 [00:28<00:01, 60.44it/s]\u001b[A\n"," 94% 1720/1829 [00:29<00:01, 60.53it/s]\u001b[A\n"," 94% 1727/1829 [00:29<00:01, 60.58it/s]\u001b[A\n"," 95% 1734/1829 [00:29<00:01, 60.62it/s]\u001b[A\n"," 95% 1741/1829 [00:29<00:01, 60.45it/s]\u001b[A\n"," 96% 1748/1829 [00:29<00:01, 60.33it/s]\u001b[A\n"," 96% 1755/1829 [00:29<00:01, 60.07it/s]\u001b[A\n"," 96% 1762/1829 [00:29<00:01, 60.01it/s]\u001b[A\n"," 97% 1769/1829 [00:29<00:00, 60.03it/s]\u001b[A\n"," 97% 1776/1829 [00:29<00:00, 60.13it/s]\u001b[A\n"," 97% 1783/1829 [00:30<00:00, 60.11it/s]\u001b[A\n"," 98% 1790/1829 [00:30<00:00, 60.00it/s]\u001b[A\n"," 98% 1797/1829 [00:30<00:00, 59.92it/s]\u001b[A\n"," 99% 1803/1829 [00:30<00:00, 59.73it/s]\u001b[A\n"," 99% 1809/1829 [00:30<00:00, 59.70it/s]\u001b[A\n"," 99% 1816/1829 [00:30<00:00, 59.82it/s]\u001b[A\n","100% 1822/1829 [00:30<00:00, 59.86it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 0.03878988325595856, 'eval_accuracy': 0.9912508544087492, 'eval_precision': 0.9912432189100892, 'eval_recall': 0.9912508544087492, 'eval_f1': 0.9912399077983243, 'eval_runtime': 30.8679, 'eval_samples_per_second': 473.955, 'eval_steps_per_second': 59.252, 'epoch': 4.0}\n"," 80% 3660/4575 [08:09<01:26, 10.59it/s]\n","100% 1829/1829 [00:30<00:00, 59.81it/s]\u001b[A\n","{'loss': 0.081, 'grad_norm': 0.15576742589473724, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 4575/4575 [09:47<00:00, 10.60it/s]\n","  0% 0/1829 [00:00<?, ?it/s]\u001b[A\n","  0% 6/1829 [00:00<00:31, 58.56it/s]\u001b[A\n","  1% 12/1829 [00:00<00:32, 55.10it/s]\u001b[A\n","  1% 18/1829 [00:00<00:31, 56.68it/s]\u001b[A\n","  1% 24/1829 [00:00<00:31, 57.36it/s]\u001b[A\n","  2% 30/1829 [00:00<00:31, 57.84it/s]\u001b[A\n","  2% 36/1829 [00:00<00:30, 58.28it/s]\u001b[A\n","  2% 42/1829 [00:00<00:30, 58.56it/s]\u001b[A\n","  3% 48/1829 [00:00<00:30, 58.81it/s]\u001b[A\n","  3% 55/1829 [00:00<00:29, 59.44it/s]\u001b[A\n","  3% 62/1829 [00:01<00:29, 59.81it/s]\u001b[A\n","  4% 69/1829 [00:01<00:29, 59.96it/s]\u001b[A\n","  4% 76/1829 [00:01<00:29, 60.14it/s]\u001b[A\n","  5% 83/1829 [00:01<00:29, 59.91it/s]\u001b[A\n","  5% 89/1829 [00:01<00:29, 59.79it/s]\u001b[A\n","  5% 96/1829 [00:01<00:28, 59.98it/s]\u001b[A\n","  6% 103/1829 [00:01<00:28, 60.20it/s]\u001b[A\n","  6% 110/1829 [00:01<00:28, 60.37it/s]\u001b[A\n","  6% 117/1829 [00:01<00:28, 60.51it/s]\u001b[A\n","  7% 124/1829 [00:02<00:28, 60.33it/s]\u001b[A\n","  7% 131/1829 [00:02<00:28, 60.39it/s]\u001b[A\n","  8% 138/1829 [00:02<00:27, 60.40it/s]\u001b[A\n","  8% 145/1829 [00:02<00:27, 60.35it/s]\u001b[A\n","  8% 152/1829 [00:02<00:27, 60.27it/s]\u001b[A\n","  9% 159/1829 [00:02<00:27, 60.32it/s]\u001b[A\n","  9% 166/1829 [00:02<00:27, 60.25it/s]\u001b[A\n","  9% 173/1829 [00:02<00:27, 60.04it/s]\u001b[A\n"," 10% 180/1829 [00:03<00:27, 59.87it/s]\u001b[A\n"," 10% 186/1829 [00:03<00:27, 59.44it/s]\u001b[A\n"," 10% 192/1829 [00:03<00:27, 59.58it/s]\u001b[A\n"," 11% 198/1829 [00:03<00:27, 59.24it/s]\u001b[A\n"," 11% 204/1829 [00:03<00:27, 58.95it/s]\u001b[A\n"," 11% 210/1829 [00:03<00:27, 59.00it/s]\u001b[A\n"," 12% 216/1829 [00:03<00:27, 59.01it/s]\u001b[A\n"," 12% 222/1829 [00:03<00:27, 58.50it/s]\u001b[A\n"," 12% 228/1829 [00:03<00:27, 57.95it/s]\u001b[A\n"," 13% 234/1829 [00:03<00:27, 58.22it/s]\u001b[A\n"," 13% 240/1829 [00:04<00:27, 58.44it/s]\u001b[A\n"," 13% 246/1829 [00:04<00:27, 57.98it/s]\u001b[A\n"," 14% 252/1829 [00:04<00:27, 56.60it/s]\u001b[A\n"," 14% 258/1829 [00:04<00:28, 55.62it/s]\u001b[A\n"," 14% 264/1829 [00:04<00:28, 54.93it/s]\u001b[A\n"," 15% 270/1829 [00:04<00:28, 54.60it/s]\u001b[A\n"," 15% 276/1829 [00:04<00:28, 54.56it/s]\u001b[A\n"," 15% 282/1829 [00:04<00:28, 54.57it/s]\u001b[A\n"," 16% 288/1829 [00:04<00:28, 54.28it/s]\u001b[A\n"," 16% 294/1829 [00:05<00:28, 54.23it/s]\u001b[A\n"," 16% 300/1829 [00:05<00:28, 54.14it/s]\u001b[A\n"," 17% 306/1829 [00:05<00:28, 54.02it/s]\u001b[A\n"," 17% 312/1829 [00:05<00:28, 54.01it/s]\u001b[A\n"," 17% 318/1829 [00:05<00:28, 53.66it/s]\u001b[A\n"," 18% 324/1829 [00:05<00:28, 52.50it/s]\u001b[A\n"," 18% 330/1829 [00:05<00:28, 52.59it/s]\u001b[A\n"," 18% 336/1829 [00:05<00:28, 52.59it/s]\u001b[A\n"," 19% 342/1829 [00:05<00:28, 51.84it/s]\u001b[A\n"," 19% 348/1829 [00:06<00:29, 50.44it/s]\u001b[A\n"," 19% 354/1829 [00:06<00:29, 50.20it/s]\u001b[A\n"," 20% 360/1829 [00:06<00:28, 50.86it/s]\u001b[A\n"," 20% 366/1829 [00:06<00:29, 50.29it/s]\u001b[A\n"," 20% 372/1829 [00:06<00:28, 51.07it/s]\u001b[A\n"," 21% 378/1829 [00:06<00:28, 50.42it/s]\u001b[A\n"," 21% 384/1829 [00:06<00:29, 49.39it/s]\u001b[A\n"," 21% 389/1829 [00:06<00:29, 48.80it/s]\u001b[A\n"," 22% 394/1829 [00:07<00:29, 48.35it/s]\u001b[A\n"," 22% 400/1829 [00:07<00:29, 49.23it/s]\u001b[A\n"," 22% 405/1829 [00:07<00:29, 48.87it/s]\u001b[A\n"," 22% 410/1829 [00:07<00:29, 48.48it/s]\u001b[A\n"," 23% 415/1829 [00:07<00:29, 48.43it/s]\u001b[A\n"," 23% 420/1829 [00:07<00:28, 48.60it/s]\u001b[A\n"," 23% 426/1829 [00:07<00:28, 49.17it/s]\u001b[A\n","100% 4575/4575 [09:55<00:00, 10.60it/s]\n"," 24% 437/1829 [00:07<00:28, 49.06it/s]\u001b[A\n"," 24% 442/1829 [00:07<00:28, 48.84it/s]\u001b[A\n"," 24% 447/1829 [00:08<00:28, 48.65it/s]\u001b[A\n"," 25% 452/1829 [00:08<00:28, 48.87it/s]\u001b[A\n"," 25% 457/1829 [00:08<00:28, 48.29it/s]\u001b[A\n"," 25% 462/1829 [00:08<00:28, 48.71it/s]\u001b[A\n"," 26% 467/1829 [00:08<00:28, 48.19it/s]\u001b[A\n"," 26% 472/1829 [00:08<00:27, 48.50it/s]\u001b[A\n"," 26% 478/1829 [00:08<00:27, 49.36it/s]\u001b[A\n"," 26% 484/1829 [00:08<00:26, 49.90it/s]\u001b[A\n"," 27% 490/1829 [00:08<00:26, 51.40it/s]\u001b[A\n"," 27% 496/1829 [00:09<00:25, 52.47it/s]\u001b[A\n"," 27% 502/1829 [00:09<00:25, 52.92it/s]\u001b[A\n"," 28% 508/1829 [00:09<00:25, 52.63it/s]\u001b[A\n"," 28% 514/1829 [00:09<00:25, 52.16it/s]\u001b[A\n"," 28% 520/1829 [00:09<00:25, 52.10it/s]\u001b[A\n"," 29% 526/1829 [00:09<00:24, 52.61it/s]\u001b[A\n"," 29% 532/1829 [00:09<00:24, 53.17it/s]\u001b[A\n"," 29% 538/1829 [00:09<00:24, 52.85it/s]\u001b[A\n"," 30% 544/1829 [00:09<00:24, 53.03it/s]\u001b[A\n"," 30% 550/1829 [00:10<00:23, 53.31it/s]\u001b[A\n"," 30% 556/1829 [00:10<00:23, 53.26it/s]\u001b[A\n"," 31% 562/1829 [00:10<00:23, 53.62it/s]\u001b[A\n"," 31% 568/1829 [00:10<00:23, 53.45it/s]\u001b[A\n"," 31% 574/1829 [00:10<00:23, 53.10it/s]\u001b[A\n"," 32% 580/1829 [00:10<00:23, 53.27it/s]\u001b[A\n"," 32% 586/1829 [00:10<00:22, 54.41it/s]\u001b[A\n"," 32% 592/1829 [00:10<00:22, 55.96it/s]\u001b[A\n"," 33% 598/1829 [00:10<00:21, 57.09it/s]\u001b[A\n"," 33% 604/1829 [00:11<00:21, 57.80it/s]\u001b[A\n"," 33% 610/1829 [00:11<00:21, 57.87it/s]\u001b[A\n"," 34% 616/1829 [00:11<00:20, 58.39it/s]\u001b[A\n"," 34% 622/1829 [00:11<00:20, 58.83it/s]\u001b[A\n"," 34% 629/1829 [00:11<00:20, 59.27it/s]\u001b[A\n"," 35% 635/1829 [00:11<00:20, 59.43it/s]\u001b[A\n"," 35% 641/1829 [00:11<00:19, 59.41it/s]\u001b[A\n"," 35% 647/1829 [00:11<00:19, 59.53it/s]\u001b[A\n"," 36% 653/1829 [00:11<00:19, 59.37it/s]\u001b[A\n"," 36% 659/1829 [00:11<00:19, 59.18it/s]\u001b[A\n"," 36% 665/1829 [00:12<00:19, 59.09it/s]\u001b[A\n"," 37% 671/1829 [00:12<00:19, 59.11it/s]\u001b[A\n"," 37% 677/1829 [00:12<00:19, 58.79it/s]\u001b[A\n"," 37% 683/1829 [00:12<00:19, 58.52it/s]\u001b[A\n"," 38% 689/1829 [00:12<00:19, 58.53it/s]\u001b[A\n"," 38% 695/1829 [00:12<00:19, 58.58it/s]\u001b[A\n"," 38% 701/1829 [00:12<00:19, 58.51it/s]\u001b[A\n"," 39% 707/1829 [00:12<00:19, 58.54it/s]\u001b[A\n"," 39% 713/1829 [00:12<00:19, 58.68it/s]\u001b[A\n"," 39% 719/1829 [00:13<00:18, 58.74it/s]\u001b[A\n"," 40% 725/1829 [00:13<00:18, 58.98it/s]\u001b[A\n"," 40% 732/1829 [00:13<00:18, 59.38it/s]\u001b[A\n"," 40% 738/1829 [00:13<00:18, 59.46it/s]\u001b[A\n"," 41% 744/1829 [00:13<00:18, 59.48it/s]\u001b[A\n"," 41% 750/1829 [00:13<00:18, 59.61it/s]\u001b[A\n"," 41% 757/1829 [00:13<00:17, 59.75it/s]\u001b[A\n"," 42% 763/1829 [00:13<00:17, 59.79it/s]\u001b[A\n"," 42% 769/1829 [00:13<00:17, 59.39it/s]\u001b[A\n"," 42% 775/1829 [00:13<00:17, 59.56it/s]\u001b[A\n"," 43% 781/1829 [00:14<00:17, 59.59it/s]\u001b[A\n"," 43% 788/1829 [00:14<00:17, 59.81it/s]\u001b[A\n"," 43% 795/1829 [00:14<00:17, 59.93it/s]\u001b[A\n"," 44% 802/1829 [00:14<00:17, 59.98it/s]\u001b[A\n"," 44% 808/1829 [00:14<00:17, 59.94it/s]\u001b[A\n"," 45% 814/1829 [00:14<00:16, 59.94it/s]\u001b[A\n"," 45% 820/1829 [00:14<00:16, 59.82it/s]\u001b[A\n"," 45% 826/1829 [00:14<00:16, 59.81it/s]\u001b[A\n"," 45% 832/1829 [00:14<00:16, 59.57it/s]\u001b[A\n"," 46% 838/1829 [00:14<00:16, 59.31it/s]\u001b[A\n"," 46% 844/1829 [00:15<00:16, 58.25it/s]\u001b[A\n"," 46% 850/1829 [00:15<00:16, 57.60it/s]\u001b[A\n"," 47% 856/1829 [00:15<00:16, 57.64it/s]\u001b[A\n"," 47% 862/1829 [00:15<00:16, 58.05it/s]\u001b[A\n"," 47% 868/1829 [00:15<00:16, 58.39it/s]\u001b[A\n"," 48% 874/1829 [00:15<00:16, 58.79it/s]\u001b[A\n"," 48% 880/1829 [00:15<00:16, 58.99it/s]\u001b[A\n"," 48% 886/1829 [00:15<00:15, 59.21it/s]\u001b[A\n"," 49% 892/1829 [00:15<00:15, 59.32it/s]\u001b[A\n"," 49% 898/1829 [00:16<00:15, 59.14it/s]\u001b[A\n"," 49% 904/1829 [00:16<00:15, 59.24it/s]\u001b[A\n"," 50% 910/1829 [00:16<00:15, 59.26it/s]\u001b[A\n"," 50% 916/1829 [00:16<00:15, 59.28it/s]\u001b[A\n"," 50% 922/1829 [00:16<00:15, 59.03it/s]\u001b[A\n"," 51% 928/1829 [00:16<00:15, 58.80it/s]\u001b[A\n"," 51% 934/1829 [00:16<00:15, 58.93it/s]\u001b[A\n"," 51% 940/1829 [00:16<00:15, 58.94it/s]\u001b[A\n"," 52% 946/1829 [00:16<00:14, 59.01it/s]\u001b[A\n"," 52% 952/1829 [00:16<00:14, 59.21it/s]\u001b[A\n"," 52% 958/1829 [00:17<00:14, 59.36it/s]\u001b[A\n"," 53% 964/1829 [00:17<00:14, 59.10it/s]\u001b[A\n"," 53% 970/1829 [00:17<00:14, 59.22it/s]\u001b[A\n"," 53% 976/1829 [00:17<00:14, 59.22it/s]\u001b[A\n"," 54% 982/1829 [00:17<00:14, 58.91it/s]\u001b[A\n"," 54% 988/1829 [00:17<00:14, 58.35it/s]\u001b[A\n"," 54% 994/1829 [00:17<00:14, 57.96it/s]\u001b[A\n"," 55% 1000/1829 [00:17<00:14, 57.41it/s]\u001b[A\n"," 55% 1006/1829 [00:17<00:14, 57.06it/s]\u001b[A\n"," 55% 1012/1829 [00:17<00:14, 57.61it/s]\u001b[A\n"," 56% 1018/1829 [00:18<00:13, 58.01it/s]\u001b[A\n"," 56% 1024/1829 [00:18<00:13, 58.12it/s]\u001b[A\n"," 56% 1030/1829 [00:18<00:13, 58.48it/s]\u001b[A\n"," 57% 1036/1829 [00:18<00:13, 58.78it/s]\u001b[A\n"," 57% 1042/1829 [00:18<00:13, 58.94it/s]\u001b[A\n"," 57% 1048/1829 [00:18<00:13, 59.04it/s]\u001b[A\n"," 58% 1054/1829 [00:18<00:13, 58.98it/s]\u001b[A\n"," 58% 1060/1829 [00:18<00:13, 59.07it/s]\u001b[A\n"," 58% 1066/1829 [00:18<00:12, 58.82it/s]\u001b[A\n"," 59% 1072/1829 [00:18<00:12, 58.56it/s]\u001b[A\n"," 59% 1078/1829 [00:19<00:12, 58.38it/s]\u001b[A\n"," 59% 1084/1829 [00:19<00:12, 57.86it/s]\u001b[A\n"," 60% 1090/1829 [00:19<00:12, 57.91it/s]\u001b[A\n"," 60% 1096/1829 [00:19<00:12, 57.94it/s]\u001b[A\n"," 60% 1102/1829 [00:19<00:12, 58.07it/s]\u001b[A\n"," 61% 1108/1829 [00:19<00:12, 57.77it/s]\u001b[A\n"," 61% 1114/1829 [00:19<00:12, 57.40it/s]\u001b[A\n"," 61% 1120/1829 [00:19<00:12, 56.85it/s]\u001b[A\n"," 62% 1126/1829 [00:19<00:12, 56.21it/s]\u001b[A\n"," 62% 1132/1829 [00:20<00:12, 56.10it/s]\u001b[A\n"," 62% 1138/1829 [00:20<00:12, 56.92it/s]\u001b[A\n"," 63% 1144/1829 [00:20<00:11, 57.41it/s]\u001b[A\n"," 63% 1150/1829 [00:20<00:11, 58.01it/s]\u001b[A\n"," 63% 1156/1829 [00:20<00:11, 58.10it/s]\u001b[A\n"," 64% 1162/1829 [00:20<00:11, 58.06it/s]\u001b[A\n"," 64% 1168/1829 [00:20<00:11, 58.21it/s]\u001b[A\n"," 64% 1174/1829 [00:20<00:11, 58.09it/s]\u001b[A\n"," 65% 1180/1829 [00:20<00:11, 57.50it/s]\u001b[A\n"," 65% 1186/1829 [00:20<00:11, 57.16it/s]\u001b[A\n"," 65% 1192/1829 [00:21<00:11, 56.50it/s]\u001b[A\n"," 66% 1198/1829 [00:21<00:11, 56.52it/s]\u001b[A\n"," 66% 1204/1829 [00:21<00:10, 57.14it/s]\u001b[A\n"," 66% 1210/1829 [00:21<00:10, 57.63it/s]\u001b[A\n"," 66% 1216/1829 [00:21<00:10, 58.00it/s]\u001b[A\n"," 67% 1222/1829 [00:21<00:10, 57.67it/s]\u001b[A\n"," 67% 1228/1829 [00:21<00:10, 56.95it/s]\u001b[A\n"," 67% 1234/1829 [00:21<00:10, 56.27it/s]\u001b[A\n"," 68% 1240/1829 [00:21<00:10, 56.03it/s]\u001b[A\n"," 68% 1246/1829 [00:22<00:10, 56.51it/s]\u001b[A\n"," 68% 1252/1829 [00:22<00:10, 57.49it/s]\u001b[A\n"," 69% 1258/1829 [00:22<00:09, 57.94it/s]\u001b[A\n"," 69% 1264/1829 [00:22<00:09, 58.45it/s]\u001b[A\n"," 69% 1271/1829 [00:22<00:09, 59.01it/s]\u001b[A\n"," 70% 1278/1829 [00:22<00:09, 59.43it/s]\u001b[A\n"," 70% 1285/1829 [00:22<00:09, 59.80it/s]\u001b[A\n"," 71% 1292/1829 [00:22<00:08, 60.08it/s]\u001b[A\n"," 71% 1299/1829 [00:22<00:08, 60.26it/s]\u001b[A\n"," 71% 1306/1829 [00:23<00:08, 60.42it/s]\u001b[A\n"," 72% 1313/1829 [00:23<00:08, 60.41it/s]\u001b[A\n"," 72% 1320/1829 [00:23<00:08, 60.40it/s]\u001b[A\n"," 73% 1327/1829 [00:23<00:08, 60.30it/s]\u001b[A\n"," 73% 1334/1829 [00:23<00:08, 60.32it/s]\u001b[A\n"," 73% 1341/1829 [00:23<00:08, 60.35it/s]\u001b[A\n"," 74% 1348/1829 [00:23<00:07, 60.41it/s]\u001b[A\n"," 74% 1355/1829 [00:23<00:07, 60.42it/s]\u001b[A\n"," 74% 1362/1829 [00:23<00:07, 60.44it/s]\u001b[A\n"," 75% 1369/1829 [00:24<00:07, 60.52it/s]\u001b[A\n"," 75% 1376/1829 [00:24<00:07, 60.57it/s]\u001b[A\n"," 76% 1383/1829 [00:24<00:07, 60.59it/s]\u001b[A\n"," 76% 1390/1829 [00:24<00:07, 60.37it/s]\u001b[A\n"," 76% 1397/1829 [00:24<00:07, 60.07it/s]\u001b[A\n"," 77% 1404/1829 [00:24<00:07, 60.02it/s]\u001b[A\n"," 77% 1411/1829 [00:24<00:06, 60.11it/s]\u001b[A\n"," 78% 1418/1829 [00:24<00:06, 60.16it/s]\u001b[A\n"," 78% 1425/1829 [00:25<00:06, 60.15it/s]\u001b[A\n"," 78% 1432/1829 [00:25<00:06, 60.28it/s]\u001b[A\n"," 79% 1439/1829 [00:25<00:06, 60.22it/s]\u001b[A\n"," 79% 1446/1829 [00:25<00:06, 60.18it/s]\u001b[A\n"," 79% 1453/1829 [00:25<00:06, 60.08it/s]\u001b[A\n"," 80% 1460/1829 [00:25<00:06, 60.08it/s]\u001b[A\n"," 80% 1467/1829 [00:25<00:06, 60.16it/s]\u001b[A\n"," 81% 1474/1829 [00:25<00:05, 60.22it/s]\u001b[A\n"," 81% 1481/1829 [00:25<00:05, 60.21it/s]\u001b[A\n"," 81% 1488/1829 [00:26<00:05, 60.22it/s]\u001b[A\n"," 82% 1495/1829 [00:26<00:05, 60.11it/s]\u001b[A\n"," 82% 1502/1829 [00:26<00:05, 60.19it/s]\u001b[A\n"," 83% 1509/1829 [00:26<00:05, 60.11it/s]\u001b[A\n"," 83% 1516/1829 [00:26<00:05, 60.24it/s]\u001b[A\n"," 83% 1523/1829 [00:26<00:05, 60.32it/s]\u001b[A\n"," 84% 1530/1829 [00:26<00:04, 60.43it/s]\u001b[A\n"," 84% 1537/1829 [00:26<00:04, 60.53it/s]\u001b[A\n"," 84% 1544/1829 [00:26<00:04, 60.59it/s]\u001b[A\n"," 85% 1551/1829 [00:27<00:04, 60.17it/s]\u001b[A\n"," 85% 1558/1829 [00:27<00:04, 60.11it/s]\u001b[A\n"," 86% 1565/1829 [00:27<00:04, 60.13it/s]\u001b[A\n"," 86% 1572/1829 [00:27<00:04, 60.17it/s]\u001b[A\n"," 86% 1579/1829 [00:27<00:04, 60.32it/s]\u001b[A\n"," 87% 1586/1829 [00:27<00:04, 60.26it/s]\u001b[A\n"," 87% 1593/1829 [00:27<00:03, 60.35it/s]\u001b[A\n"," 87% 1600/1829 [00:27<00:03, 60.37it/s]\u001b[A\n"," 88% 1607/1829 [00:28<00:03, 60.41it/s]\u001b[A\n"," 88% 1614/1829 [00:28<00:03, 60.55it/s]\u001b[A\n"," 89% 1621/1829 [00:28<00:03, 60.51it/s]\u001b[A\n"," 89% 1628/1829 [00:28<00:03, 60.38it/s]\u001b[A\n"," 89% 1635/1829 [00:28<00:03, 60.29it/s]\u001b[A\n"," 90% 1642/1829 [00:28<00:03, 60.33it/s]\u001b[A\n"," 90% 1649/1829 [00:28<00:02, 60.33it/s]\u001b[A\n"," 91% 1656/1829 [00:28<00:02, 60.39it/s]\u001b[A\n"," 91% 1663/1829 [00:28<00:02, 60.13it/s]\u001b[A\n"," 91% 1670/1829 [00:29<00:02, 60.12it/s]\u001b[A\n"," 92% 1677/1829 [00:29<00:02, 60.21it/s]\u001b[A\n"," 92% 1684/1829 [00:29<00:02, 60.08it/s]\u001b[A\n"," 92% 1691/1829 [00:29<00:02, 60.06it/s]\u001b[A\n"," 93% 1698/1829 [00:29<00:02, 60.07it/s]\u001b[A\n"," 93% 1705/1829 [00:29<00:02, 60.18it/s]\u001b[A\n"," 94% 1712/1829 [00:29<00:01, 59.83it/s]\u001b[A\n"," 94% 1718/1829 [00:29<00:01, 59.81it/s]\u001b[A\n"," 94% 1724/1829 [00:29<00:01, 59.81it/s]\u001b[A\n"," 95% 1730/1829 [00:30<00:01, 59.61it/s]\u001b[A\n"," 95% 1736/1829 [00:30<00:01, 59.14it/s]\u001b[A\n"," 95% 1742/1829 [00:30<00:01, 58.81it/s]\u001b[A\n"," 96% 1748/1829 [00:30<00:01, 58.55it/s]\u001b[A\n"," 96% 1754/1829 [00:30<00:01, 58.66it/s]\u001b[A\n"," 96% 1760/1829 [00:30<00:01, 58.81it/s]\u001b[A\n"," 97% 1766/1829 [00:30<00:01, 58.88it/s]\u001b[A\n"," 97% 1772/1829 [00:30<00:00, 58.95it/s]\u001b[A\n"," 97% 1778/1829 [00:30<00:00, 58.99it/s]\u001b[A\n"," 98% 1784/1829 [00:30<00:00, 59.00it/s]\u001b[A\n"," 98% 1790/1829 [00:31<00:00, 59.04it/s]\u001b[A\n"," 98% 1796/1829 [00:31<00:00, 58.96it/s]\u001b[A\n"," 99% 1803/1829 [00:31<00:00, 59.25it/s]\u001b[A\n"," 99% 1809/1829 [00:31<00:00, 59.33it/s]\u001b[A\n"," 99% 1815/1829 [00:31<00:00, 59.27it/s]\u001b[A\n","100% 1821/1829 [00:31<00:00, 59.29it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 0.02645595744252205, 'eval_accuracy': 0.9948735475051265, 'eval_precision': 0.9948734999146758, 'eval_recall': 0.9948735475051265, 'eval_f1': 0.994872016689101, 'eval_runtime': 31.7725, 'eval_samples_per_second': 460.462, 'eval_steps_per_second': 57.566, 'epoch': 5.0}\n","100% 4575/4575 [10:19<00:00, 10.60it/s]\n","100% 1829/1829 [00:31<00:00, 59.42it/s]\u001b[A\n","{'train_runtime': 629.556, 'train_samples_per_second': 116.193, 'train_steps_per_second': 7.267, 'train_loss': 0.2837980326668161, 'epoch': 5.0}\n","100% 4575/4575 [10:29<00:00,  7.27it/s]\n","100% 1829/1829 [00:31<00:00, 57.73it/s]\n","Evaluation results:\n","{'eval_loss': 0.02645595744252205, 'eval_accuracy': 0.9948735475051265, 'eval_precision': 0.9948734999146758, 'eval_recall': 0.9948735475051265, 'eval_f1': 0.994872016689101, 'eval_runtime': 31.7016, 'eval_samples_per_second': 461.491, 'eval_steps_per_second': 57.694, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-nagation-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/xy8wuta5\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241202_181542-xy8wuta5/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/negation_attribution \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R2_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/negation_attribution_anli_r2_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_uy1TkCieQp","executionInfo":{"status":"ok","timestamp":1733166196312,"user_tz":360,"elapsed":745992,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"2042a5cd-f117-4a71-807a-6c0c64bd92d3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 18:51:01.863125: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 18:51:01.878524: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 18:51:01.883021: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 18:51:01.894120: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 18:51:03.112292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","README.md: 100% 20.8k/20.8k [00:00<00:00, 64.3MB/s]\n","train-00000-of-00001.parquet: 100% 50.2M/50.2M [00:03<00:00, 14.9MB/s]\n","test-00000-of-00001.parquet: 100% 308k/308k [00:00<00:00, 386MB/s]\n","validation-00000-of-00001.parquet: 100% 157k/157k [00:00<00:00, 2.47MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 738827.43 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 593198.48 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 525607.30 examples/s]\n","train-00000-of-00001.parquet: 100% 70.0M/70.0M [00:01<00:00, 37.6MB/s]\n","test-00000-of-00001.parquet: 100% 477k/477k [00:00<00:00, 380MB/s]\n","validation-00000-of-00001.parquet: 100% 239k/239k [00:00<00:00, 1.35MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 609965.64 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 558230.30 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 481614.80 examples/s]\n","Map: 100% 392702/392702 [00:13<00:00, 29083.64 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 36398.86 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 35953.78 examples/s]\n","Map: 100% 392702/392702 [00:13<00:00, 29666.74 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 35828.70 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 35979.91 examples/s]\n","Generating test split: 2000 examples [00:00, 3289.63 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2875.63 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:329: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7364.24 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7473.01 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:44<00:00,  1.19it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:44<00:00,  1.19it/s]\n","{'eval_loss': 4.091798305511475, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.384, 'eval_precision': 0.38439714845562833, 'eval_recall': 0.384, 'eval_f1': 0.3793838637937607, 'eval_runtime': 114.5064, 'eval_samples_per_second': 8.733, 'eval_steps_per_second': 1.092}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:42<00:00,  1.22it/s]\n","{'eval_loss': 3.9308924674987793, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.381, 'eval_precision': 0.37574572349292495, 'eval_recall': 0.381, 'eval_f1': 0.37290274698444026, 'eval_runtime': 103.3254, 'eval_samples_per_second': 9.678, 'eval_steps_per_second': 1.21}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:29<00:00,  1.20it/s]\n","{'eval_loss': 4.011345386505127, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.3825, 'eval_precision': 0.3799682659370559, 'eval_recall': 0.3825, 'eval_f1': 0.37663793123561334, 'eval_runtime': 209.9761, 'eval_samples_per_second': 9.525, 'eval_steps_per_second': 1.191}\n","100% 125/125 [01:47<00:00,  1.17it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/negation_attribution_anli_r2_test/misclassified_English.jsonl\n","100% 125/125 [01:44<00:00,  1.19it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/negation_attribution_anli_r2_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m:\n","\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/My Drive/nlp_final_project/wandb/offline-run-20241202_185117-okvuvxol\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241202_185117-okvuvxol/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset cointegrated/nli-rus-translated-v2021 \\\n","    --source_filter anli_r1 \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_anli_en_ru_bert_2/r1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I8LllgQRiflr","executionInfo":{"status":"ok","timestamp":1733168169842,"user_tz":360,"elapsed":1175776,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"621f36f3-f665-4126-c68e-f512a281e86d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 19:16:44.343531: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-02 19:16:44.359914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 19:16:44.380883: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 19:16:44.387229: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 19:16:44.402531: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 19:16:45.640166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241202_191716-yd7wq6er\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/yd7wq6er\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","README.md: 100% 2.49k/2.49k [00:00<00:00, 13.6MB/s]\n","(…)-00000-of-00003-bf0537f750691c8e.parquet: 100% 63.6M/63.6M [00:00<00:00, 153MB/s]\n","(…)-00001-of-00003-dcfe505e70e75a94.parquet: 100% 204M/204M [00:01<00:00, 170MB/s]\n","(…)-00002-of-00003-70fff0af35c82eba.parquet: 100% 194M/194M [00:00<00:00, 218MB/s]\n","(…)-00000-of-00001-ef07e98641a18871.parquet: 100% 30.9M/30.9M [00:00<00:00, 140MB/s]\n","(…)-00000-of-00001-1746a3e472e61b9d.parquet: 100% 12.9M/12.9M [00:00<00:00, 112MB/s]\n","Generating train split: 100% 1756548/1756548 [00:03<00:00, 479012.10 examples/s]\n","Generating dev split: 100% 106557/106557 [00:00<00:00, 454538.70 examples/s]\n","Generating test split: 100% 34615/34615 [00:00<00:00, 363577.21 examples/s]\n","Filter: 100% 1756548/1756548 [00:21<00:00, 80769.50 examples/s]\n","Filter: 100% 106557/106557 [00:01<00:00, 80601.97 examples/s]\n","Filter: 100% 34615/34615 [00:00<00:00, 77747.96 examples/s]\n","Filtered dataset to source: anli_r1\n","Map: 100% 16946/16946 [00:02<00:00, 6732.03 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 7233.72 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 2359.06 examples/s]\n","Map: 100% 16946/16946 [00:01<00:00, 11949.12 examples/s]\n","Map: 100% 16946/16946 [00:01<00:00, 10912.85 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 11031.69 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 10452.83 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 11297.33 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 9465.63 examples/s]\n","Converted dataset to two rows\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language']\n","Map (num_proc=2): 100% 33892/33892 [00:07<00:00, 4835.04 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language']\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2589.70 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:329: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.7258, 'grad_norm': 15.551647186279297, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 2119/10595 [03:21<13:19, 10.60it/s]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  3% 7/250 [00:00<00:03, 68.35it/s]\u001b[A\n","  6% 14/250 [00:00<00:03, 62.55it/s]\u001b[A\n","  8% 21/250 [00:00<00:03, 61.06it/s]\u001b[A\n"," 11% 28/250 [00:00<00:03, 60.72it/s]\u001b[A\n"," 14% 35/250 [00:00<00:03, 60.37it/s]\u001b[A\n"," 17% 42/250 [00:00<00:03, 59.99it/s]\u001b[A\n"," 20% 49/250 [00:00<00:03, 59.98it/s]\u001b[A\n"," 22% 56/250 [00:00<00:03, 60.04it/s]\u001b[A\n"," 25% 63/250 [00:01<00:03, 60.09it/s]\u001b[A\n"," 28% 70/250 [00:01<00:02, 60.17it/s]\u001b[A\n"," 31% 77/250 [00:01<00:02, 59.88it/s]\u001b[A\n"," 33% 83/250 [00:01<00:02, 59.37it/s]\u001b[A\n"," 36% 89/250 [00:01<00:02, 59.15it/s]\u001b[A\n"," 38% 95/250 [00:01<00:02, 58.96it/s]\u001b[A\n"," 40% 101/250 [00:01<00:02, 59.17it/s]\u001b[A\n"," 43% 107/250 [00:01<00:02, 59.32it/s]\u001b[A\n"," 45% 113/250 [00:01<00:02, 59.52it/s]\u001b[A\n"," 48% 119/250 [00:01<00:02, 59.37it/s]\u001b[A\n"," 50% 125/250 [00:02<00:02, 59.51it/s]\u001b[A\n"," 52% 131/250 [00:02<00:01, 59.57it/s]\u001b[A\n"," 55% 137/250 [00:02<00:01, 59.65it/s]\u001b[A\n"," 58% 144/250 [00:02<00:01, 59.82it/s]\u001b[A\n"," 60% 151/250 [00:02<00:01, 59.98it/s]\u001b[A\n"," 63% 158/250 [00:02<00:01, 60.03it/s]\u001b[A\n"," 66% 165/250 [00:02<00:01, 59.91it/s]\u001b[A\n"," 68% 171/250 [00:02<00:01, 59.66it/s]\u001b[A\n"," 71% 178/250 [00:02<00:01, 59.83it/s]\u001b[A\n"," 74% 185/250 [00:03<00:01, 59.99it/s]\u001b[A\n"," 77% 192/250 [00:03<00:00, 60.05it/s]\u001b[A\n"," 80% 199/250 [00:03<00:00, 60.07it/s]\u001b[A\n"," 82% 206/250 [00:03<00:00, 60.11it/s]\u001b[A\n"," 85% 213/250 [00:03<00:00, 60.19it/s]\u001b[A\n"," 88% 220/250 [00:03<00:00, 60.21it/s]\u001b[A\n"," 91% 227/250 [00:03<00:00, 60.19it/s]\u001b[A\n"," 94% 234/250 [00:03<00:00, 60.24it/s]\u001b[A\n"," 96% 241/250 [00:04<00:00, 60.25it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 1.2338407039642334, 'eval_accuracy': 0.4335, 'eval_precision': 0.42525657627204805, 'eval_recall': 0.4335, 'eval_f1': 0.4208269903056338, 'eval_runtime': 4.2047, 'eval_samples_per_second': 475.653, 'eval_steps_per_second': 59.457, 'epoch': 1.0}\n"," 20% 2119/10595 [03:25<13:19, 10.60it/s]\n","100% 250/250 [00:04<00:00, 60.25it/s]\u001b[A\n","{'loss': 0.4693, 'grad_norm': 14.389431953430176, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 4238/10595 [06:52<09:09, 11.57it/s]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  3% 7/250 [00:00<00:03, 68.52it/s]\u001b[A\n","  6% 14/250 [00:00<00:03, 62.58it/s]\u001b[A\n","  8% 21/250 [00:00<00:03, 60.82it/s]\u001b[A\n"," 11% 28/250 [00:00<00:03, 59.98it/s]\u001b[A\n"," 14% 35/250 [00:00<00:03, 59.72it/s]\u001b[A\n"," 16% 41/250 [00:00<00:03, 59.42it/s]\u001b[A\n"," 19% 47/250 [00:00<00:03, 59.25it/s]\u001b[A\n"," 21% 53/250 [00:00<00:03, 59.13it/s]\u001b[A\n"," 24% 59/250 [00:00<00:03, 58.83it/s]\u001b[A\n"," 26% 65/250 [00:01<00:03, 58.77it/s]\u001b[A\n"," 28% 71/250 [00:01<00:03, 58.80it/s]\u001b[A\n"," 31% 77/250 [00:01<00:02, 58.75it/s]\u001b[A\n"," 33% 83/250 [00:01<00:02, 58.66it/s]\u001b[A\n"," 36% 89/250 [00:01<00:02, 58.59it/s]\u001b[A\n"," 38% 96/250 [00:01<00:02, 59.09it/s]\u001b[A\n"," 41% 102/250 [00:01<00:02, 59.00it/s]\u001b[A\n"," 44% 109/250 [00:01<00:02, 59.43it/s]\u001b[A\n"," 46% 116/250 [00:01<00:02, 59.72it/s]\u001b[A\n"," 49% 122/250 [00:02<00:02, 59.47it/s]\u001b[A\n"," 51% 128/250 [00:02<00:02, 59.13it/s]\u001b[A\n"," 54% 134/250 [00:02<00:01, 58.59it/s]\u001b[A\n"," 56% 140/250 [00:02<00:01, 58.68it/s]\u001b[A\n"," 58% 146/250 [00:02<00:01, 58.99it/s]\u001b[A\n"," 61% 152/250 [00:02<00:01, 58.95it/s]\u001b[A\n"," 63% 158/250 [00:02<00:01, 58.81it/s]\u001b[A\n"," 66% 164/250 [00:02<00:01, 58.82it/s]\u001b[A\n"," 68% 170/250 [00:02<00:01, 58.80it/s]\u001b[A\n"," 70% 176/250 [00:02<00:01, 58.80it/s]\u001b[A\n"," 73% 183/250 [00:03<00:01, 59.36it/s]\u001b[A\n"," 76% 190/250 [00:03<00:01, 59.71it/s]\u001b[A\n"," 79% 197/250 [00:03<00:00, 59.89it/s]\u001b[A\n"," 82% 204/250 [00:03<00:00, 60.06it/s]\u001b[A\n"," 84% 211/250 [00:03<00:00, 60.19it/s]\u001b[A\n"," 87% 218/250 [00:03<00:00, 60.29it/s]\u001b[A\n"," 90% 225/250 [00:03<00:00, 60.34it/s]\u001b[A\n"," 93% 232/250 [00:03<00:00, 60.38it/s]\u001b[A\n"," 96% 239/250 [00:04<00:00, 60.37it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 1.637671947479248, 'eval_accuracy': 0.4365, 'eval_precision': 0.43268373634268115, 'eval_recall': 0.4365, 'eval_f1': 0.4335394639852391, 'eval_runtime': 4.2213, 'eval_samples_per_second': 473.79, 'eval_steps_per_second': 59.224, 'epoch': 2.0}\n"," 40% 4238/10595 [06:56<09:09, 11.57it/s]\n","100% 250/250 [00:04<00:00, 60.35it/s]\u001b[A\n","{'loss': 0.2912, 'grad_norm': 39.26069259643555, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 6357/10595 [10:22<06:37, 10.65it/s]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  3% 7/250 [00:00<00:03, 69.33it/s]\u001b[A\n","  6% 14/250 [00:00<00:03, 63.30it/s]\u001b[A\n","  8% 21/250 [00:00<00:03, 61.60it/s]\u001b[A\n"," 11% 28/250 [00:00<00:03, 61.01it/s]\u001b[A\n"," 14% 35/250 [00:00<00:03, 60.33it/s]\u001b[A\n"," 17% 42/250 [00:00<00:03, 59.82it/s]\u001b[A\n"," 19% 48/250 [00:00<00:03, 59.47it/s]\u001b[A\n"," 22% 54/250 [00:00<00:03, 59.35it/s]\u001b[A\n"," 24% 60/250 [00:00<00:03, 59.30it/s]\u001b[A\n"," 26% 66/250 [00:01<00:03, 59.24it/s]\u001b[A\n"," 29% 72/250 [00:01<00:03, 59.11it/s]\u001b[A\n"," 31% 78/250 [00:01<00:02, 58.81it/s]\u001b[A\n"," 34% 85/250 [00:01<00:02, 59.31it/s]\u001b[A\n"," 36% 91/250 [00:01<00:02, 59.46it/s]\u001b[A\n"," 39% 97/250 [00:01<00:02, 59.38it/s]\u001b[A\n"," 41% 103/250 [00:01<00:02, 59.23it/s]\u001b[A\n"," 44% 109/250 [00:01<00:02, 59.32it/s]\u001b[A\n"," 46% 115/250 [00:01<00:02, 59.21it/s]\u001b[A\n"," 48% 121/250 [00:02<00:02, 59.03it/s]\u001b[A\n"," 51% 127/250 [00:02<00:02, 58.81it/s]\u001b[A\n"," 53% 133/250 [00:02<00:01, 58.92it/s]\u001b[A\n"," 56% 139/250 [00:02<00:01, 58.86it/s]\u001b[A\n"," 58% 145/250 [00:02<00:01, 58.71it/s]\u001b[A\n"," 60% 151/250 [00:02<00:01, 58.54it/s]\u001b[A\n"," 63% 157/250 [00:02<00:01, 58.87it/s]\u001b[A\n"," 65% 163/250 [00:02<00:01, 59.16it/s]\u001b[A\n"," 68% 170/250 [00:02<00:01, 59.49it/s]\u001b[A\n"," 71% 177/250 [00:02<00:01, 59.78it/s]\u001b[A\n"," 74% 184/250 [00:03<00:01, 59.95it/s]\u001b[A\n"," 76% 191/250 [00:03<00:00, 60.04it/s]\u001b[A\n"," 79% 198/250 [00:03<00:00, 60.05it/s]\u001b[A\n"," 82% 205/250 [00:03<00:00, 59.71it/s]\u001b[A\n"," 84% 211/250 [00:03<00:00, 59.47it/s]\u001b[A\n"," 87% 217/250 [00:03<00:00, 59.28it/s]\u001b[A\n"," 89% 223/250 [00:03<00:00, 59.15it/s]\u001b[A\n"," 92% 229/250 [00:03<00:00, 59.04it/s]\u001b[A\n"," 94% 235/250 [00:03<00:00, 58.97it/s]\u001b[A\n"," 96% 241/250 [00:04<00:00, 58.92it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 1.91386079788208, 'eval_accuracy': 0.438, 'eval_precision': 0.4343007150330012, 'eval_recall': 0.438, 'eval_f1': 0.4349737938272656, 'eval_runtime': 4.2294, 'eval_samples_per_second': 472.88, 'eval_steps_per_second': 59.11, 'epoch': 3.0}\n"," 60% 6357/10595 [10:26<06:37, 10.65it/s]\n","100% 250/250 [00:04<00:00, 58.65it/s]\u001b[A\n","{'loss': 0.1918, 'grad_norm': 0.08682739734649658, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 8476/10595 [13:54<03:01, 11.65it/s]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  3% 7/250 [00:00<00:03, 69.49it/s]\u001b[A\n","  6% 14/250 [00:00<00:03, 63.80it/s]\u001b[A\n","  8% 21/250 [00:00<00:03, 62.17it/s]\u001b[A\n"," 11% 28/250 [00:00<00:03, 61.53it/s]\u001b[A\n"," 14% 35/250 [00:00<00:03, 60.99it/s]\u001b[A\n"," 17% 42/250 [00:00<00:03, 60.80it/s]\u001b[A\n"," 20% 49/250 [00:00<00:03, 60.47it/s]\u001b[A\n"," 22% 56/250 [00:00<00:03, 60.47it/s]\u001b[A\n"," 25% 63/250 [00:01<00:03, 60.50it/s]\u001b[A\n"," 28% 70/250 [00:01<00:02, 60.39it/s]\u001b[A\n"," 31% 77/250 [00:01<00:02, 60.21it/s]\u001b[A\n"," 34% 84/250 [00:01<00:02, 60.28it/s]\u001b[A\n"," 36% 91/250 [00:01<00:02, 60.23it/s]\u001b[A\n"," 39% 98/250 [00:01<00:02, 60.33it/s]\u001b[A\n"," 42% 105/250 [00:01<00:02, 60.14it/s]\u001b[A\n"," 45% 112/250 [00:01<00:02, 60.24it/s]\u001b[A\n"," 48% 119/250 [00:01<00:02, 60.27it/s]\u001b[A\n"," 50% 126/250 [00:02<00:02, 60.20it/s]\u001b[A\n"," 53% 133/250 [00:02<00:01, 60.25it/s]\u001b[A\n"," 56% 140/250 [00:02<00:01, 60.31it/s]\u001b[A\n"," 59% 147/250 [00:02<00:01, 60.27it/s]\u001b[A\n"," 62% 154/250 [00:02<00:01, 59.98it/s]\u001b[A\n"," 64% 160/250 [00:02<00:01, 59.98it/s]\u001b[A\n"," 67% 167/250 [00:02<00:01, 60.16it/s]\u001b[A\n"," 70% 174/250 [00:02<00:01, 60.13it/s]\u001b[A\n"," 72% 181/250 [00:02<00:01, 60.24it/s]\u001b[A\n"," 75% 188/250 [00:03<00:01, 60.14it/s]\u001b[A\n"," 78% 195/250 [00:03<00:00, 60.21it/s]\u001b[A\n"," 81% 202/250 [00:03<00:00, 60.30it/s]\u001b[A\n"," 84% 209/250 [00:03<00:00, 60.35it/s]\u001b[A\n"," 86% 216/250 [00:03<00:00, 60.39it/s]\u001b[A\n"," 89% 223/250 [00:03<00:00, 60.41it/s]\u001b[A\n"," 92% 230/250 [00:03<00:00, 60.44it/s]\u001b[A\n"," 95% 237/250 [00:03<00:00, 60.46it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 2.8319716453552246, 'eval_accuracy': 0.446, 'eval_precision': 0.4432413012785316, 'eval_recall': 0.446, 'eval_f1': 0.44363976719199216, 'eval_runtime': 4.1563, 'eval_samples_per_second': 481.196, 'eval_steps_per_second': 60.15, 'epoch': 4.0}\n"," 80% 8476/10595 [13:58<03:01, 11.65it/s]\n","100% 250/250 [00:04<00:00, 60.45it/s]\u001b[A\n","{'loss': 0.1238, 'grad_norm': 0.03343738615512848, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 10595/10595 [17:30<00:00, 10.60it/s]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  2% 6/250 [00:00<00:04, 59.39it/s]\u001b[A\n","  5% 12/250 [00:00<00:04, 58.31it/s]\u001b[A\n","  7% 18/250 [00:00<00:03, 58.93it/s]\u001b[A\n"," 10% 24/250 [00:00<00:03, 59.22it/s]\u001b[A\n"," 12% 31/250 [00:00<00:03, 59.63it/s]\u001b[A\n"," 15% 38/250 [00:00<00:03, 59.92it/s]\u001b[A\n"," 18% 45/250 [00:00<00:03, 60.03it/s]\u001b[A\n"," 21% 52/250 [00:00<00:03, 60.13it/s]\u001b[A\n"," 24% 59/250 [00:00<00:03, 60.09it/s]\u001b[A\n"," 26% 66/250 [00:01<00:03, 60.14it/s]\u001b[A\n"," 29% 73/250 [00:01<00:02, 60.24it/s]\u001b[A\n"," 32% 80/250 [00:01<00:02, 60.29it/s]\u001b[A\n"," 35% 87/250 [00:01<00:02, 60.32it/s]\u001b[A\n"," 38% 94/250 [00:01<00:02, 60.36it/s]\u001b[A\n"," 40% 101/250 [00:01<00:02, 60.31it/s]\u001b[A\n"," 43% 108/250 [00:01<00:02, 60.20it/s]\u001b[A\n"," 46% 115/250 [00:01<00:02, 60.19it/s]\u001b[A\n"," 49% 122/250 [00:02<00:02, 60.00it/s]\u001b[A\n"," 52% 129/250 [00:02<00:02, 60.10it/s]\u001b[A\n"," 54% 136/250 [00:02<00:01, 60.14it/s]\u001b[A\n"," 57% 143/250 [00:02<00:01, 60.17it/s]\u001b[A\n"," 60% 150/250 [00:02<00:01, 60.12it/s]\u001b[A\n"," 63% 157/250 [00:02<00:01, 60.12it/s]\u001b[A\n"," 66% 164/250 [00:02<00:01, 59.92it/s]\u001b[A\n"," 68% 170/250 [00:02<00:01, 59.91it/s]\u001b[A\n"," 70% 176/250 [00:02<00:01, 59.81it/s]\u001b[A\n"," 73% 182/250 [00:03<00:01, 59.65it/s]\u001b[A\n"," 75% 188/250 [00:03<00:01, 59.75it/s]\u001b[A\n"," 78% 195/250 [00:03<00:00, 59.93it/s]\u001b[A\n"," 80% 201/250 [00:03<00:00, 59.93it/s]\u001b[A\n"," 83% 207/250 [00:03<00:00, 59.86it/s]\u001b[A\n"," 85% 213/250 [00:03<00:00, 59.69it/s]\u001b[A\n"," 88% 219/250 [00:03<00:00, 59.71it/s]\u001b[A\n"," 90% 225/250 [00:03<00:00, 58.55it/s]\u001b[A\n"," 92% 231/250 [00:03<00:00, 57.74it/s]\u001b[A\n"," 95% 237/250 [00:03<00:00, 56.94it/s]\u001b[A\n"," 97% 243/250 [00:04<00:00, 57.44it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 3.360548734664917, 'eval_accuracy': 0.4335, 'eval_precision': 0.429437851317329, 'eval_recall': 0.4335, 'eval_f1': 0.43032821036084035, 'eval_runtime': 4.2232, 'eval_samples_per_second': 473.579, 'eval_steps_per_second': 59.197, 'epoch': 5.0}\n","100% 10595/10595 [17:34<00:00, 10.60it/s]\n","100% 250/250 [00:04<00:00, 58.07it/s]\u001b[A\n","{'train_runtime': 1065.3118, 'train_samples_per_second': 159.071, 'train_steps_per_second': 9.945, 'train_loss': 0.3603854731604309, 'epoch': 5.0}\n","100% 10595/10595 [17:45<00:00,  9.95it/s]\n","100% 250/250 [00:04<00:00, 56.61it/s]\n","Evaluation results:\n","{'eval_loss': 3.360548734664917, 'eval_accuracy': 0.4335, 'eval_precision': 0.429437851317329, 'eval_recall': 0.4335, 'eval_f1': 0.43032821036084035, 'eval_runtime': 4.4367, 'eval_samples_per_second': 450.786, 'eval_steps_per_second': 56.348, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/yd7wq6er\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241202_191716-yd7wq6er/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r1/checkpoint-8476 \\\n","    --task nli \\\n","    --dataset cointegrated/nli-rus-translated-v2021 \\\n","    --source_filter anli_r2 \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_anli_en_ru_bert_2/r2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQaT3bXgzZHp","executionInfo":{"status":"ok","timestamp":1733171365003,"user_tz":360,"elapsed":2824717,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"16f2b80b-8026-4870-fc84-1e7f5b0f67f6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 19:42:24.528048: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-02 19:42:24.545395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 19:42:24.566916: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 19:42:24.573458: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 19:42:24.589568: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 19:42:25.653818: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241202_194228-q3d0zh4h\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/q3d0zh4h\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Filter: 100% 1756548/1756548 [00:22<00:00, 79325.80 examples/s]\n","Filter: 100% 106557/106557 [00:01<00:00, 78724.32 examples/s]\n","Filter: 100% 34615/34615 [00:00<00:00, 75565.98 examples/s]\n","Filtered dataset to source: anli_r2\n","Map: 100% 45460/45460 [00:06<00:00, 6555.67 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 7223.71 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 7246.24 examples/s]\n","Map: 100% 45460/45460 [00:03<00:00, 11747.03 examples/s]\n","Map: 100% 45460/45460 [00:04<00:00, 10960.51 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 11229.61 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 10526.52 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 11405.19 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 10500.54 examples/s]\n","Converted dataset to two rows\n","tokenizer_config.json: 100% 49.0/49.0 [00:00<00:00, 241kB/s]\n","config.json: 100% 625/625 [00:00<00:00, 3.24MB/s]\n","vocab.txt: 100% 996k/996k [00:00<00:00, 13.2MB/s]\n","tokenizer.json: 100% 1.96M/1.96M [00:00<00:00, 4.72MB/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language']\n","Map (num_proc=2): 100% 90920/90920 [00:19<00:00, 4770.88 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language']\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2629.06 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:329: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.6265, 'grad_norm': 14.073987007141113, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 5683/28415 [08:55<33:51, 11.19it/s]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  3% 8/250 [00:00<00:03, 68.75it/s]\u001b[A\n","  6% 15/250 [00:00<00:03, 63.56it/s]\u001b[A\n","  9% 22/250 [00:00<00:03, 62.06it/s]\u001b[A\n"," 12% 29/250 [00:00<00:03, 61.26it/s]\u001b[A\n"," 14% 36/250 [00:00<00:03, 60.91it/s]\u001b[A\n"," 17% 43/250 [00:00<00:03, 60.58it/s]\u001b[A\n"," 20% 50/250 [00:00<00:03, 60.44it/s]\u001b[A\n"," 23% 57/250 [00:00<00:03, 60.37it/s]\u001b[A\n"," 26% 64/250 [00:01<00:03, 60.30it/s]\u001b[A\n"," 28% 71/250 [00:01<00:02, 60.27it/s]\u001b[A\n"," 31% 78/250 [00:01<00:02, 60.06it/s]\u001b[A\n"," 34% 85/250 [00:01<00:02, 60.06it/s]\u001b[A\n"," 37% 92/250 [00:01<00:02, 60.11it/s]\u001b[A\n"," 40% 99/250 [00:01<00:02, 59.89it/s]\u001b[A\n"," 42% 105/250 [00:01<00:02, 59.49it/s]\u001b[A\n"," 44% 111/250 [00:01<00:02, 59.58it/s]\u001b[A\n"," 47% 117/250 [00:01<00:02, 59.54it/s]\u001b[A\n"," 50% 124/250 [00:02<00:02, 59.81it/s]\u001b[A\n"," 52% 130/250 [00:02<00:02, 59.72it/s]\u001b[A\n"," 54% 136/250 [00:02<00:01, 59.79it/s]\u001b[A\n"," 57% 143/250 [00:02<00:01, 59.92it/s]\u001b[A\n"," 60% 150/250 [00:02<00:01, 60.00it/s]\u001b[A\n"," 63% 157/250 [00:02<00:01, 60.09it/s]\u001b[A\n"," 66% 164/250 [00:02<00:01, 60.12it/s]\u001b[A\n"," 68% 171/250 [00:02<00:01, 60.18it/s]\u001b[A\n"," 71% 178/250 [00:02<00:01, 60.23it/s]\u001b[A\n"," 74% 185/250 [00:03<00:01, 60.24it/s]\u001b[A\n"," 77% 192/250 [00:03<00:00, 60.21it/s]\u001b[A\n"," 80% 199/250 [00:03<00:00, 60.18it/s]\u001b[A\n"," 82% 206/250 [00:03<00:00, 60.11it/s]\u001b[A\n"," 85% 213/250 [00:03<00:00, 60.08it/s]\u001b[A\n"," 88% 220/250 [00:03<00:00, 60.11it/s]\u001b[A\n"," 91% 227/250 [00:03<00:00, 59.79it/s]\u001b[A\n"," 93% 233/250 [00:03<00:00, 59.50it/s]\u001b[A\n"," 96% 240/250 [00:03<00:00, 59.71it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 1.4815622568130493, 'eval_accuracy': 0.414, 'eval_precision': 0.4122697726743841, 'eval_recall': 0.414, 'eval_f1': 0.3922112327562064, 'eval_runtime': 4.1763, 'eval_samples_per_second': 478.897, 'eval_steps_per_second': 59.862, 'epoch': 1.0}\n"," 20% 5683/28415 [08:59<33:51, 11.19it/s]\n","100% 250/250 [00:04<00:00, 59.67it/s]\u001b[A\n","{'loss': 0.4148, 'grad_norm': 8.108847618103027, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 11366/28415 [18:00<25:15, 11.25it/s]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  3% 7/250 [00:00<00:03, 69.83it/s]\u001b[A\n","  6% 14/250 [00:00<00:03, 63.68it/s]\u001b[A\n","  8% 21/250 [00:00<00:03, 61.77it/s]\u001b[A\n"," 11% 28/250 [00:00<00:03, 61.05it/s]\u001b[A\n"," 14% 35/250 [00:00<00:03, 60.19it/s]\u001b[A\n"," 17% 42/250 [00:00<00:03, 60.12it/s]\u001b[A\n"," 20% 49/250 [00:00<00:03, 60.12it/s]\u001b[A\n"," 22% 56/250 [00:00<00:03, 60.12it/s]\u001b[A\n"," 25% 63/250 [00:01<00:03, 60.10it/s]\u001b[A\n"," 28% 70/250 [00:01<00:02, 60.06it/s]\u001b[A\n"," 31% 77/250 [00:01<00:02, 59.93it/s]\u001b[A\n"," 33% 83/250 [00:01<00:02, 59.80it/s]\u001b[A\n"," 36% 90/250 [00:01<00:02, 59.94it/s]\u001b[A\n"," 38% 96/250 [00:01<00:02, 59.92it/s]\u001b[A\n"," 41% 103/250 [00:01<00:02, 59.98it/s]\u001b[A\n"," 44% 109/250 [00:01<00:02, 59.90it/s]\u001b[A\n"," 46% 116/250 [00:01<00:02, 60.01it/s]\u001b[A\n"," 49% 122/250 [00:02<00:02, 59.77it/s]\u001b[A\n"," 52% 129/250 [00:02<00:02, 59.88it/s]\u001b[A\n"," 54% 135/250 [00:02<00:01, 59.71it/s]\u001b[A\n"," 57% 142/250 [00:02<00:01, 59.85it/s]\u001b[A\n"," 59% 148/250 [00:02<00:01, 59.87it/s]\u001b[A\n"," 62% 154/250 [00:02<00:01, 59.60it/s]\u001b[A\n"," 64% 161/250 [00:02<00:01, 59.77it/s]\u001b[A\n"," 67% 167/250 [00:02<00:01, 59.81it/s]\u001b[A\n"," 70% 174/250 [00:02<00:01, 59.90it/s]\u001b[A\n"," 72% 180/250 [00:02<00:01, 59.90it/s]\u001b[A\n"," 74% 186/250 [00:03<00:01, 59.92it/s]\u001b[A\n"," 77% 192/250 [00:03<00:00, 59.93it/s]\u001b[A\n"," 79% 198/250 [00:03<00:00, 59.89it/s]\u001b[A\n"," 82% 204/250 [00:03<00:00, 59.80it/s]\u001b[A\n"," 84% 210/250 [00:03<00:00, 59.81it/s]\u001b[A\n"," 86% 216/250 [00:03<00:00, 59.81it/s]\u001b[A\n"," 89% 223/250 [00:03<00:00, 59.93it/s]\u001b[A\n"," 92% 230/250 [00:03<00:00, 60.04it/s]\u001b[A\n"," 95% 237/250 [00:03<00:00, 60.05it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 1.7454782724380493, 'eval_accuracy': 0.4335, 'eval_precision': 0.44145110223110223, 'eval_recall': 0.4335, 'eval_f1': 0.4157492452520885, 'eval_runtime': 4.1807, 'eval_samples_per_second': 478.389, 'eval_steps_per_second': 59.799, 'epoch': 2.0}\n"," 40% 11366/28415 [18:05<25:15, 11.25it/s]\n","100% 250/250 [00:04<00:00, 60.07it/s]\u001b[A\n","{'loss': 0.2658, 'grad_norm': 1.664657473564148, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 17049/28415 [27:09<16:47, 11.29it/s]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  3% 8/250 [00:00<00:03, 69.03it/s]\u001b[A\n","  6% 15/250 [00:00<00:03, 63.18it/s]\u001b[A\n","  9% 22/250 [00:00<00:03, 61.82it/s]\u001b[A\n"," 12% 29/250 [00:00<00:03, 61.26it/s]\u001b[A\n"," 14% 36/250 [00:00<00:03, 60.86it/s]\u001b[A\n"," 17% 43/250 [00:00<00:03, 60.44it/s]\u001b[A\n"," 20% 50/250 [00:00<00:03, 60.16it/s]\u001b[A\n"," 23% 57/250 [00:00<00:03, 60.13it/s]\u001b[A\n"," 26% 64/250 [00:01<00:03, 60.19it/s]\u001b[A\n"," 28% 71/250 [00:01<00:02, 60.06it/s]\u001b[A\n"," 31% 78/250 [00:01<00:02, 60.08it/s]\u001b[A\n"," 34% 85/250 [00:01<00:02, 60.10it/s]\u001b[A\n"," 37% 92/250 [00:01<00:02, 60.11it/s]\u001b[A\n"," 40% 99/250 [00:01<00:02, 60.10it/s]\u001b[A\n"," 42% 106/250 [00:01<00:02, 59.94it/s]\u001b[A\n"," 45% 113/250 [00:01<00:02, 60.06it/s]\u001b[A\n"," 48% 120/250 [00:01<00:02, 60.05it/s]\u001b[A\n"," 51% 127/250 [00:02<00:02, 60.14it/s]\u001b[A\n"," 54% 134/250 [00:02<00:01, 59.85it/s]\u001b[A\n"," 56% 140/250 [00:02<00:01, 59.87it/s]\u001b[A\n"," 58% 146/250 [00:02<00:01, 59.91it/s]\u001b[A\n"," 61% 152/250 [00:02<00:01, 59.74it/s]\u001b[A\n"," 63% 158/250 [00:02<00:01, 59.64it/s]\u001b[A\n"," 66% 164/250 [00:02<00:01, 59.67it/s]\u001b[A\n"," 68% 171/250 [00:02<00:01, 59.83it/s]\u001b[A\n"," 71% 177/250 [00:02<00:01, 59.76it/s]\u001b[A\n"," 74% 184/250 [00:03<00:01, 59.92it/s]\u001b[A\n"," 76% 191/250 [00:03<00:00, 60.04it/s]\u001b[A\n"," 79% 198/250 [00:03<00:00, 60.15it/s]\u001b[A\n"," 82% 205/250 [00:03<00:00, 60.23it/s]\u001b[A\n"," 85% 212/250 [00:03<00:00, 60.21it/s]\u001b[A\n"," 88% 219/250 [00:03<00:00, 60.05it/s]\u001b[A\n"," 90% 226/250 [00:03<00:00, 60.03it/s]\u001b[A\n"," 93% 233/250 [00:03<00:00, 60.07it/s]\u001b[A\n"," 96% 240/250 [00:03<00:00, 60.15it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 2.2417149543762207, 'eval_accuracy': 0.4295, 'eval_precision': 0.4297807720520814, 'eval_recall': 0.4295, 'eval_f1': 0.4211073255934736, 'eval_runtime': 4.1736, 'eval_samples_per_second': 479.203, 'eval_steps_per_second': 59.9, 'epoch': 3.0}\n"," 60% 17049/28415 [27:13<16:47, 11.29it/s]\n","100% 250/250 [00:04<00:00, 60.07it/s]\u001b[A\n","{'loss': 0.1735, 'grad_norm': 0.1340101808309555, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 22732/28415 [36:15<08:25, 11.24it/s]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  3% 7/250 [00:00<00:03, 67.95it/s]\u001b[A\n","  6% 14/250 [00:00<00:03, 62.12it/s]\u001b[A\n","  8% 21/250 [00:00<00:03, 61.25it/s]\u001b[A\n"," 11% 28/250 [00:00<00:03, 60.79it/s]\u001b[A\n"," 14% 35/250 [00:00<00:03, 60.28it/s]\u001b[A\n"," 17% 42/250 [00:00<00:03, 60.28it/s]\u001b[A\n"," 20% 49/250 [00:00<00:03, 60.26it/s]\u001b[A\n"," 22% 56/250 [00:00<00:03, 60.25it/s]\u001b[A\n"," 25% 63/250 [00:01<00:03, 60.22it/s]\u001b[A\n"," 28% 70/250 [00:01<00:02, 60.08it/s]\u001b[A\n"," 31% 77/250 [00:01<00:02, 59.61it/s]\u001b[A\n"," 33% 83/250 [00:01<00:02, 59.21it/s]\u001b[A\n"," 36% 89/250 [00:01<00:02, 58.97it/s]\u001b[A\n"," 38% 95/250 [00:01<00:02, 58.82it/s]\u001b[A\n"," 40% 101/250 [00:01<00:02, 59.12it/s]\u001b[A\n"," 43% 107/250 [00:01<00:02, 58.89it/s]\u001b[A\n"," 45% 113/250 [00:01<00:02, 58.63it/s]\u001b[A\n"," 48% 119/250 [00:01<00:02, 58.68it/s]\u001b[A\n"," 50% 125/250 [00:02<00:02, 58.63it/s]\u001b[A\n"," 52% 131/250 [00:02<00:02, 58.38it/s]\u001b[A\n"," 55% 138/250 [00:02<00:01, 58.97it/s]\u001b[A\n"," 58% 145/250 [00:02<00:01, 59.33it/s]\u001b[A\n"," 60% 151/250 [00:02<00:01, 59.45it/s]\u001b[A\n"," 63% 158/250 [00:02<00:01, 59.69it/s]\u001b[A\n"," 66% 165/250 [00:02<00:01, 59.81it/s]\u001b[A\n"," 69% 172/250 [00:02<00:01, 59.95it/s]\u001b[A\n"," 71% 178/250 [00:02<00:01, 59.59it/s]\u001b[A\n"," 74% 184/250 [00:03<00:01, 59.69it/s]\u001b[A\n"," 76% 190/250 [00:03<00:01, 59.71it/s]\u001b[A\n"," 78% 196/250 [00:03<00:00, 59.71it/s]\u001b[A\n"," 81% 203/250 [00:03<00:00, 59.83it/s]\u001b[A\n"," 84% 209/250 [00:03<00:00, 59.68it/s]\u001b[A\n"," 86% 215/250 [00:03<00:00, 59.65it/s]\u001b[A\n"," 89% 222/250 [00:03<00:00, 59.77it/s]\u001b[A\n"," 91% 228/250 [00:03<00:00, 59.80it/s]\u001b[A\n"," 94% 234/250 [00:03<00:00, 59.39it/s]\u001b[A\n"," 96% 241/250 [00:04<00:00, 59.65it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 3.0125064849853516, 'eval_accuracy': 0.443, 'eval_precision': 0.4455398721021411, 'eval_recall': 0.443, 'eval_f1': 0.4360688081458151, 'eval_runtime': 4.2143, 'eval_samples_per_second': 474.575, 'eval_steps_per_second': 59.322, 'epoch': 4.0}\n"," 80% 22732/28415 [36:19<08:25, 11.24it/s]\n","100% 250/250 [00:04<00:00, 59.78it/s]\u001b[A\n","{'loss': 0.1102, 'grad_norm': 107.26680755615234, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 28415/28415 [45:28<00:00, 11.23it/s]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  2% 6/250 [00:00<00:04, 58.35it/s]\u001b[A\n","  5% 12/250 [00:00<00:04, 53.22it/s]\u001b[A\n","  7% 18/250 [00:00<00:04, 55.49it/s]\u001b[A\n"," 10% 24/250 [00:00<00:03, 56.77it/s]\u001b[A\n"," 12% 30/250 [00:00<00:03, 57.64it/s]\u001b[A\n"," 14% 36/250 [00:00<00:03, 58.15it/s]\u001b[A\n"," 17% 42/250 [00:00<00:03, 58.32it/s]\u001b[A\n"," 19% 48/250 [00:00<00:03, 58.34it/s]\u001b[A\n"," 22% 54/250 [00:00<00:03, 58.48it/s]\u001b[A\n"," 24% 60/250 [00:01<00:03, 58.33it/s]\u001b[A\n"," 26% 66/250 [00:01<00:03, 58.53it/s]\u001b[A\n"," 29% 72/250 [00:01<00:03, 58.59it/s]\u001b[A\n"," 31% 78/250 [00:01<00:02, 58.32it/s]\u001b[A\n"," 34% 84/250 [00:01<00:02, 58.65it/s]\u001b[A\n"," 36% 90/250 [00:01<00:02, 58.79it/s]\u001b[A\n"," 38% 96/250 [00:01<00:02, 58.77it/s]\u001b[A\n"," 41% 102/250 [00:01<00:02, 58.23it/s]\u001b[A\n"," 43% 108/250 [00:01<00:02, 57.50it/s]\u001b[A\n"," 46% 114/250 [00:01<00:02, 57.82it/s]\u001b[A\n"," 48% 120/250 [00:02<00:02, 57.88it/s]\u001b[A\n"," 50% 126/250 [00:02<00:02, 58.22it/s]\u001b[A\n"," 53% 132/250 [00:02<00:02, 58.69it/s]\u001b[A\n"," 55% 138/250 [00:02<00:01, 59.01it/s]\u001b[A\n"," 58% 144/250 [00:02<00:01, 59.18it/s]\u001b[A\n"," 60% 150/250 [00:02<00:01, 59.42it/s]\u001b[A\n"," 62% 156/250 [00:02<00:01, 59.48it/s]\u001b[A\n"," 65% 162/250 [00:02<00:01, 59.60it/s]\u001b[A\n"," 67% 168/250 [00:02<00:01, 59.64it/s]\u001b[A\n"," 70% 174/250 [00:02<00:01, 59.62it/s]\u001b[A\n"," 72% 180/250 [00:03<00:01, 59.43it/s]\u001b[A\n"," 74% 186/250 [00:03<00:01, 59.51it/s]\u001b[A\n"," 77% 192/250 [00:03<00:00, 59.46it/s]\u001b[A\n"," 79% 198/250 [00:03<00:00, 59.15it/s]\u001b[A\n"," 82% 204/250 [00:03<00:00, 57.98it/s]\u001b[A\n"," 84% 210/250 [00:03<00:00, 57.42it/s]\u001b[A\n"," 86% 216/250 [00:03<00:00, 57.34it/s]\u001b[A\n"," 89% 223/250 [00:03<00:00, 58.30it/s]\u001b[A\n"," 92% 229/250 [00:03<00:00, 58.66it/s]\u001b[A\n"," 94% 236/250 [00:04<00:00, 59.07it/s]\u001b[A\n"," 97% 242/250 [00:04<00:00, 58.74it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 3.580814838409424, 'eval_accuracy': 0.4395, 'eval_precision': 0.43774648849169545, 'eval_recall': 0.4395, 'eval_f1': 0.4348530505260444, 'eval_runtime': 4.3123, 'eval_samples_per_second': 463.787, 'eval_steps_per_second': 57.973, 'epoch': 5.0}\n","100% 28415/28415 [45:32<00:00, 11.23it/s]\n","100% 250/250 [00:04<00:00, 57.62it/s]\u001b[A\n","{'train_runtime': 2739.7994, 'train_samples_per_second': 165.925, 'train_steps_per_second': 10.371, 'train_loss': 0.31815344068589985, 'epoch': 5.0}\n","100% 28415/28415 [45:39<00:00, 10.37it/s]\n","100% 250/250 [00:04<00:00, 56.71it/s]\n","Evaluation results:\n","{'eval_loss': 3.580814838409424, 'eval_accuracy': 0.4395, 'eval_precision': 0.43774648849169545, 'eval_recall': 0.4395, 'eval_f1': 0.4348530505260444, 'eval_runtime': 4.4272, 'eval_samples_per_second': 451.755, 'eval_steps_per_second': 56.469, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/q3d0zh4h\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241202_194228-q3d0zh4h/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r2/checkpoint-22732 \\\n","    --task nli \\\n","    --dataset cointegrated/nli-rus-translated-v2021 \\\n","    --source_filter anli_r3 \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_anli_en_ru_bert_2/r3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Delf7MMr5SmS","executionInfo":{"status":"ok","timestamp":1733177542496,"user_tz":360,"elapsed":5149350,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"8412345a-760c-4d49-d36c-5e96aa1ac15e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 20:30:41.221120: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-02 20:30:41.238222: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 20:30:41.259261: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 20:30:41.265594: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 20:30:41.281033: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 20:30:42.346567: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241202_203044-4204cwmc\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/4204cwmc\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Filter: 100% 1756548/1756548 [00:21<00:00, 81930.59 examples/s]\n","Filter: 100% 106557/106557 [00:01<00:00, 78784.67 examples/s]\n","Filter: 100% 34615/34615 [00:00<00:00, 75485.60 examples/s]\n","Filtered dataset to source: anli_r3\n","Map: 100% 100459/100459 [00:15<00:00, 6638.14 examples/s]\n","Map: 100% 1200/1200 [00:00<00:00, 7158.07 examples/s]\n","Map: 100% 1200/1200 [00:00<00:00, 7233.28 examples/s]\n","Map: 100% 100459/100459 [00:08<00:00, 11862.42 examples/s]\n","Map: 100% 100459/100459 [00:09<00:00, 10785.45 examples/s]\n","Map: 100% 1200/1200 [00:00<00:00, 11103.41 examples/s]\n","Map: 100% 1200/1200 [00:00<00:00, 9806.32 examples/s] \n","Map: 100% 1200/1200 [00:00<00:00, 11137.27 examples/s]\n","Map: 100% 1200/1200 [00:00<00:00, 9729.36 examples/s]\n","Converted dataset to two rows\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language']\n","Map (num_proc=2): 100% 200918/200918 [00:40<00:00, 4934.28 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language']\n","Map (num_proc=2): 100% 2400/2400 [00:00<00:00, 2858.77 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.6892, 'grad_norm': 14.008108139038086, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 12558/62790 [19:42<1:14:26, 11.25it/s]\n","  0% 0/300 [00:00<?, ?it/s]\u001b[A\n","  2% 7/300 [00:00<00:04, 69.95it/s]\u001b[A\n","  5% 14/300 [00:00<00:04, 63.78it/s]\u001b[A\n","  7% 21/300 [00:00<00:04, 62.04it/s]\u001b[A\n","  9% 28/300 [00:00<00:04, 61.02it/s]\u001b[A\n"," 12% 35/300 [00:00<00:04, 60.32it/s]\u001b[A\n"," 14% 42/300 [00:00<00:04, 60.29it/s]\u001b[A\n"," 16% 49/300 [00:00<00:04, 60.15it/s]\u001b[A\n"," 19% 56/300 [00:00<00:04, 60.06it/s]\u001b[A\n"," 21% 63/300 [00:01<00:03, 60.05it/s]\u001b[A\n"," 23% 70/300 [00:01<00:03, 60.04it/s]\u001b[A\n"," 26% 77/300 [00:01<00:03, 59.93it/s]\u001b[A\n"," 28% 83/300 [00:01<00:03, 59.79it/s]\u001b[A\n"," 30% 89/300 [00:01<00:03, 59.78it/s]\u001b[A\n"," 32% 95/300 [00:01<00:03, 59.78it/s]\u001b[A\n"," 34% 102/300 [00:01<00:03, 59.85it/s]\u001b[A\n"," 36% 108/300 [00:01<00:03, 59.89it/s]\u001b[A\n"," 38% 114/300 [00:01<00:03, 59.70it/s]\u001b[A\n"," 40% 120/300 [00:01<00:03, 59.48it/s]\u001b[A\n"," 42% 126/300 [00:02<00:02, 59.62it/s]\u001b[A\n"," 44% 132/300 [00:02<00:02, 59.65it/s]\u001b[A\n"," 46% 138/300 [00:02<00:02, 59.51it/s]\u001b[A\n"," 48% 144/300 [00:02<00:02, 59.53it/s]\u001b[A\n"," 50% 150/300 [00:02<00:02, 59.51it/s]\u001b[A\n"," 52% 156/300 [00:02<00:02, 59.31it/s]\u001b[A\n"," 54% 162/300 [00:02<00:02, 59.15it/s]\u001b[A\n"," 56% 168/300 [00:02<00:02, 59.05it/s]\u001b[A\n"," 58% 174/300 [00:02<00:02, 58.91it/s]\u001b[A\n"," 60% 180/300 [00:03<00:02, 58.57it/s]\u001b[A\n"," 62% 186/300 [00:03<00:01, 58.53it/s]\u001b[A\n"," 64% 192/300 [00:03<00:01, 58.76it/s]\u001b[A\n"," 66% 198/300 [00:03<00:01, 58.68it/s]\u001b[A\n"," 68% 204/300 [00:03<00:01, 58.66it/s]\u001b[A\n"," 70% 210/300 [00:03<00:01, 58.63it/s]\u001b[A\n"," 72% 216/300 [00:03<00:01, 58.61it/s]\u001b[A\n"," 74% 222/300 [00:03<00:01, 58.66it/s]\u001b[A\n"," 76% 228/300 [00:03<00:01, 58.53it/s]\u001b[A\n"," 78% 234/300 [00:03<00:01, 58.29it/s]\u001b[A\n"," 80% 240/300 [00:04<00:01, 58.33it/s]\u001b[A\n"," 82% 246/300 [00:04<00:00, 58.41it/s]\u001b[A\n"," 84% 252/300 [00:04<00:00, 58.49it/s]\u001b[A\n"," 86% 258/300 [00:04<00:00, 58.26it/s]\u001b[A\n"," 88% 264/300 [00:04<00:00, 57.99it/s]\u001b[A\n"," 90% 270/300 [00:04<00:00, 58.12it/s]\u001b[A\n"," 92% 276/300 [00:04<00:00, 58.22it/s]\u001b[A\n"," 94% 282/300 [00:04<00:00, 58.18it/s]\u001b[A\n"," 96% 288/300 [00:04<00:00, 58.38it/s]\u001b[A\n"," 98% 294/300 [00:04<00:00, 58.43it/s]\u001b[A\n","                                           \n","\u001b[A{'eval_loss': 1.2687631845474243, 'eval_accuracy': 0.42583333333333334, 'eval_precision': 0.42808811026307175, 'eval_recall': 0.42583333333333334, 'eval_f1': 0.4233105861812383, 'eval_runtime': 5.0878, 'eval_samples_per_second': 471.721, 'eval_steps_per_second': 58.965, 'epoch': 1.0}\n"," 20% 12558/62790 [19:47<1:14:26, 11.25it/s]\n","100% 300/300 [00:05<00:00, 58.75it/s]\u001b[A\n","{'loss': 0.4928, 'grad_norm': 15.982789039611816, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 25116/62790 [39:37<55:59, 11.21it/s]\n","  0% 0/300 [00:00<?, ?it/s]\u001b[A\n","  2% 7/300 [00:00<00:04, 69.82it/s]\u001b[A\n","  5% 14/300 [00:00<00:04, 63.72it/s]\u001b[A\n","  7% 21/300 [00:00<00:04, 61.85it/s]\u001b[A\n","  9% 28/300 [00:00<00:04, 61.11it/s]\u001b[A\n"," 12% 35/300 [00:00<00:04, 60.55it/s]\u001b[A\n"," 14% 42/300 [00:00<00:04, 60.30it/s]\u001b[A\n"," 16% 49/300 [00:00<00:04, 60.08it/s]\u001b[A\n"," 19% 56/300 [00:00<00:04, 60.12it/s]\u001b[A\n"," 21% 63/300 [00:01<00:03, 59.97it/s]\u001b[A\n"," 23% 70/300 [00:01<00:03, 59.95it/s]\u001b[A\n"," 25% 76/300 [00:01<00:03, 59.90it/s]\u001b[A\n"," 27% 82/300 [00:01<00:03, 59.91it/s]\u001b[A\n"," 29% 88/300 [00:01<00:03, 59.66it/s]\u001b[A\n"," 31% 94/300 [00:01<00:03, 59.73it/s]\u001b[A\n"," 33% 100/300 [00:01<00:03, 59.80it/s]\u001b[A\n"," 35% 106/300 [00:01<00:03, 59.67it/s]\u001b[A\n"," 38% 113/300 [00:01<00:03, 59.81it/s]\u001b[A\n"," 40% 120/300 [00:01<00:03, 59.90it/s]\u001b[A\n"," 42% 126/300 [00:02<00:02, 59.88it/s]\u001b[A\n"," 44% 132/300 [00:02<00:02, 59.82it/s]\u001b[A\n"," 46% 138/300 [00:02<00:02, 59.79it/s]\u001b[A\n"," 48% 144/300 [00:02<00:02, 59.59it/s]\u001b[A\n"," 50% 150/300 [00:02<00:02, 59.44it/s]\u001b[A\n"," 52% 156/300 [00:02<00:02, 59.54it/s]\u001b[A\n"," 54% 162/300 [00:02<00:02, 59.53it/s]\u001b[A\n"," 56% 168/300 [00:02<00:02, 59.30it/s]\u001b[A\n"," 58% 174/300 [00:02<00:02, 59.36it/s]\u001b[A\n"," 60% 180/300 [00:02<00:02, 59.44it/s]\u001b[A\n"," 62% 186/300 [00:03<00:01, 59.41it/s]\u001b[A\n"," 64% 192/300 [00:03<00:01, 59.49it/s]\u001b[A\n"," 66% 198/300 [00:03<00:01, 59.40it/s]\u001b[A\n"," 68% 204/300 [00:03<00:01, 59.54it/s]\u001b[A\n"," 70% 210/300 [00:03<00:01, 59.07it/s]\u001b[A\n"," 72% 216/300 [00:03<00:01, 58.94it/s]\u001b[A\n"," 74% 222/300 [00:03<00:01, 59.01it/s]\u001b[A\n"," 76% 228/300 [00:03<00:01, 59.14it/s]\u001b[A\n"," 78% 234/300 [00:03<00:01, 59.33it/s]\u001b[A\n"," 80% 240/300 [00:04<00:01, 59.47it/s]\u001b[A\n"," 82% 246/300 [00:04<00:00, 59.57it/s]\u001b[A\n"," 84% 252/300 [00:04<00:00, 59.67it/s]\u001b[A\n"," 86% 258/300 [00:04<00:00, 59.56it/s]\u001b[A\n"," 88% 264/300 [00:04<00:00, 59.52it/s]\u001b[A\n"," 90% 270/300 [00:04<00:00, 59.62it/s]\u001b[A\n"," 92% 276/300 [00:04<00:00, 59.49it/s]\u001b[A\n"," 94% 282/300 [00:04<00:00, 59.51it/s]\u001b[A\n"," 96% 288/300 [00:04<00:00, 59.47it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 1.4808387756347656, 'eval_accuracy': 0.43333333333333335, 'eval_precision': 0.4362405783099487, 'eval_recall': 0.43333333333333335, 'eval_f1': 0.42947417194168397, 'eval_runtime': 5.041, 'eval_samples_per_second': 476.094, 'eval_steps_per_second': 59.512, 'epoch': 2.0}\n"," 40% 25116/62790 [39:42<55:59, 11.21it/s]\n","100% 300/300 [00:05<00:00, 59.57it/s]\u001b[A\n","{'loss': 0.3355, 'grad_norm': 78.9699478149414, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 37674/62790 [59:32<37:06, 11.28it/s]\n","  0% 0/300 [00:00<?, ?it/s]\u001b[A\n","  2% 7/300 [00:00<00:04, 68.56it/s]\u001b[A\n","  5% 14/300 [00:00<00:04, 62.98it/s]\u001b[A\n","  7% 21/300 [00:00<00:04, 60.85it/s]\u001b[A\n","  9% 28/300 [00:00<00:04, 59.52it/s]\u001b[A\n"," 11% 34/300 [00:00<00:04, 59.31it/s]\u001b[A\n"," 13% 40/300 [00:00<00:04, 59.23it/s]\u001b[A\n"," 15% 46/300 [00:00<00:04, 59.31it/s]\u001b[A\n"," 17% 52/300 [00:00<00:04, 59.45it/s]\u001b[A\n"," 19% 58/300 [00:00<00:04, 59.49it/s]\u001b[A\n"," 21% 64/300 [00:01<00:03, 59.44it/s]\u001b[A\n"," 23% 70/300 [00:01<00:03, 59.50it/s]\u001b[A\n"," 25% 76/300 [00:01<00:03, 59.27it/s]\u001b[A\n"," 27% 82/300 [00:01<00:03, 58.90it/s]\u001b[A\n"," 29% 88/300 [00:01<00:03, 59.02it/s]\u001b[A\n"," 31% 94/300 [00:01<00:03, 58.97it/s]\u001b[A\n"," 33% 100/300 [00:01<00:03, 58.94it/s]\u001b[A\n"," 35% 106/300 [00:01<00:03, 58.96it/s]\u001b[A\n"," 37% 112/300 [00:01<00:03, 58.99it/s]\u001b[A\n"," 39% 118/300 [00:01<00:03, 59.00it/s]\u001b[A\n"," 41% 124/300 [00:02<00:02, 59.02it/s]\u001b[A\n"," 43% 130/300 [00:02<00:02, 58.54it/s]\u001b[A\n"," 45% 136/300 [00:02<00:02, 58.04it/s]\u001b[A\n"," 47% 142/300 [00:02<00:02, 57.51it/s]\u001b[A\n"," 49% 148/300 [00:02<00:02, 58.00it/s]\u001b[A\n"," 51% 154/300 [00:02<00:02, 58.41it/s]\u001b[A\n"," 53% 160/300 [00:02<00:02, 58.61it/s]\u001b[A\n"," 55% 166/300 [00:02<00:02, 58.84it/s]\u001b[A\n"," 57% 172/300 [00:02<00:02, 59.01it/s]\u001b[A\n"," 59% 178/300 [00:03<00:02, 58.48it/s]\u001b[A\n"," 61% 184/300 [00:03<00:01, 58.41it/s]\u001b[A\n"," 63% 190/300 [00:03<00:01, 58.38it/s]\u001b[A\n"," 65% 196/300 [00:03<00:01, 58.23it/s]\u001b[A\n"," 67% 202/300 [00:03<00:01, 58.22it/s]\u001b[A\n"," 69% 208/300 [00:03<00:01, 57.82it/s]\u001b[A\n"," 71% 214/300 [00:03<00:01, 57.35it/s]\u001b[A\n"," 73% 220/300 [00:03<00:01, 57.25it/s]\u001b[A\n"," 75% 226/300 [00:03<00:01, 57.08it/s]\u001b[A\n"," 77% 232/300 [00:03<00:01, 57.63it/s]\u001b[A\n"," 79% 238/300 [00:04<00:01, 58.03it/s]\u001b[A\n"," 81% 244/300 [00:04<00:00, 58.38it/s]\u001b[A\n"," 83% 250/300 [00:04<00:00, 58.24it/s]\u001b[A\n"," 85% 256/300 [00:04<00:00, 58.22it/s]\u001b[A\n"," 87% 262/300 [00:04<00:00, 58.43it/s]\u001b[A\n"," 89% 268/300 [00:04<00:00, 58.16it/s]\u001b[A\n"," 91% 274/300 [00:04<00:00, 58.29it/s]\u001b[A\n"," 93% 280/300 [00:04<00:00, 58.57it/s]\u001b[A\n"," 95% 286/300 [00:04<00:00, 58.79it/s]\u001b[A\n"," 97% 292/300 [00:04<00:00, 58.94it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 1.916776180267334, 'eval_accuracy': 0.43375, 'eval_precision': 0.43739455487699314, 'eval_recall': 0.43375, 'eval_f1': 0.4282949723379227, 'eval_runtime': 5.1307, 'eval_samples_per_second': 467.771, 'eval_steps_per_second': 58.471, 'epoch': 3.0}\n"," 60% 37674/62790 [59:37<37:06, 11.28it/s]\n","100% 300/300 [00:05<00:00, 59.05it/s]\u001b[A\n","{'loss': 0.2211, 'grad_norm': 49.9864501953125, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 50232/62790 [1:19:30<18:34, 11.27it/s]\n","  0% 0/300 [00:00<?, ?it/s]\u001b[A\n","  2% 7/300 [00:00<00:04, 69.58it/s]\u001b[A\n","  5% 14/300 [00:00<00:04, 63.27it/s]\u001b[A\n","  7% 21/300 [00:00<00:04, 61.60it/s]\u001b[A\n","  9% 28/300 [00:00<00:04, 60.86it/s]\u001b[A\n"," 12% 35/300 [00:00<00:04, 60.40it/s]\u001b[A\n"," 14% 42/300 [00:00<00:04, 60.15it/s]\u001b[A\n"," 16% 49/300 [00:00<00:04, 59.99it/s]\u001b[A\n"," 19% 56/300 [00:00<00:04, 59.95it/s]\u001b[A\n"," 21% 62/300 [00:01<00:03, 59.91it/s]\u001b[A\n"," 23% 68/300 [00:01<00:03, 59.82it/s]\u001b[A\n"," 25% 74/300 [00:01<00:03, 59.83it/s]\u001b[A\n"," 27% 80/300 [00:01<00:03, 59.68it/s]\u001b[A\n"," 29% 86/300 [00:01<00:03, 59.72it/s]\u001b[A\n"," 31% 92/300 [00:01<00:03, 59.72it/s]\u001b[A\n"," 33% 98/300 [00:01<00:03, 59.67it/s]\u001b[A\n"," 35% 104/300 [00:01<00:03, 59.55it/s]\u001b[A\n"," 37% 110/300 [00:01<00:03, 59.41it/s]\u001b[A\n"," 39% 116/300 [00:01<00:03, 58.65it/s]\u001b[A\n"," 41% 122/300 [00:02<00:03, 58.41it/s]\u001b[A\n"," 43% 128/300 [00:02<00:02, 58.86it/s]\u001b[A\n"," 45% 134/300 [00:02<00:02, 58.90it/s]\u001b[A\n"," 47% 140/300 [00:02<00:02, 59.09it/s]\u001b[A\n"," 49% 146/300 [00:02<00:02, 59.26it/s]\u001b[A\n"," 51% 152/300 [00:02<00:02, 59.00it/s]\u001b[A\n"," 53% 158/300 [00:02<00:02, 59.11it/s]\u001b[A\n"," 55% 164/300 [00:02<00:02, 59.33it/s]\u001b[A\n"," 57% 170/300 [00:02<00:02, 59.45it/s]\u001b[A\n"," 59% 176/300 [00:02<00:02, 59.60it/s]\u001b[A\n"," 61% 182/300 [00:03<00:01, 59.72it/s]\u001b[A\n"," 63% 188/300 [00:03<00:01, 59.73it/s]\u001b[A\n"," 65% 194/300 [00:03<00:01, 59.80it/s]\u001b[A\n"," 67% 200/300 [00:03<00:01, 59.85it/s]\u001b[A\n"," 69% 206/300 [00:03<00:01, 59.68it/s]\u001b[A\n"," 71% 212/300 [00:03<00:01, 59.66it/s]\u001b[A\n"," 73% 218/300 [00:03<00:01, 59.28it/s]\u001b[A\n"," 75% 224/300 [00:03<00:01, 59.25it/s]\u001b[A\n"," 77% 230/300 [00:03<00:01, 59.27it/s]\u001b[A\n"," 79% 236/300 [00:03<00:01, 59.43it/s]\u001b[A\n"," 81% 242/300 [00:04<00:00, 59.45it/s]\u001b[A\n"," 83% 248/300 [00:04<00:00, 59.41it/s]\u001b[A\n"," 85% 254/300 [00:04<00:00, 59.39it/s]\u001b[A\n"," 87% 260/300 [00:04<00:00, 59.33it/s]\u001b[A\n"," 89% 266/300 [00:04<00:00, 59.14it/s]\u001b[A\n"," 91% 272/300 [00:04<00:00, 59.19it/s]\u001b[A\n"," 93% 278/300 [00:04<00:00, 59.27it/s]\u001b[A\n"," 95% 284/300 [00:04<00:00, 59.02it/s]\u001b[A\n"," 97% 290/300 [00:04<00:00, 58.91it/s]\u001b[A\n","                                           \n","\u001b[A{'eval_loss': 2.4050979614257812, 'eval_accuracy': 0.43583333333333335, 'eval_precision': 0.4384699105763487, 'eval_recall': 0.43583333333333335, 'eval_f1': 0.4311114088862132, 'eval_runtime': 5.0607, 'eval_samples_per_second': 474.239, 'eval_steps_per_second': 59.28, 'epoch': 4.0}\n"," 80% 50232/62790 [1:19:35<18:34, 11.27it/s]\n","100% 300/300 [00:05<00:00, 58.86it/s]\u001b[A\n","{'loss': 0.1525, 'grad_norm': 0.033087532967329025, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 62790/62790 [1:39:31<00:00, 11.25it/s]\n","  0% 0/300 [00:00<?, ?it/s]\u001b[A\n","  2% 6/300 [00:00<00:05, 58.79it/s]\u001b[A\n","  4% 12/300 [00:00<00:05, 55.86it/s]\u001b[A\n","  6% 18/300 [00:00<00:04, 57.51it/s]\u001b[A\n","  8% 24/300 [00:00<00:04, 58.03it/s]\u001b[A\n"," 10% 30/300 [00:00<00:04, 58.19it/s]\u001b[A\n"," 12% 36/300 [00:00<00:04, 58.57it/s]\u001b[A\n"," 14% 42/300 [00:00<00:04, 58.71it/s]\u001b[A\n"," 16% 48/300 [00:00<00:04, 58.80it/s]\u001b[A\n"," 18% 54/300 [00:00<00:04, 59.06it/s]\u001b[A\n"," 20% 60/300 [00:01<00:04, 59.18it/s]\u001b[A\n"," 22% 66/300 [00:01<00:03, 59.34it/s]\u001b[A\n"," 24% 72/300 [00:01<00:03, 59.44it/s]\u001b[A\n"," 26% 78/300 [00:01<00:03, 59.20it/s]\u001b[A\n"," 28% 84/300 [00:01<00:03, 59.03it/s]\u001b[A\n"," 30% 90/300 [00:01<00:03, 59.23it/s]\u001b[A\n"," 32% 96/300 [00:01<00:03, 59.18it/s]\u001b[A\n"," 34% 102/300 [00:01<00:03, 58.91it/s]\u001b[A\n"," 36% 108/300 [00:01<00:03, 58.80it/s]\u001b[A\n"," 38% 114/300 [00:01<00:03, 58.92it/s]\u001b[A\n"," 40% 120/300 [00:02<00:03, 58.76it/s]\u001b[A\n"," 42% 126/300 [00:02<00:02, 58.92it/s]\u001b[A\n"," 44% 132/300 [00:02<00:02, 58.33it/s]\u001b[A\n"," 46% 138/300 [00:02<00:02, 58.65it/s]\u001b[A\n"," 48% 144/300 [00:02<00:02, 58.95it/s]\u001b[A\n"," 50% 150/300 [00:02<00:02, 59.07it/s]\u001b[A\n"," 52% 156/300 [00:02<00:02, 59.17it/s]\u001b[A\n"," 54% 162/300 [00:02<00:02, 59.03it/s]\u001b[A\n"," 56% 168/300 [00:02<00:02, 58.36it/s]\u001b[A\n"," 58% 174/300 [00:02<00:02, 57.90it/s]\u001b[A\n"," 60% 180/300 [00:03<00:02, 57.56it/s]\u001b[A\n"," 62% 186/300 [00:03<00:01, 57.52it/s]\u001b[A\n"," 64% 192/300 [00:03<00:01, 58.06it/s]\u001b[A\n"," 66% 198/300 [00:03<00:01, 58.43it/s]\u001b[A\n"," 68% 204/300 [00:03<00:01, 58.72it/s]\u001b[A\n"," 70% 210/300 [00:03<00:01, 58.58it/s]\u001b[A\n"," 72% 216/300 [00:03<00:01, 58.72it/s]\u001b[A\n"," 74% 222/300 [00:03<00:01, 58.68it/s]\u001b[A\n"," 76% 228/300 [00:03<00:01, 58.71it/s]\u001b[A\n"," 78% 234/300 [00:03<00:01, 58.75it/s]\u001b[A\n"," 80% 240/300 [00:04<00:01, 58.66it/s]\u001b[A\n"," 82% 246/300 [00:04<00:00, 58.63it/s]\u001b[A\n"," 84% 252/300 [00:04<00:00, 58.87it/s]\u001b[A\n"," 86% 258/300 [00:04<00:00, 58.26it/s]\u001b[A\n"," 88% 264/300 [00:04<00:00, 58.22it/s]\u001b[A\n"," 90% 270/300 [00:04<00:00, 58.38it/s]\u001b[A\n"," 92% 276/300 [00:04<00:00, 57.73it/s]\u001b[A\n"," 94% 282/300 [00:04<00:00, 57.37it/s]\u001b[A\n"," 96% 288/300 [00:04<00:00, 57.00it/s]\u001b[A\n"," 98% 294/300 [00:05<00:00, 56.96it/s]\u001b[A\n","                                           \n","\u001b[A{'eval_loss': 3.3032751083374023, 'eval_accuracy': 0.4429166666666667, 'eval_precision': 0.44461479480482363, 'eval_recall': 0.4429166666666667, 'eval_f1': 0.4402174691824452, 'eval_runtime': 5.1624, 'eval_samples_per_second': 464.901, 'eval_steps_per_second': 58.113, 'epoch': 5.0}\n","100% 62790/62790 [1:39:37<00:00, 11.25it/s]\n","100% 300/300 [00:05<00:00, 57.60it/s]\u001b[A\n","{'train_runtime': 5984.1275, 'train_samples_per_second': 167.876, 'train_steps_per_second': 10.493, 'train_loss': 0.37820889782347406, 'epoch': 5.0}\n","100% 62790/62790 [1:39:44<00:00, 10.49it/s]\n","100% 300/300 [00:05<00:00, 59.16it/s]\n","Evaluation results:\n","{'eval_loss': 3.3032751083374023, 'eval_accuracy': 0.4429166666666667, 'eval_precision': 0.44461479480482363, 'eval_recall': 0.4429166666666667, 'eval_f1': 0.4402174691824452, 'eval_runtime': 5.0927, 'eval_samples_per_second': 471.265, 'eval_steps_per_second': 58.908, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/4204cwmc\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241202_203044-4204cwmc/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r3/checkpoint-62790 \\\n","    --task nli \\\n","    --dataset negation_examples_comb.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_anli_en_ru_bert_2/negation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZmGPGMFEV0T","executionInfo":{"status":"ok","timestamp":1733179286033,"user_tz":360,"elapsed":1073910,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"7810c001-69dd-4705-ebec-5842c94f6b54"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 22:23:36.395096: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-02 22:23:36.411856: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 22:23:36.432644: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 22:23:36.438972: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 22:23:36.454220: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 22:23:37.512791: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241202_222340-iptjuxlv\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/iptjuxlv\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 34540 examples [00:00, 86717.84 examples/s]\n","Filter: 100% 34540/34540 [00:00<00:00, 121399.62 examples/s]\n","Filter: 100% 34540/34540 [00:00<00:00, 132796.48 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 33888/33888 [00:08<00:00, 4017.73 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 652/652 [00:00<00:00, 1222.06 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.323, 'grad_norm': 3.540598154067993, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 2118/10590 [03:20<13:13, 10.67it/s]\n","  0% 0/82 [00:00<?, ?it/s]\u001b[A\n"," 10% 8/82 [00:00<00:01, 69.09it/s]\u001b[A\n"," 18% 15/82 [00:00<00:01, 64.02it/s]\u001b[A\n"," 27% 22/82 [00:00<00:00, 62.24it/s]\u001b[A\n"," 35% 29/82 [00:00<00:00, 61.54it/s]\u001b[A\n"," 44% 36/82 [00:00<00:00, 61.07it/s]\u001b[A\n"," 52% 43/82 [00:00<00:00, 60.39it/s]\u001b[A\n"," 61% 50/82 [00:00<00:00, 59.86it/s]\u001b[A\n"," 68% 56/82 [00:00<00:00, 59.80it/s]\u001b[A\n"," 77% 63/82 [00:01<00:00, 59.89it/s]\u001b[A\n"," 85% 70/82 [00:01<00:00, 59.98it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 1.8320672512054443, 'eval_accuracy': 0.44631901840490795, 'eval_precision': 0.46756542799914513, 'eval_recall': 0.44631901840490795, 'eval_f1': 0.45242889795806884, 'eval_runtime': 1.3697, 'eval_samples_per_second': 476.011, 'eval_steps_per_second': 59.866, 'epoch': 1.0}\n"," 20% 2118/10590 [03:21<13:13, 10.67it/s]\n","100% 82/82 [00:01<00:00, 59.85it/s]\u001b[A\n","{'loss': 0.2005, 'grad_norm': 118.9350357055664, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 4236/10590 [06:46<09:57, 10.64it/s]\n","  0% 0/82 [00:00<?, ?it/s]\u001b[A\n","  9% 7/82 [00:00<00:01, 69.18it/s]\u001b[A\n"," 17% 14/82 [00:00<00:01, 62.17it/s]\u001b[A\n"," 26% 21/82 [00:00<00:00, 61.14it/s]\u001b[A\n"," 34% 28/82 [00:00<00:00, 60.70it/s]\u001b[A\n"," 43% 35/82 [00:00<00:00, 60.49it/s]\u001b[A\n"," 51% 42/82 [00:00<00:00, 60.34it/s]\u001b[A\n"," 60% 49/82 [00:00<00:00, 59.78it/s]\u001b[A\n"," 67% 55/82 [00:00<00:00, 59.70it/s]\u001b[A\n"," 76% 62/82 [00:01<00:00, 59.87it/s]\u001b[A\n"," 83% 68/82 [00:01<00:00, 59.41it/s]\u001b[A\n"," 91% 75/82 [00:01<00:00, 59.64it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 2.8500125408172607, 'eval_accuracy': 0.4294478527607362, 'eval_precision': 0.4800910863189917, 'eval_recall': 0.4294478527607362, 'eval_f1': 0.4413585232637541, 'eval_runtime': 1.3766, 'eval_samples_per_second': 473.64, 'eval_steps_per_second': 59.568, 'epoch': 2.0}\n"," 40% 4236/10590 [06:47<09:57, 10.64it/s]\n","100% 82/82 [00:01<00:00, 61.24it/s]\u001b[A\n","{'loss': 0.1298, 'grad_norm': 0.05375805124640465, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 6354/10590 [10:13<06:37, 10.66it/s]\n","  0% 0/82 [00:00<?, ?it/s]\u001b[A\n"," 10% 8/82 [00:00<00:01, 69.01it/s]\u001b[A\n"," 18% 15/82 [00:00<00:01, 63.27it/s]\u001b[A\n"," 27% 22/82 [00:00<00:00, 61.52it/s]\u001b[A\n"," 35% 29/82 [00:00<00:00, 60.53it/s]\u001b[A\n"," 44% 36/82 [00:00<00:00, 60.14it/s]\u001b[A\n"," 52% 43/82 [00:00<00:00, 60.10it/s]\u001b[A\n"," 61% 50/82 [00:00<00:00, 59.81it/s]\u001b[A\n"," 68% 56/82 [00:00<00:00, 59.60it/s]\u001b[A\n"," 76% 62/82 [00:01<00:00, 59.42it/s]\u001b[A\n"," 83% 68/82 [00:01<00:00, 59.23it/s]\u001b[A\n"," 90% 74/82 [00:01<00:00, 59.18it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 3.4095308780670166, 'eval_accuracy': 0.43558282208588955, 'eval_precision': 0.4643755064835382, 'eval_recall': 0.43558282208588955, 'eval_f1': 0.44461747774181226, 'eval_runtime': 1.3827, 'eval_samples_per_second': 471.528, 'eval_steps_per_second': 59.303, 'epoch': 3.0}\n"," 60% 6354/10590 [10:14<06:37, 10.66it/s]\n","100% 82/82 [00:01<00:00, 59.27it/s]\u001b[A\n","{'loss': 0.071, 'grad_norm': 0.009980677627027035, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 8472/10590 [13:39<03:17, 10.72it/s]\n","  0% 0/82 [00:00<?, ?it/s]\u001b[A\n"," 10% 8/82 [00:00<00:01, 69.03it/s]\u001b[A\n"," 18% 15/82 [00:00<00:01, 63.79it/s]\u001b[A\n"," 27% 22/82 [00:00<00:00, 62.07it/s]\u001b[A\n"," 35% 29/82 [00:00<00:00, 61.41it/s]\u001b[A\n"," 44% 36/82 [00:00<00:00, 61.00it/s]\u001b[A\n"," 52% 43/82 [00:00<00:00, 60.79it/s]\u001b[A\n"," 61% 50/82 [00:00<00:00, 60.64it/s]\u001b[A\n"," 70% 57/82 [00:00<00:00, 60.45it/s]\u001b[A\n"," 78% 64/82 [00:01<00:00, 60.36it/s]\u001b[A\n"," 87% 71/82 [00:01<00:00, 60.36it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 3.615046501159668, 'eval_accuracy': 0.45858895705521474, 'eval_precision': 0.4822650432198762, 'eval_recall': 0.45858895705521474, 'eval_f1': 0.4666867553026615, 'eval_runtime': 1.3597, 'eval_samples_per_second': 479.505, 'eval_steps_per_second': 60.306, 'epoch': 4.0}\n"," 80% 8472/10590 [13:41<03:17, 10.72it/s]\n","100% 82/82 [00:01<00:00, 60.35it/s]\u001b[A\n","{'loss': 0.0457, 'grad_norm': 0.009752222336828709, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 10590/10590 [17:12<00:00, 10.69it/s]\n","  0% 0/82 [00:00<?, ?it/s]\u001b[A\n","  7% 6/82 [00:00<00:01, 59.92it/s]\u001b[A\n"," 15% 12/82 [00:00<00:01, 57.95it/s]\u001b[A\n"," 22% 18/82 [00:00<00:01, 57.25it/s]\u001b[A\n"," 29% 24/82 [00:00<00:00, 58.01it/s]\u001b[A\n"," 37% 30/82 [00:00<00:00, 58.69it/s]\u001b[A\n"," 45% 37/82 [00:00<00:00, 59.27it/s]\u001b[A\n"," 54% 44/82 [00:00<00:00, 59.60it/s]\u001b[A\n"," 61% 50/82 [00:00<00:00, 59.64it/s]\u001b[A\n"," 68% 56/82 [00:00<00:00, 59.26it/s]\u001b[A\n"," 76% 62/82 [00:01<00:00, 59.23it/s]\u001b[A\n"," 83% 68/82 [00:01<00:00, 59.33it/s]\u001b[A\n"," 90% 74/82 [00:01<00:00, 59.39it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 4.058070182800293, 'eval_accuracy': 0.4447852760736196, 'eval_precision': 0.4777065975677044, 'eval_recall': 0.4447852760736196, 'eval_f1': 0.45333699742325195, 'eval_runtime': 1.4058, 'eval_samples_per_second': 463.778, 'eval_steps_per_second': 58.328, 'epoch': 5.0}\n","100% 10590/10590 [17:14<00:00, 10.69it/s]\n","100% 82/82 [00:01<00:00, 59.47it/s]\u001b[A\n","{'train_runtime': 1042.9951, 'train_samples_per_second': 162.455, 'train_steps_per_second': 10.153, 'train_loss': 0.15400212389664114, 'epoch': 5.0}\n","100% 10590/10590 [17:22<00:00, 10.15it/s]\n","100% 82/82 [00:01<00:00, 58.62it/s]\n","Evaluation results:\n","{'eval_loss': 4.058070182800293, 'eval_accuracy': 0.4447852760736196, 'eval_precision': 0.4777065975677044, 'eval_recall': 0.4447852760736196, 'eval_f1': 0.45333699742325195, 'eval_runtime': 1.4191, 'eval_samples_per_second': 459.452, 'eval_steps_per_second': 57.784, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/iptjuxlv\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241202_222340-iptjuxlv/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/negation/checkpoint-2118 \\\n","    --task nli \\\n","    --dataset attribution_examples_comb.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_anli_en_ru_bert_2/attribution"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fq2ywU0XeL6Z","executionInfo":{"status":"ok","timestamp":1733180333085,"user_tz":360,"elapsed":902778,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"cf57823f-d1a6-44de-ae0f-e2021e6c7915"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 22:43:54.615690: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-02 22:43:54.633278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 22:43:54.654881: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 22:43:54.661368: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 22:43:54.677837: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 22:43:55.762542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241202_224358-64jo629w\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/64jo629w\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 28836 examples [00:00, 81515.31 examples/s]\n","Filter: 100% 28836/28836 [00:00<00:00, 124868.31 examples/s]\n","Filter: 100% 28836/28836 [00:00<00:00, 138031.68 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 28084/28084 [00:07<00:00, 3928.33 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 752/752 [00:00<00:00, 1323.71 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.4085, 'grad_norm': 24.78322410583496, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 1756/8780 [02:45<10:12, 11.46it/s]\n","  0% 0/94 [00:00<?, ?it/s]\u001b[A\n","  7% 7/94 [00:00<00:01, 69.43it/s]\u001b[A\n"," 15% 14/94 [00:00<00:01, 63.07it/s]\u001b[A\n"," 22% 21/94 [00:00<00:01, 61.24it/s]\u001b[A\n"," 30% 28/94 [00:00<00:01, 60.33it/s]\u001b[A\n"," 37% 35/94 [00:00<00:00, 60.01it/s]\u001b[A\n"," 45% 42/94 [00:00<00:00, 59.78it/s]\u001b[A\n"," 51% 48/94 [00:00<00:00, 59.59it/s]\u001b[A\n"," 57% 54/94 [00:00<00:00, 59.18it/s]\u001b[A\n"," 64% 60/94 [00:00<00:00, 59.13it/s]\u001b[A\n"," 70% 66/94 [00:01<00:00, 58.93it/s]\u001b[A\n"," 77% 72/94 [00:01<00:00, 58.95it/s]\u001b[A\n"," 84% 79/94 [00:01<00:00, 59.45it/s]\u001b[A\n"," 90% 85/94 [00:01<00:00, 59.60it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 1.5036958456039429, 'eval_accuracy': 0.46808510638297873, 'eval_precision': 0.4785073256192556, 'eval_recall': 0.46808510638297873, 'eval_f1': 0.4673863070758081, 'eval_runtime': 1.5901, 'eval_samples_per_second': 472.916, 'eval_steps_per_second': 59.115, 'epoch': 1.0}\n"," 20% 1756/8780 [02:47<10:12, 11.46it/s]\n","100% 94/94 [00:01<00:00, 59.79it/s]\u001b[A\n","{'loss': 0.2182, 'grad_norm': 24.73504066467285, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 3512/8780 [05:38<07:32, 11.65it/s]\n","  0% 0/94 [00:00<?, ?it/s]\u001b[A\n","  7% 7/94 [00:00<00:01, 69.26it/s]\u001b[A\n"," 15% 14/94 [00:00<00:01, 62.89it/s]\u001b[A\n"," 22% 21/94 [00:00<00:01, 61.24it/s]\u001b[A\n"," 30% 28/94 [00:00<00:01, 60.51it/s]\u001b[A\n"," 37% 35/94 [00:00<00:00, 59.94it/s]\u001b[A\n"," 45% 42/94 [00:00<00:00, 59.52it/s]\u001b[A\n"," 51% 48/94 [00:00<00:00, 59.32it/s]\u001b[A\n"," 57% 54/94 [00:00<00:00, 59.21it/s]\u001b[A\n"," 65% 61/94 [00:01<00:00, 59.53it/s]\u001b[A\n"," 71% 67/94 [00:01<00:00, 59.37it/s]\u001b[A\n"," 78% 73/94 [00:01<00:00, 59.06it/s]\u001b[A\n"," 84% 79/94 [00:01<00:00, 59.07it/s]\u001b[A\n"," 90% 85/94 [00:01<00:00, 59.02it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 2.069974899291992, 'eval_accuracy': 0.48138297872340424, 'eval_precision': 0.48302530434711805, 'eval_recall': 0.48138297872340424, 'eval_f1': 0.480473642651985, 'eval_runtime': 1.5976, 'eval_samples_per_second': 470.692, 'eval_steps_per_second': 58.836, 'epoch': 2.0}\n"," 40% 3512/8780 [05:40<07:32, 11.65it/s]\n","100% 94/94 [00:01<00:00, 59.00it/s]\u001b[A\n","{'loss': 0.1448, 'grad_norm': 1.2514406442642212, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 5268/8780 [08:32<05:28, 10.68it/s]\n","  0% 0/94 [00:00<?, ?it/s]\u001b[A\n","  9% 8/94 [00:00<00:01, 69.27it/s]\u001b[A\n"," 16% 15/94 [00:00<00:01, 63.52it/s]\u001b[A\n"," 23% 22/94 [00:00<00:01, 61.48it/s]\u001b[A\n"," 31% 29/94 [00:00<00:01, 60.70it/s]\u001b[A\n"," 38% 36/94 [00:00<00:00, 60.21it/s]\u001b[A\n"," 46% 43/94 [00:00<00:00, 59.84it/s]\u001b[A\n"," 52% 49/94 [00:00<00:00, 59.63it/s]\u001b[A\n"," 59% 55/94 [00:00<00:00, 59.39it/s]\u001b[A\n"," 65% 61/94 [00:01<00:00, 59.28it/s]\u001b[A\n"," 71% 67/94 [00:01<00:00, 59.23it/s]\u001b[A\n"," 78% 73/94 [00:01<00:00, 59.17it/s]\u001b[A\n"," 84% 79/94 [00:01<00:00, 59.02it/s]\u001b[A\n"," 90% 85/94 [00:01<00:00, 58.95it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 2.915384531021118, 'eval_accuracy': 0.48404255319148937, 'eval_precision': 0.48596128289332047, 'eval_recall': 0.48404255319148937, 'eval_f1': 0.48099269826698765, 'eval_runtime': 1.5968, 'eval_samples_per_second': 470.929, 'eval_steps_per_second': 58.866, 'epoch': 3.0}\n"," 60% 5268/8780 [08:33<05:28, 10.68it/s]\n","100% 94/94 [00:01<00:00, 58.82it/s]\u001b[A\n","{'loss': 0.0871, 'grad_norm': 0.022260183468461037, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 7024/8780 [11:25<02:44, 10.69it/s]\n","  0% 0/94 [00:00<?, ?it/s]\u001b[A\n","  9% 8/94 [00:00<00:01, 68.73it/s]\u001b[A\n"," 16% 15/94 [00:00<00:01, 63.14it/s]\u001b[A\n"," 23% 22/94 [00:00<00:01, 61.65it/s]\u001b[A\n"," 31% 29/94 [00:00<00:01, 61.14it/s]\u001b[A\n"," 38% 36/94 [00:00<00:00, 60.51it/s]\u001b[A\n"," 46% 43/94 [00:00<00:00, 60.41it/s]\u001b[A\n"," 53% 50/94 [00:00<00:00, 60.39it/s]\u001b[A\n"," 61% 57/94 [00:00<00:00, 60.41it/s]\u001b[A\n"," 68% 64/94 [00:01<00:00, 60.24it/s]\u001b[A\n"," 76% 71/94 [00:01<00:00, 60.25it/s]\u001b[A\n"," 83% 78/94 [00:01<00:00, 60.27it/s]\u001b[A\n"," 90% 85/94 [00:01<00:00, 60.28it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 3.511740207672119, 'eval_accuracy': 0.47606382978723405, 'eval_precision': 0.4736661979044594, 'eval_recall': 0.47606382978723405, 'eval_f1': 0.4721535895358292, 'eval_runtime': 1.5725, 'eval_samples_per_second': 478.233, 'eval_steps_per_second': 59.779, 'epoch': 4.0}\n"," 80% 7024/8780 [11:26<02:44, 10.69it/s]\n","100% 94/94 [00:01<00:00, 60.17it/s]\u001b[A\n","{'loss': 0.0479, 'grad_norm': 0.008738337084650993, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 8780/8780 [14:27<00:00, 10.67it/s]\n","  0% 0/94 [00:00<?, ?it/s]\u001b[A\n","  6% 6/94 [00:00<00:01, 59.19it/s]\u001b[A\n"," 13% 12/94 [00:00<00:01, 54.86it/s]\u001b[A\n"," 20% 19/94 [00:00<00:01, 57.53it/s]\u001b[A\n"," 27% 25/94 [00:00<00:01, 58.12it/s]\u001b[A\n"," 33% 31/94 [00:00<00:01, 58.13it/s]\u001b[A\n"," 39% 37/94 [00:00<00:00, 58.23it/s]\u001b[A\n"," 46% 43/94 [00:00<00:00, 58.35it/s]\u001b[A\n"," 52% 49/94 [00:00<00:00, 58.48it/s]\u001b[A\n"," 59% 55/94 [00:00<00:00, 58.27it/s]\u001b[A\n"," 65% 61/94 [00:01<00:00, 58.16it/s]\u001b[A\n"," 71% 67/94 [00:01<00:00, 58.28it/s]\u001b[A\n"," 78% 73/94 [00:01<00:00, 58.10it/s]\u001b[A\n"," 84% 79/94 [00:01<00:00, 58.53it/s]\u001b[A\n"," 90% 85/94 [00:01<00:00, 58.49it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 3.82232666015625, 'eval_accuracy': 0.4734042553191489, 'eval_precision': 0.47484877870804204, 'eval_recall': 0.4734042553191489, 'eval_f1': 0.46953353944820053, 'eval_runtime': 1.6463, 'eval_samples_per_second': 456.777, 'eval_steps_per_second': 57.097, 'epoch': 5.0}\n","100% 8780/8780 [14:28<00:00, 10.67it/s]\n","100% 94/94 [00:01<00:00, 57.79it/s]\u001b[A\n","{'train_runtime': 875.6578, 'train_samples_per_second': 160.359, 'train_steps_per_second': 10.027, 'train_loss': 0.18131814317985656, 'epoch': 5.0}\n","100% 8780/8780 [14:35<00:00, 10.03it/s]\n","100% 94/94 [00:02<00:00, 41.05it/s]\n","Evaluation results:\n","{'eval_loss': 3.82232666015625, 'eval_accuracy': 0.4734042553191489, 'eval_precision': 0.47484877870804204, 'eval_recall': 0.4734042553191489, 'eval_f1': 0.46953353944820053, 'eval_runtime': 1.6557, 'eval_samples_per_second': 454.199, 'eval_steps_per_second': 56.775, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/64jo629w\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241202_224358-64jo629w/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/attribution/checkpoint-5268 \\\n","    --task nli \\\n","    --dataset high_overlap_examples_comb.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_anli_en_ru_bert_2/high_overlap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udKlQqcgi1Un","executionInfo":{"status":"ok","timestamp":1733180573448,"user_tz":360,"elapsed":160362,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"a64fac8a-e52a-484e-d39d-6a8008814d71"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 23:00:17.420242: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-02 23:00:17.437507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 23:00:17.458691: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 23:00:17.465117: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 23:00:17.481111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 23:00:18.551241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241202_230021-wir5qogn\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/wir5qogn\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 3236 examples [00:00, 17348.01 examples/s]\n","Filter: 100% 3236/3236 [00:00<00:00, 87178.16 examples/s]\n","Filter: 100% 3236/3236 [00:00<00:00, 108904.50 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 3178/3178 [00:01<00:00, 2421.97 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 58/58 [00:00<00:00, 148.29 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.4498, 'grad_norm': 60.61149597167969, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 199/995 [00:19<01:14, 10.67it/s]\n","  0% 0/8 [00:00<?, ?it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.029757022857666, 'eval_accuracy': 0.6551724137931034, 'eval_precision': 0.8252680382497827, 'eval_recall': 0.6551724137931034, 'eval_f1': 0.7183945196115582, 'eval_runtime': 0.1359, 'eval_samples_per_second': 426.867, 'eval_steps_per_second': 58.878, 'epoch': 1.0}\n"," 20% 199/995 [00:19<01:14, 10.67it/s]\n","100% 8/8 [00:00<00:00, 69.73it/s]\u001b[A\n","{'loss': 0.2071, 'grad_norm': 30.55490493774414, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 398/995 [00:44<00:56, 10.65it/s]\n","  0% 0/8 [00:00<?, ?it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.8830230236053467, 'eval_accuracy': 0.603448275862069, 'eval_precision': 0.7629310344827587, 'eval_recall': 0.603448275862069, 'eval_f1': 0.667513611615245, 'eval_runtime': 0.1325, 'eval_samples_per_second': 437.889, 'eval_steps_per_second': 60.398, 'epoch': 2.0}\n"," 40% 398/995 [00:44<00:56, 10.65it/s]\n","100% 8/8 [00:00<00:00, 74.42it/s]\u001b[A\n","{'loss': 0.124, 'grad_norm': 8.194220542907715, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 597/995 [01:09<00:35, 11.12it/s]\n","  0% 0/8 [00:00<?, ?it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.9353424310684204, 'eval_accuracy': 0.6379310344827587, 'eval_precision': 0.8425427793621986, 'eval_recall': 0.6379310344827587, 'eval_f1': 0.7126452253749287, 'eval_runtime': 0.1359, 'eval_samples_per_second': 426.732, 'eval_steps_per_second': 58.86, 'epoch': 3.0}\n"," 60% 597/995 [01:09<00:35, 11.12it/s]\n","100% 8/8 [00:00<00:00, 68.97it/s]\u001b[A\n","{'loss': 0.0686, 'grad_norm': 107.91780853271484, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 796/995 [01:34<00:19, 10.43it/s]\n","  0% 0/8 [00:00<?, ?it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 2.264033317565918, 'eval_accuracy': 0.6551724137931034, 'eval_precision': 0.803448275862069, 'eval_recall': 0.6551724137931034, 'eval_f1': 0.6982240861551207, 'eval_runtime': 0.1423, 'eval_samples_per_second': 407.597, 'eval_steps_per_second': 56.22, 'epoch': 4.0}\n"," 80% 796/995 [01:34<00:19, 10.43it/s]\n","100% 8/8 [00:00<00:00, 69.93it/s]\u001b[A\n","{'loss': 0.0615, 'grad_norm': 0.032230179756879807, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 995/995 [02:07<00:00, 10.80it/s]\n","  0% 0/8 [00:00<?, ?it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.9220865964889526, 'eval_accuracy': 0.6724137931034483, 'eval_precision': 0.8000680860721429, 'eval_recall': 0.6724137931034483, 'eval_f1': 0.7230308569050963, 'eval_runtime': 0.1624, 'eval_samples_per_second': 357.241, 'eval_steps_per_second': 49.275, 'epoch': 5.0}\n","100% 995/995 [02:07<00:00, 10.80it/s]\n","100% 8/8 [00:00<00:00, 58.75it/s]\u001b[A\n","{'train_runtime': 135.5341, 'train_samples_per_second': 117.24, 'train_steps_per_second': 7.341, 'train_loss': 0.1821891017894649, 'epoch': 5.0}\n","100% 995/995 [02:15<00:00,  7.34it/s]\n","100% 8/8 [00:02<00:00,  3.63it/s]\n","Evaluation results:\n","{'eval_loss': 1.9220865964889526, 'eval_accuracy': 0.6724137931034483, 'eval_precision': 0.8000680860721429, 'eval_recall': 0.6724137931034483, 'eval_f1': 0.7230308569050963, 'eval_runtime': 0.159, 'eval_samples_per_second': 364.741, 'eval_steps_per_second': 50.309, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/wir5qogn\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241202_230021-wir5qogn/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r1/checkpoint-8476 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R1_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/anli_r1_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C5XAuL1omlQc","executionInfo":{"status":"ok","timestamp":1733181759094,"user_tz":360,"elapsed":763112,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"9ed08105-f55e-4dcc-f4eb-0e7a09f552ec"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 23:10:07.347492: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 23:10:07.361245: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 23:10:07.365363: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 23:10:07.375668: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 23:10:08.557725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","README.md: 100% 20.8k/20.8k [00:00<00:00, 70.3MB/s]\n","train-00000-of-00001.parquet: 100% 50.2M/50.2M [00:00<00:00, 168MB/s]\n","test-00000-of-00001.parquet: 100% 308k/308k [00:00<00:00, 434MB/s]\n","validation-00000-of-00001.parquet: 100% 157k/157k [00:00<00:00, 257MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 803634.10 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 573042.35 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 643885.14 examples/s]\n","train-00000-of-00001.parquet: 100% 70.0M/70.0M [00:00<00:00, 248MB/s]\n","test-00000-of-00001.parquet: 100% 477k/477k [00:00<00:00, 404MB/s]\n","validation-00000-of-00001.parquet: 100% 239k/239k [00:00<00:00, 296MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 609782.95 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 475762.16 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 395329.58 examples/s]\n","Map: 100% 392702/392702 [00:14<00:00, 27742.34 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 34333.70 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 34598.33 examples/s]\n","Map: 100% 392702/392702 [00:13<00:00, 29091.20 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 32505.33 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 31693.45 examples/s]\n","Generating test split: 2000 examples [00:00, 3927.06 examples/s]\n","tokenizer_config.json: 100% 49.0/49.0 [00:00<00:00, 221kB/s]\n","config.json: 100% 625/625 [00:00<00:00, 3.38MB/s]\n","vocab.txt: 100% 996k/996k [00:00<00:00, 1.42MB/s]\n","tokenizer.json: 100% 1.96M/1.96M [00:00<00:00, 2.85MB/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 3146.83 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7331.53 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7415.40 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [02:14<00:00,  1.26it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [02:14<00:00,  1.08s/it]\n","{'eval_loss': 2.9437010288238525, 'eval_model_preparation_time': 0.0031, 'eval_accuracy': 0.424, 'eval_precision': 0.4247809112333072, 'eval_recall': 0.424, 'eval_f1': 0.42305708457442626, 'eval_runtime': 157.839, 'eval_samples_per_second': 6.336, 'eval_steps_per_second': 0.792}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:40<00:00,  1.24it/s]\n","{'eval_loss': 2.6777021884918213, 'eval_model_preparation_time': 0.0031, 'eval_accuracy': 0.45, 'eval_precision': 0.4494188489092868, 'eval_recall': 0.45, 'eval_f1': 0.4488433883846398, 'eval_runtime': 101.5393, 'eval_samples_per_second': 9.848, 'eval_steps_per_second': 1.231}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:21<00:00,  1.24it/s]\n","{'eval_loss': 2.810701608657837, 'eval_model_preparation_time': 0.0031, 'eval_accuracy': 0.437, 'eval_precision': 0.43700839591712437, 'eval_recall': 0.437, 'eval_f1': 0.43595875288104946, 'eval_runtime': 202.0968, 'eval_samples_per_second': 9.896, 'eval_steps_per_second': 1.237}\n","100% 125/125 [01:39<00:00,  1.26it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/anli_r1_test/misclassified_English.jsonl\n","100% 125/125 [01:40<00:00,  1.25it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/anli_r1_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m:\n","\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/nlp_final_project/wandb/offline-run-20241202_231020-hnv6cuxh\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241202_231020-hnv6cuxh/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r1/checkpoint-8476 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R2_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/anli_r2_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yd1a_jmozhq","executionInfo":{"status":"ok","timestamp":1733182419181,"user_tz":360,"elapsed":660091,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"29a84beb-c70c-4d20-af6f-8d743b5dc6de"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 23:22:42.428293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 23:22:42.442728: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 23:22:42.446722: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 23:22:42.456693: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 23:22:43.390149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","Generating test split: 2000 examples [00:00, 3507.09 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 3033.71 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7428.50 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7782.23 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:45<00:00,  1.21it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:45<00:00,  1.19it/s]\n","{'eval_loss': 3.440232992172241, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.353, 'eval_precision': 0.3514936472169513, 'eval_recall': 0.353, 'eval_f1': 0.35134638559012693, 'eval_runtime': 106.4563, 'eval_samples_per_second': 9.394, 'eval_steps_per_second': 1.174}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:41<00:00,  1.23it/s]\n","{'eval_loss': 3.03963565826416, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.4, 'eval_precision': 0.39731094025716285, 'eval_recall': 0.4, 'eval_f1': 0.3975088186913957, 'eval_runtime': 102.5348, 'eval_samples_per_second': 9.753, 'eval_steps_per_second': 1.219}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:24<00:00,  1.22it/s]\n","{'eval_loss': 3.2399344444274902, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.3765, 'eval_precision': 0.37440241280643094, 'eval_recall': 0.3765, 'eval_f1': 0.37450139837061547, 'eval_runtime': 205.2638, 'eval_samples_per_second': 9.744, 'eval_steps_per_second': 1.218}\n","100% 125/125 [01:42<00:00,  1.22it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/anli_r2_test/misclassified_English.jsonl\n","100% 125/125 [01:42<00:00,  1.21it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/anli_r2_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m:\n","\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/nlp_final_project/wandb/offline-run-20241202_232301-276yt455\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241202_232301-276yt455/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r1/checkpoint-8476 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R3_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/anli_r3_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7JnlEg9qwq-","executionInfo":{"status":"ok","timestamp":1733183149371,"user_tz":360,"elapsed":730193,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"ca0bf72e-d0ec-4b9c-f17d-cffccdc31934"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 23:33:42.445575: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 23:33:42.459174: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 23:33:42.464076: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 23:33:42.474207: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 23:33:43.413811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","Generating test split: 2400 examples [00:00, 4994.71 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2400/2400 [00:00<00:00, 3249.22 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2400/2400 [00:00<00:00, 7245.41 examples/s]\n","Filter: 100% 2400/2400 [00:00<00:00, 7287.31 examples/s]\n","\n","Evaluation on English test set:\n","100% 150/150 [01:55<00:00,  1.30it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 150/150 [01:55<00:00,  1.30it/s]\n","{'eval_loss': 3.4649739265441895, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.36583333333333334, 'eval_precision': 0.36132552509108745, 'eval_recall': 0.36583333333333334, 'eval_f1': 0.35595508370701706, 'eval_runtime': 117.0279, 'eval_samples_per_second': 10.254, 'eval_steps_per_second': 1.282}\n","\n","Evaluation on Russian test set:\n","100% 150/150 [01:56<00:00,  1.29it/s]\n","{'eval_loss': 3.302203893661499, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.34833333333333333, 'eval_precision': 0.34630678315957997, 'eval_recall': 0.34833333333333333, 'eval_f1': 0.3423798392099884, 'eval_runtime': 117.0425, 'eval_samples_per_second': 10.253, 'eval_steps_per_second': 1.282}\n","\n","Evaluation on the entire test set:\n","100% 300/300 [03:52<00:00,  1.29it/s]\n","{'eval_loss': 3.3835887908935547, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.3570833333333333, 'eval_precision': 0.35382835681477803, 'eval_recall': 0.3570833333333333, 'eval_f1': 0.34945530913705286, 'eval_runtime': 233.4886, 'eval_samples_per_second': 10.279, 'eval_steps_per_second': 1.285}\n","100% 150/150 [01:55<00:00,  1.30it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/anli_r3_test/misclassified_English.jsonl\n","100% 150/150 [01:56<00:00,  1.29it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/anli_r3_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m:\n","\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/nlp_final_project/wandb/offline-run-20241202_233350-a4ogqpft\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241202_233350-a4ogqpft/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r1/checkpoint-8476 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/xnli_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KshJc-uLq0oh","executionInfo":{"status":"ok","timestamp":1733186627883,"user_tz":360,"elapsed":3237622,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"5412f190-1e5f-4938-865d-5db2d40a53d6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-02 23:49:53.688928: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-02 23:49:53.702791: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-02 23:49:53.706823: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-02 23:49:53.716849: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-02 23:49:54.681856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 6329.45 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7704.00 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7596.38 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [08:47<00:00,  1.51it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [08:47<00:00,  1.19it/s]\n","{'eval_loss': 1.4172537326812744, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.7251497005988023, 'eval_precision': 0.7494436628911108, 'eval_recall': 0.7251497005988023, 'eval_f1': 0.7257750783755467, 'eval_runtime': 528.237, 'eval_samples_per_second': 9.484, 'eval_steps_per_second': 1.187}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [08:55<00:00,  1.17it/s]\n","{'eval_loss': 1.7281697988510132, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.6538922155688622, 'eval_precision': 0.683433245550407, 'eval_recall': 0.6538922155688622, 'eval_f1': 0.6530841221905677, 'eval_runtime': 536.3414, 'eval_samples_per_second': 9.341, 'eval_steps_per_second': 1.169}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [17:49<00:00,  1.17it/s]\n","{'eval_loss': 1.572711706161499, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.6895209580838323, 'eval_precision': 0.7166942304007425, 'eval_recall': 0.6895209580838323, 'eval_f1': 0.6895757633326424, 'eval_runtime': 1070.3275, 'eval_samples_per_second': 9.362, 'eval_steps_per_second': 1.171}\n","100% 627/627 [08:59<00:00,  1.16it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/xnli_test/misclassified_English.jsonl\n","100% 627/627 [08:53<00:00,  1.18it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r1_model_testing/xnli_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m:\n","\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/nlp_final_project/wandb/offline-run-20241202_235000-izk97cjg\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241202_235000-izk97cjg/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r2/checkpoint-22732 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/xnli_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O95ctQBDvc4q","executionInfo":{"status":"ok","timestamp":1733191686296,"user_tz":360,"elapsed":3040371,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"576227a4-da20-4638-9a57-7e811235e1d4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 01:17:29.684574: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 01:17:29.699497: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 01:17:29.703534: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 01:17:29.714171: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 01:17:30.721661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 7510.23 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7671.76 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7643.17 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [08:36<00:00,  1.64it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [08:36<00:00,  1.21it/s]\n","{'eval_loss': 1.7337021827697754, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.675249500998004, 'eval_precision': 0.71768135905764, 'eval_recall': 0.675249500998004, 'eval_f1': 0.6748186692358252, 'eval_runtime': 524.0734, 'eval_samples_per_second': 9.56, 'eval_steps_per_second': 1.196}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [08:19<00:00,  1.26it/s]\n","{'eval_loss': 2.1365838050842285, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.5882235528942116, 'eval_precision': 0.6394387548509496, 'eval_recall': 0.5882235528942116, 'eval_f1': 0.581229398187475, 'eval_runtime': 500.0631, 'eval_samples_per_second': 10.019, 'eval_steps_per_second': 1.254}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [16:25<00:00,  1.27it/s]\n","{'eval_loss': 1.935142993927002, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.6317365269461078, 'eval_precision': 0.6796771674427141, 'eval_recall': 0.6317365269461078, 'eval_f1': 0.6286343387163794, 'eval_runtime': 986.4069, 'eval_samples_per_second': 10.158, 'eval_steps_per_second': 1.27}\n","100% 627/627 [08:14<00:00,  1.27it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/xnli_test/misclassified_English.jsonl\n","100% 627/627 [08:18<00:00,  1.26it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/xnli_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r2/checkpoint-22732 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R3_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/anli_r3_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovSaCUf3F_L_","executionInfo":{"status":"ok","timestamp":1733192419643,"user_tz":360,"elapsed":733368,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"5d914489-4d35-4a68-8d28-998185d991be"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 02:08:09.620002: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 02:08:09.634307: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 02:08:09.638375: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 02:08:09.648533: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 02:08:10.593907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2400/2400 [00:00<00:00, 3226.10 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2400/2400 [00:00<00:00, 7503.73 examples/s]\n","Filter: 100% 2400/2400 [00:00<00:00, 7622.13 examples/s]\n","\n","Evaluation on English test set:\n","100% 150/150 [01:58<00:00,  1.28it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 150/150 [01:58<00:00,  1.27it/s]\n","{'eval_loss': 3.3403480052948, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.3933333333333333, 'eval_precision': 0.3929189640768588, 'eval_recall': 0.3933333333333333, 'eval_f1': 0.38306426084203865, 'eval_runtime': 119.4785, 'eval_samples_per_second': 10.044, 'eval_steps_per_second': 1.255}\n","\n","Evaluation on Russian test set:\n","100% 150/150 [02:00<00:00,  1.24it/s]\n","{'eval_loss': 3.315581798553467, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.3458333333333333, 'eval_precision': 0.34203708830437646, 'eval_recall': 0.3458333333333333, 'eval_f1': 0.33580356490813346, 'eval_runtime': 121.5296, 'eval_samples_per_second': 9.874, 'eval_steps_per_second': 1.234}\n","\n","Evaluation on the entire test set:\n","100% 300/300 [03:55<00:00,  1.28it/s]\n","{'eval_loss': 3.327965021133423, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.3695833333333333, 'eval_precision': 0.3673944257658503, 'eval_recall': 0.3695833333333333, 'eval_f1': 0.3594186275328669, 'eval_runtime': 236.0827, 'eval_samples_per_second': 10.166, 'eval_steps_per_second': 1.271}\n","100% 150/150 [01:57<00:00,  1.28it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/anli_r3_test/misclassified_English.jsonl\n","100% 150/150 [01:58<00:00,  1.27it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/anli_r3_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r2/checkpoint-22732 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R2_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/anli_r2_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUCZQV73GIRS","executionInfo":{"status":"ok","timestamp":1733193072069,"user_tz":360,"elapsed":652444,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"9a8a08cc-a015-4fe8-e4ad-b3b8375db3b6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 02:20:23.041790: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 02:20:23.057500: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 02:20:23.061630: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 02:20:23.072138: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 02:20:24.057480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2751.21 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7478.12 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7509.89 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:46<00:00,  1.17it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:46<00:00,  1.18it/s]\n","{'eval_loss': 2.8699326515197754, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.47, 'eval_precision': 0.4703141809133236, 'eval_recall': 0.47, 'eval_f1': 0.46371105927864376, 'eval_runtime': 107.3822, 'eval_samples_per_second': 9.313, 'eval_steps_per_second': 1.164}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:44<00:00,  1.19it/s]\n","{'eval_loss': 2.8580172061920166, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.46, 'eval_precision': 0.4609231498140817, 'eval_recall': 0.46, 'eval_f1': 0.45368785103945386, 'eval_runtime': 105.7276, 'eval_samples_per_second': 9.458, 'eval_steps_per_second': 1.182}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:28<00:00,  1.20it/s]\n","{'eval_loss': 2.8639748096466064, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.465, 'eval_precision': 0.4654821108891997, 'eval_recall': 0.465, 'eval_f1': 0.4586881242192831, 'eval_runtime': 209.2766, 'eval_samples_per_second': 9.557, 'eval_steps_per_second': 1.195}\n","100% 125/125 [01:44<00:00,  1.20it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/anli_r2_test/misclassified_English.jsonl\n","100% 125/125 [01:44<00:00,  1.19it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/anli_r2_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r2/checkpoint-22732 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R1_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/anli_r1_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zaL9KyISGMso","executionInfo":{"status":"ok","timestamp":1733193690135,"user_tz":360,"elapsed":618082,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"396e8526-55ad-4bb0-d63d-efd8b21eeb19"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 02:31:15.378280: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 02:31:15.392732: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 02:31:15.396706: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 02:31:15.407404: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 02:31:16.356448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2911.78 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7398.96 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7384.12 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:40<00:00,  1.29it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:40<00:00,  1.25it/s]\n","{'eval_loss': 2.513634443283081, 'eval_model_preparation_time': 0.0032, 'eval_accuracy': 0.511, 'eval_precision': 0.5143500446118767, 'eval_recall': 0.511, 'eval_f1': 0.5045467442154508, 'eval_runtime': 101.4618, 'eval_samples_per_second': 9.856, 'eval_steps_per_second': 1.232}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:37<00:00,  1.29it/s]\n","{'eval_loss': 2.339719295501709, 'eval_model_preparation_time': 0.0032, 'eval_accuracy': 0.535, 'eval_precision': 0.5413726256045406, 'eval_recall': 0.535, 'eval_f1': 0.5299456891247369, 'eval_runtime': 98.0283, 'eval_samples_per_second': 10.201, 'eval_steps_per_second': 1.275}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:19<00:00,  1.25it/s]\n","{'eval_loss': 2.4266767501831055, 'eval_model_preparation_time': 0.0032, 'eval_accuracy': 0.523, 'eval_precision': 0.5278893194247766, 'eval_recall': 0.523, 'eval_f1': 0.5172522858565906, 'eval_runtime': 200.0069, 'eval_samples_per_second': 10.0, 'eval_steps_per_second': 1.25}\n","100% 125/125 [01:37<00:00,  1.28it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/anli_r1_test/misclassified_English.jsonl\n","100% 125/125 [01:38<00:00,  1.26it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r2_model_testing/anli_r1_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r3/checkpoint-62790 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/xnli_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7B65aljGPgu","executionInfo":{"status":"ok","timestamp":1733196697957,"user_tz":360,"elapsed":3007841,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"0af30f75-954e-4c4f-e9bc-fe951a8baec3"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 02:41:33.630797: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 02:41:33.645156: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 02:41:33.649212: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 02:41:33.659571: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 02:41:34.654942: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 7381.93 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7926.20 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7802.11 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [08:10<00:00,  1.65it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [08:10<00:00,  1.28it/s]\n","{'eval_loss': 1.738822340965271, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.6970059880239521, 'eval_precision': 0.7169698343093487, 'eval_recall': 0.6970059880239521, 'eval_f1': 0.6979493166112962, 'eval_runtime': 497.4219, 'eval_samples_per_second': 10.072, 'eval_steps_per_second': 1.26}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [08:18<00:00,  1.26it/s]\n","{'eval_loss': 2.1681082248687744, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.6157684630738522, 'eval_precision': 0.6390648962339944, 'eval_recall': 0.6157684630738522, 'eval_f1': 0.6140566792176267, 'eval_runtime': 498.7761, 'eval_samples_per_second': 10.045, 'eval_steps_per_second': 1.257}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [16:24<00:00,  1.27it/s]\n","{'eval_loss': 1.9534653425216675, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.6563872255489022, 'eval_precision': 0.6785071053495461, 'eval_recall': 0.6563872255489022, 'eval_f1': 0.6562579348799077, 'eval_runtime': 985.4289, 'eval_samples_per_second': 10.168, 'eval_steps_per_second': 1.272}\n","100% 627/627 [08:15<00:00,  1.27it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/xnli_test/misclassified_English.jsonl\n","100% 627/627 [08:16<00:00,  1.26it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/xnli_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r3/checkpoint-62790 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R1_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/anli_r1_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"usZTzGzfJY-4","executionInfo":{"status":"ok","timestamp":1733197346237,"user_tz":360,"elapsed":648300,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"36658dbb-541c-459a-bd93-3c28c648625b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 03:31:41.394208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 03:31:41.408726: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 03:31:41.412884: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 03:31:41.423403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 03:31:42.422929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2794.55 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7486.08 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7502.01 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:46<00:00,  1.21it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:46<00:00,  1.18it/s]\n","{'eval_loss': 2.74578595161438, 'eval_model_preparation_time': 0.003, 'eval_accuracy': 0.542, 'eval_precision': 0.5437114256122778, 'eval_recall': 0.542, 'eval_f1': 0.539745091855991, 'eval_runtime': 107.4299, 'eval_samples_per_second': 9.308, 'eval_steps_per_second': 1.164}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:44<00:00,  1.20it/s]\n","{'eval_loss': 2.7547450065612793, 'eval_model_preparation_time': 0.003, 'eval_accuracy': 0.518, 'eval_precision': 0.5235004827831099, 'eval_recall': 0.518, 'eval_f1': 0.5157155157015482, 'eval_runtime': 104.8707, 'eval_samples_per_second': 9.536, 'eval_steps_per_second': 1.192}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:27<00:00,  1.20it/s]\n","{'eval_loss': 2.750265598297119, 'eval_model_preparation_time': 0.003, 'eval_accuracy': 0.53, 'eval_precision': 0.533245137789764, 'eval_recall': 0.53, 'eval_f1': 0.5276394423436885, 'eval_runtime': 208.3598, 'eval_samples_per_second': 9.599, 'eval_steps_per_second': 1.2}\n","100% 125/125 [01:43<00:00,  1.21it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/anli_r1_test/misclassified_English.jsonl\n","100% 125/125 [01:43<00:00,  1.21it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/anli_r1_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r3/checkpoint-62790 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R2_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/anli_r2_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zI_Xpo06JeT1","executionInfo":{"status":"ok","timestamp":1733197986565,"user_tz":360,"elapsed":640349,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"2c0cb28c-92a6-4244-85fd-97571489b5f5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 03:42:29.584550: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 03:42:29.599279: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 03:42:29.603399: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 03:42:29.613864: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 03:42:30.592061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2767.39 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7387.63 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7415.66 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:44<00:00,  1.21it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:44<00:00,  1.20it/s]\n","{'eval_loss': 3.409207820892334, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.448, 'eval_precision': 0.44536738424464206, 'eval_recall': 0.448, 'eval_f1': 0.44150118401955546, 'eval_runtime': 105.5507, 'eval_samples_per_second': 9.474, 'eval_steps_per_second': 1.184}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:42<00:00,  1.22it/s]\n","{'eval_loss': 3.3042304515838623, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.449, 'eval_precision': 0.4482239696205969, 'eval_recall': 0.449, 'eval_f1': 0.4449703012648927, 'eval_runtime': 103.2834, 'eval_samples_per_second': 9.682, 'eval_steps_per_second': 1.21}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:24<00:00,  1.22it/s]\n","{'eval_loss': 3.3567192554473877, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.4485, 'eval_precision': 0.44691921095047593, 'eval_recall': 0.4485, 'eval_f1': 0.44334614065565603, 'eval_runtime': 205.4178, 'eval_samples_per_second': 9.736, 'eval_steps_per_second': 1.217}\n","100% 125/125 [01:42<00:00,  1.22it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/anli_r2_test/misclassified_English.jsonl\n","100% 125/125 [01:42<00:00,  1.22it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/anli_r2_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/r3/checkpoint-62790 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R3_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/anli_r3_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rlOo-byCJhaV","executionInfo":{"status":"ok","timestamp":1733198716371,"user_tz":360,"elapsed":729836,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"1183ac59-3cc0-4756-8d84-c8131a960ecf"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 03:53:09.840956: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 03:53:09.855659: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 03:53:09.859804: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 03:53:09.870452: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 03:53:10.858696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2400/2400 [00:00<00:00, 3136.73 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2400/2400 [00:00<00:00, 7541.60 examples/s]\n","Filter: 100% 2400/2400 [00:00<00:00, 7770.71 examples/s]\n","\n","Evaluation on English test set:\n","100% 150/150 [01:56<00:00,  1.28it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 150/150 [01:56<00:00,  1.29it/s]\n","{'eval_loss': 3.359679698944092, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.4475, 'eval_precision': 0.44942466434890427, 'eval_recall': 0.4475, 'eval_f1': 0.44178205837408163, 'eval_runtime': 117.8329, 'eval_samples_per_second': 10.184, 'eval_steps_per_second': 1.273}\n","\n","Evaluation on Russian test set:\n","100% 150/150 [01:57<00:00,  1.28it/s]\n","{'eval_loss': 3.3287930488586426, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.4075, 'eval_precision': 0.40791969362124625, 'eval_recall': 0.4075, 'eval_f1': 0.403772651553785, 'eval_runtime': 118.2681, 'eval_samples_per_second': 10.146, 'eval_steps_per_second': 1.268}\n","\n","Evaluation on the entire test set:\n","100% 300/300 [03:55<00:00,  1.27it/s]\n","{'eval_loss': 3.344236373901367, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.4275, 'eval_precision': 0.42827253430519, 'eval_recall': 0.4275, 'eval_f1': 0.42286320127159077, 'eval_runtime': 236.1386, 'eval_samples_per_second': 10.164, 'eval_steps_per_second': 1.27}\n","100% 150/150 [01:57<00:00,  1.27it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/anli_r3_test/misclassified_English.jsonl\n","100% 150/150 [01:57<00:00,  1.28it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/anli_r3_model_testing/anli_r3_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/negation/checkpoint-2118 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/negation_testing/xnli_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"efdKe2nEJjQ3","executionInfo":{"status":"ok","timestamp":1733204900252,"user_tz":360,"elapsed":3004721,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"d7b39591-59b8-4dbe-bf1e-ae488efa6cf3"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 04:58:19.205715: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 04:58:19.219755: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 04:58:19.223781: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 04:58:19.234093: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 04:58:20.202137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 7875.80 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7918.86 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7824.20 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [08:33<00:00,  1.64it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [08:33<00:00,  1.22it/s]\n","{'eval_loss': 1.1008360385894775, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.681437125748503, 'eval_precision': 0.6994299874618933, 'eval_recall': 0.681437125748503, 'eval_f1': 0.6821809024532892, 'eval_runtime': 519.0182, 'eval_samples_per_second': 9.653, 'eval_steps_per_second': 1.208}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [08:09<00:00,  1.28it/s]\n","{'eval_loss': 1.3431018590927124, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.5940119760479042, 'eval_precision': 0.6142651267708464, 'eval_recall': 0.5940119760479042, 'eval_f1': 0.5934555688510192, 'eval_runtime': 490.209, 'eval_samples_per_second': 10.22, 'eval_steps_per_second': 1.279}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [16:22<00:00,  1.28it/s]\n","{'eval_loss': 1.2219690084457397, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.6377245508982036, 'eval_precision': 0.6571449806118439, 'eval_recall': 0.6377245508982036, 'eval_f1': 0.637944117537391, 'eval_runtime': 983.2251, 'eval_samples_per_second': 10.191, 'eval_steps_per_second': 1.274}\n","100% 627/627 [08:09<00:00,  1.28it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/negation_testing/xnli_test/misclassified_English.jsonl\n","100% 627/627 [08:08<00:00,  1.28it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/negation_testing/xnli_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/negation/checkpoint-2118 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R3_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/negation_testing/anli_r3_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZzahpIP4h9T","executionInfo":{"status":"ok","timestamp":1733205661394,"user_tz":360,"elapsed":761145,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"dd4f23c9-84f3-49df-a488-e57c24607cf4"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 05:48:23.634715: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 05:48:23.648979: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 05:48:23.653000: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 05:48:23.663052: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 05:48:24.644052: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2400/2400 [00:00<00:00, 3031.04 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2400/2400 [00:00<00:00, 7074.03 examples/s]\n","Filter: 100% 2400/2400 [00:00<00:00, 7482.35 examples/s]\n","\n","Evaluation on English test set:\n","100% 150/150 [01:56<00:00,  1.24it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 150/150 [01:56<00:00,  1.29it/s]\n","{'eval_loss': 2.0275492668151855, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.45166666666666666, 'eval_precision': 0.45473164941499494, 'eval_recall': 0.45166666666666666, 'eval_f1': 0.447414308607928, 'eval_runtime': 117.7034, 'eval_samples_per_second': 10.195, 'eval_steps_per_second': 1.274}\n","\n","Evaluation on Russian test set:\n","100% 150/150 [01:56<00:00,  1.28it/s]\n","{'eval_loss': 1.927852988243103, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.43, 'eval_precision': 0.43297825832390024, 'eval_recall': 0.43, 'eval_f1': 0.4256918769423559, 'eval_runtime': 117.6555, 'eval_samples_per_second': 10.199, 'eval_steps_per_second': 1.275}\n","\n","Evaluation on the entire test set:\n","100% 300/300 [04:28<00:00,  1.12it/s]\n","{'eval_loss': 1.9777010679244995, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.44083333333333335, 'eval_precision': 0.4439349337734497, 'eval_recall': 0.44083333333333335, 'eval_f1': 0.43660841782214777, 'eval_runtime': 269.5829, 'eval_samples_per_second': 8.903, 'eval_steps_per_second': 1.113}\n","100% 150/150 [01:57<00:00,  1.28it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/negation_testing/anli_r3_test/misclassified_English.jsonl\n","100% 150/150 [01:57<00:00,  1.28it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/negation_testing/anli_r3_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/negation/checkpoint-2118 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R2_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/negation_testing/anli_r2_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYh1ZxLA4qg_","executionInfo":{"status":"ok","timestamp":1733206275855,"user_tz":360,"elapsed":614464,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"40f16150-d6c1-4888-a38f-8f63ed1cdb9f"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 06:01:04.800138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 06:01:04.814125: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 06:01:04.818098: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 06:01:04.828517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 06:01:05.786693: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2819.38 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7510.72 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7619.00 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:38<00:00,  1.25it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:38<00:00,  1.27it/s]\n","{'eval_loss': 2.0068492889404297, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.409, 'eval_precision': 0.4106899622545485, 'eval_recall': 0.409, 'eval_f1': 0.4000795276576966, 'eval_runtime': 99.871, 'eval_samples_per_second': 10.013, 'eval_steps_per_second': 1.252}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:39<00:00,  1.26it/s]\n","{'eval_loss': 1.8396871089935303, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.416, 'eval_precision': 0.4178704767810141, 'eval_recall': 0.416, 'eval_f1': 0.40971789299037376, 'eval_runtime': 99.8592, 'eval_samples_per_second': 10.014, 'eval_steps_per_second': 1.252}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:16<00:00,  1.27it/s]\n","{'eval_loss': 1.9232683181762695, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.4125, 'eval_precision': 0.4143285415542924, 'eval_recall': 0.4125, 'eval_f1': 0.40497369324400895, 'eval_runtime': 197.6096, 'eval_samples_per_second': 10.121, 'eval_steps_per_second': 1.265}\n","100% 125/125 [01:37<00:00,  1.28it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/negation_testing/anli_r2_test/misclassified_English.jsonl\n","100% 125/125 [01:38<00:00,  1.27it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/negation_testing/anli_r2_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/negation/checkpoint-2118 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R1_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/negation_testing/anli_r1_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8amXmtF4uBz","executionInfo":{"status":"ok","timestamp":1733206886150,"user_tz":360,"elapsed":610299,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"33b10a39-1cc4-4fa9-a733-0dbf20e39906"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 06:11:19.088816: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 06:11:19.103392: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 06:11:19.107512: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 06:11:19.117929: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 06:11:20.081729: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2924.59 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7450.26 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7668.99 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:38<00:00,  1.26it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:38<00:00,  1.27it/s]\n","{'eval_loss': 1.6115480661392212, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.484, 'eval_precision': 0.4971967278235139, 'eval_recall': 0.484, 'eval_f1': 0.4785609665600111, 'eval_runtime': 99.3413, 'eval_samples_per_second': 10.066, 'eval_steps_per_second': 1.258}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:37<00:00,  1.28it/s]\n","{'eval_loss': 1.5554841756820679, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.481, 'eval_precision': 0.488020807350129, 'eval_recall': 0.481, 'eval_f1': 0.4733380956813105, 'eval_runtime': 98.3856, 'eval_samples_per_second': 10.164, 'eval_steps_per_second': 1.271}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:16<00:00,  1.27it/s]\n","{'eval_loss': 1.5835161209106445, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.4825, 'eval_precision': 0.49203029056155334, 'eval_recall': 0.4825, 'eval_f1': 0.4758833762382385, 'eval_runtime': 196.8474, 'eval_samples_per_second': 10.16, 'eval_steps_per_second': 1.27}\n","100% 125/125 [01:37<00:00,  1.28it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/negation_testing/anli_r1_test/misclassified_English.jsonl\n","100% 125/125 [01:37<00:00,  1.28it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/negation_testing/anli_r1_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/attribution/checkpoint-5268 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/attribution_testing/xnli_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rRQUcbwe4wV1","executionInfo":{"status":"ok","timestamp":1733209854100,"user_tz":360,"elapsed":2967110,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"11bbbffc-b408-4e4d-b328-035dd7073ec9"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 06:21:30.352140: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 06:21:30.367893: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 06:21:30.372123: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 06:21:30.382906: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 06:21:31.389862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 7614.94 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7711.02 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7865.09 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [08:11<00:00,  1.65it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [08:11<00:00,  1.28it/s]\n","{'eval_loss': 1.7215588092803955, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.688622754491018, 'eval_precision': 0.7022471045962625, 'eval_recall': 0.688622754491018, 'eval_f1': 0.6897221128973996, 'eval_runtime': 496.091, 'eval_samples_per_second': 10.099, 'eval_steps_per_second': 1.264}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [08:10<00:00,  1.28it/s]\n","{'eval_loss': 2.1083521842956543, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.6107784431137725, 'eval_precision': 0.6266871299536885, 'eval_recall': 0.6107784431137725, 'eval_f1': 0.6109832222640217, 'eval_runtime': 491.1033, 'eval_samples_per_second': 10.202, 'eval_steps_per_second': 1.277}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [16:15<00:00,  1.28it/s]\n","{'eval_loss': 1.9149556159973145, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.6497005988023952, 'eval_precision': 0.6646993293003415, 'eval_recall': 0.6497005988023952, 'eval_f1': 0.6504630423604818, 'eval_runtime': 976.2479, 'eval_samples_per_second': 10.264, 'eval_steps_per_second': 1.283}\n","100% 627/627 [08:03<00:00,  1.30it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/attribution_testing/xnli_test/misclassified_English.jsonl\n","100% 627/627 [08:02<00:00,  1.30it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/attribution_testing/xnli_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/attribution/checkpoint-5268 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R1_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/attribution_testing/anli_r1_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuEMFy9645ZI","executionInfo":{"status":"ok","timestamp":1733210454497,"user_tz":360,"elapsed":600406,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"ff5673b4-152c-4f40-a34f-a0b0bb211780"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 07:10:57.494635: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 07:10:57.511472: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 07:10:57.517042: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 07:10:57.535842: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 07:10:58.519827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2859.14 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7555.30 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7511.18 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:37<00:00,  1.27it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:37<00:00,  1.29it/s]\n","{'eval_loss': 2.5468246936798096, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.532, 'eval_precision': 0.5319173982863833, 'eval_recall': 0.532, 'eval_f1': 0.5288336730441601, 'eval_runtime': 98.2667, 'eval_samples_per_second': 10.176, 'eval_steps_per_second': 1.272}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:35<00:00,  1.30it/s]\n","{'eval_loss': 2.5518054962158203, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.528, 'eval_precision': 0.5307543135016972, 'eval_recall': 0.528, 'eval_f1': 0.5230725269665325, 'eval_runtime': 96.6984, 'eval_samples_per_second': 10.341, 'eval_steps_per_second': 1.293}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:12<00:00,  1.30it/s]\n","{'eval_loss': 2.5493149757385254, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.53, 'eval_precision': 0.5310690154301224, 'eval_recall': 0.53, 'eval_f1': 0.5259796965221044, 'eval_runtime': 192.8849, 'eval_samples_per_second': 10.369, 'eval_steps_per_second': 1.296}\n","100% 125/125 [01:35<00:00,  1.30it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/attribution_testing/anli_r1_test/misclassified_English.jsonl\n","100% 125/125 [01:35<00:00,  1.31it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/attribution_testing/anli_r1_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/attribution/checkpoint-5268 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R2_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/attribution_testing/anli_r2_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2lpaH1v04_Rx","executionInfo":{"status":"ok","timestamp":1733211114190,"user_tz":360,"elapsed":659725,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"b9440071-1c89-4a76-c2b6-14ff560e2a4a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 07:20:57.678328: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 07:20:57.692478: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 07:20:57.696498: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 07:20:57.706573: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 07:20:58.649851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2956.35 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7537.88 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7556.30 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:36<00:00,  1.30it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:37<00:00,  1.29it/s]\n","{'eval_loss': 3.2347021102905273, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.445, 'eval_precision': 0.4457965067727945, 'eval_recall': 0.445, 'eval_f1': 0.4393963193744109, 'eval_runtime': 98.1032, 'eval_samples_per_second': 10.193, 'eval_steps_per_second': 1.274}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:36<00:00,  1.29it/s]\n","{'eval_loss': 3.3179025650024414, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.413, 'eval_precision': 0.40897829449067097, 'eval_recall': 0.413, 'eval_f1': 0.4071235732884887, 'eval_runtime': 97.6114, 'eval_samples_per_second': 10.245, 'eval_steps_per_second': 1.281}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:33<00:00,  1.17it/s]\n","{'eval_loss': 3.2763023376464844, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.429, 'eval_precision': 0.4272953447932567, 'eval_recall': 0.429, 'eval_f1': 0.42337425990972827, 'eval_runtime': 214.5327, 'eval_samples_per_second': 9.323, 'eval_steps_per_second': 1.165}\n","100% 125/125 [01:52<00:00,  1.11it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/attribution_testing/anli_r2_test/misclassified_English.jsonl\n","100% 125/125 [01:56<00:00,  1.08it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/attribution_testing/anli_r2_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/attribution/checkpoint-5268 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R3_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/attribution_testing/anli_r3_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UItc4csc5CNc","executionInfo":{"status":"ok","timestamp":1733211963721,"user_tz":360,"elapsed":849551,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"960ae03f-ee47-4708-a83f-e763bfd9680a"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 07:31:58.089697: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 07:31:58.105186: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 07:31:58.110204: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 07:31:58.122897: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 07:31:59.188923: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2400/2400 [00:00<00:00, 2617.97 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2400/2400 [00:00<00:00, 7070.62 examples/s]\n","Filter: 100% 2400/2400 [00:00<00:00, 7385.10 examples/s]\n","\n","Evaluation on English test set:\n","100% 150/150 [02:19<00:00,  1.11it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 150/150 [02:19<00:00,  1.08it/s]\n","{'eval_loss': 3.2452034950256348, 'eval_model_preparation_time': 0.0032, 'eval_accuracy': 0.4533333333333333, 'eval_precision': 0.45567942193619654, 'eval_recall': 0.4533333333333333, 'eval_f1': 0.4507212400282349, 'eval_runtime': 140.4647, 'eval_samples_per_second': 8.543, 'eval_steps_per_second': 1.068}\n","\n","Evaluation on Russian test set:\n","100% 150/150 [02:08<00:00,  1.17it/s]\n","{'eval_loss': 3.365535259246826, 'eval_model_preparation_time': 0.0032, 'eval_accuracy': 0.41083333333333333, 'eval_precision': 0.4124336328045794, 'eval_recall': 0.41083333333333333, 'eval_f1': 0.40770862757865295, 'eval_runtime': 129.5757, 'eval_samples_per_second': 9.261, 'eval_steps_per_second': 1.158}\n","\n","Evaluation on the entire test set:\n","100% 300/300 [04:22<00:00,  1.14it/s]\n","{'eval_loss': 3.3053693771362305, 'eval_model_preparation_time': 0.0032, 'eval_accuracy': 0.4320833333333333, 'eval_precision': 0.4339474300259503, 'eval_recall': 0.4320833333333333, 'eval_f1': 0.4292474747241721, 'eval_runtime': 263.2622, 'eval_samples_per_second': 9.116, 'eval_steps_per_second': 1.14}\n","100% 150/150 [02:23<00:00,  1.04it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/attribution_testing/anli_r3_test/misclassified_English.jsonl\n","100% 150/150 [02:29<00:00,  1.01it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/attribution_testing/anli_r3_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/high_overlap/checkpoint-199 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/high_overlap_testing/xnli_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmotYjWZ5EfB","executionInfo":{"status":"ok","timestamp":1733215539962,"user_tz":360,"elapsed":3576278,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"3fc67178-993d-4690-e4af-2cc7c2e15e21"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 07:46:07.532170: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 07:46:07.546794: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 07:46:07.551312: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 07:46:07.562109: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 07:46:08.665663: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 6299.27 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7688.59 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7543.78 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [10:32<00:00,  1.38it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [10:32<00:00,  1.01s/it]\n","{'eval_loss': 1.1441164016723633, 'eval_model_preparation_time': 0.0038, 'eval_accuracy': 0.6872255489021956, 'eval_precision': 0.7014571833945843, 'eval_recall': 0.6872255489021956, 'eval_f1': 0.6861994070339219, 'eval_runtime': 641.6285, 'eval_samples_per_second': 7.808, 'eval_steps_per_second': 0.977}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [10:45<00:00,  1.03s/it]\n","{'eval_loss': 1.4034885168075562, 'eval_model_preparation_time': 0.0038, 'eval_accuracy': 0.5972055888223553, 'eval_precision': 0.6158266797155681, 'eval_recall': 0.5972055888223553, 'eval_f1': 0.59216817757667, 'eval_runtime': 646.7303, 'eval_samples_per_second': 7.747, 'eval_steps_per_second': 0.969}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [17:39<00:00,  1.18it/s]\n","{'eval_loss': 1.2738025188446045, 'eval_model_preparation_time': 0.0038, 'eval_accuracy': 0.6422155688622755, 'eval_precision': 0.6591189182773062, 'eval_recall': 0.6422155688622755, 'eval_f1': 0.6395392031405085, 'eval_runtime': 1060.2801, 'eval_samples_per_second': 9.45, 'eval_steps_per_second': 1.182}\n","100% 627/627 [10:17<00:00,  1.01it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/high_overlap_testing/xnli_test/misclassified_English.jsonl\n","100% 627/627 [09:31<00:00,  1.10it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/high_overlap_testing/xnli_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/high_overlap/checkpoint-199 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R1_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/high_overlap_testing/anli_r1_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wr8I57YS5SyX","executionInfo":{"status":"ok","timestamp":1733216233238,"user_tz":360,"elapsed":693296,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"a08c959d-94bd-4a34-be43-b5c6faf2891e"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 08:45:44.020122: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 08:45:44.037288: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 08:45:44.043062: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 08:45:44.061846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 08:45:45.135241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2602.44 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7226.96 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 7206.05 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:52<00:00,  1.20it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:52<00:00,  1.11it/s]\n","{'eval_loss': 1.7612605094909668, 'eval_model_preparation_time': 0.004, 'eval_accuracy': 0.483, 'eval_precision': 0.48933099284769377, 'eval_recall': 0.483, 'eval_f1': 0.48253457671670635, 'eval_runtime': 113.805, 'eval_samples_per_second': 8.787, 'eval_steps_per_second': 1.098}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:50<00:00,  1.13it/s]\n","{'eval_loss': 1.6489697694778442, 'eval_model_preparation_time': 0.004, 'eval_accuracy': 0.491, 'eval_precision': 0.4955859697568124, 'eval_recall': 0.491, 'eval_f1': 0.489674398034398, 'eval_runtime': 111.2868, 'eval_samples_per_second': 8.986, 'eval_steps_per_second': 1.123}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:42<00:00,  1.12it/s]\n","{'eval_loss': 1.7051150798797607, 'eval_model_preparation_time': 0.004, 'eval_accuracy': 0.487, 'eval_precision': 0.49245087276130406, 'eval_recall': 0.487, 'eval_f1': 0.48610104011293104, 'eval_runtime': 223.5925, 'eval_samples_per_second': 8.945, 'eval_steps_per_second': 1.118}\n","100% 125/125 [01:49<00:00,  1.14it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/high_overlap_testing/anli_r1_test/misclassified_English.jsonl\n","100% 125/125 [01:52<00:00,  1.11it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/high_overlap_testing/anli_r1_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/high_overlap/checkpoint-199 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R2_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/high_overlap_testing/anli_r2_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K8Yge0bi5Z3_","executionInfo":{"status":"ok","timestamp":1733216959091,"user_tz":360,"elapsed":725868,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"e97bcfc0-3ac8-4ede-925a-8afb4d486e69"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 08:57:16.825416: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 08:57:16.840952: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 08:57:16.845124: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 08:57:16.855835: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 08:57:17.881207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2723.29 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 7112.56 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 6889.23 examples/s]\n","\n","Evaluation on English test set:\n","100% 125/125 [01:52<00:00,  1.10it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [01:52<00:00,  1.11it/s]\n","{'eval_loss': 2.1167211532592773, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.419, 'eval_precision': 0.42042772329160955, 'eval_recall': 0.419, 'eval_f1': 0.4153799742037086, 'eval_runtime': 113.9703, 'eval_samples_per_second': 8.774, 'eval_steps_per_second': 1.097}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [01:57<00:00,  1.06it/s]\n","{'eval_loss': 2.0418341159820557, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.398, 'eval_precision': 0.40082621058956336, 'eval_recall': 0.398, 'eval_f1': 0.3972975992042691, 'eval_runtime': 118.6703, 'eval_samples_per_second': 8.427, 'eval_steps_per_second': 1.053}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [03:59<00:00,  1.04it/s]\n","{'eval_loss': 2.079277753829956, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.4085, 'eval_precision': 0.41058847644265223, 'eval_recall': 0.4085, 'eval_f1': 0.406468259789545, 'eval_runtime': 240.9205, 'eval_samples_per_second': 8.301, 'eval_steps_per_second': 1.038}\n","100% 125/125 [01:56<00:00,  1.07it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/high_overlap_testing/anli_r2_test/misclassified_English.jsonl\n","100% 125/125 [01:52<00:00,  1.11it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/high_overlap_testing/anli_r2_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/high_overlap/checkpoint-199 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R3_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/high_overlap_testing/anli_r3_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJUc8WWJ5cz8","executionInfo":{"status":"ok","timestamp":1733217837654,"user_tz":360,"elapsed":878590,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"821b309c-7da6-4b73-b3a3-e75e9730e216"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 09:09:22.857846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 09:09:22.873657: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 09:09:22.878126: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 09:09:22.889548: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 09:09:23.903712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2400/2400 [00:00<00:00, 2553.85 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2400/2400 [00:00<00:00, 7563.05 examples/s]\n","Filter: 100% 2400/2400 [00:00<00:00, 7596.74 examples/s]\n","\n","Evaluation on English test set:\n","100% 150/150 [02:22<00:00,  1.03it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 150/150 [02:22<00:00,  1.05it/s]\n","{'eval_loss': 2.164536476135254, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.43916666666666665, 'eval_precision': 0.4392971721762396, 'eval_recall': 0.43916666666666665, 'eval_f1': 0.4391941315054073, 'eval_runtime': 143.9608, 'eval_samples_per_second': 8.336, 'eval_steps_per_second': 1.042}\n","\n","Evaluation on Russian test set:\n","100% 150/150 [02:24<00:00,  1.04it/s]\n","{'eval_loss': 2.1344804763793945, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.4025, 'eval_precision': 0.4031361180729601, 'eval_recall': 0.4025, 'eval_f1': 0.4016648945959197, 'eval_runtime': 145.1923, 'eval_samples_per_second': 8.265, 'eval_steps_per_second': 1.033}\n","\n","Evaluation on the entire test set:\n","100% 300/300 [04:43<00:00,  1.06it/s]\n","{'eval_loss': 2.149508476257324, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.42083333333333334, 'eval_precision': 0.42125415413342454, 'eval_recall': 0.42083333333333334, 'eval_f1': 0.42063204478911426, 'eval_runtime': 284.4992, 'eval_samples_per_second': 8.436, 'eval_steps_per_second': 1.054}\n","100% 150/150 [02:18<00:00,  1.09it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/high_overlap_testing/anli_r3_test/misclassified_English.jsonl\n","100% 150/150 [02:22<00:00,  1.05it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/high_overlap_testing/anli_r3_test/misclassified_Russian.jsonl\n"]}]},{"cell_type":"markdown","source":["Training with Metaphors first then ANLI one epoch each"],"metadata":{"id":"B3HM2rztp1OM"}},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset metaphor_training.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_anli_en_ru_bert_2/metaphor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kziromrl5e_Z","executionInfo":{"status":"ok","timestamp":1733253583153,"user_tz":360,"elapsed":176898,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"6498abfa-42bc-4c79-e5e8-5adf0f7ae7ba"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 19:16:57.558346: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 19:16:57.574330: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 19:16:57.595591: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 19:16:57.601957: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 19:16:57.617180: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 19:16:58.853997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/My Drive/nlp_final_project/wandb/run-20241203_191726-xbnp4rkz\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/xbnp4rkz\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 2403 examples [00:00, 6460.56 examples/s]\n","Filter: 100% 2403/2403 [00:00<00:00, 52070.18 examples/s]\n","Filter: 100% 2403/2403 [00:00<00:00, 91810.93 examples/s]\n","tokenizer_config.json: 100% 49.0/49.0 [00:00<00:00, 175kB/s]\n","config.json: 100% 625/625 [00:00<00:00, 2.74MB/s]\n","vocab.txt: 100% 996k/996k [00:00<00:00, 17.4MB/s]\n","tokenizer.json: 100% 1.96M/1.96M [00:00<00:00, 21.3MB/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 1922/1922 [00:00<00:00, 2633.64 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 481/481 [00:00<00:00, 1084.20 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.7556, 'grad_norm': 42.231082916259766, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 121/605 [00:13<00:43, 11.04it/s]\n","  0% 0/61 [00:00<?, ?it/s]\u001b[A\n"," 11% 7/61 [00:00<00:00, 67.96it/s]\u001b[A\n"," 23% 14/61 [00:00<00:00, 61.99it/s]\u001b[A\n"," 34% 21/61 [00:00<00:00, 60.12it/s]\u001b[A\n"," 46% 28/61 [00:00<00:00, 59.26it/s]\u001b[A\n"," 56% 34/61 [00:00<00:00, 58.94it/s]\u001b[A\n"," 66% 40/61 [00:00<00:00, 58.60it/s]\u001b[A\n"," 75% 46/61 [00:00<00:00, 58.34it/s]\u001b[A\n"," 85% 52/61 [00:00<00:00, 58.20it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.7784393429756165, 'eval_accuracy': 0.6029106029106029, 'eval_precision': 0.6091781743157575, 'eval_recall': 0.6029106029106029, 'eval_f1': 0.576286778667731, 'eval_runtime': 1.1015, 'eval_samples_per_second': 436.658, 'eval_steps_per_second': 55.377, 'epoch': 1.0}\n"," 20% 121/605 [00:14<00:43, 11.04it/s]\n","100% 61/61 [00:01<00:00, 58.11it/s]\u001b[A\n","{'loss': 0.4533, 'grad_norm': 144.9141845703125, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 242/605 [00:31<00:34, 10.62it/s]\n","  0% 0/61 [00:00<?, ?it/s]\u001b[A\n"," 11% 7/61 [00:00<00:00, 69.38it/s]\u001b[A\n"," 23% 14/61 [00:00<00:00, 62.76it/s]\u001b[A\n"," 34% 21/61 [00:00<00:00, 61.35it/s]\u001b[A\n"," 46% 28/61 [00:00<00:00, 60.56it/s]\u001b[A\n"," 57% 35/61 [00:00<00:00, 60.07it/s]\u001b[A\n"," 69% 42/61 [00:00<00:00, 59.80it/s]\u001b[A\n"," 79% 48/61 [00:00<00:00, 59.57it/s]\u001b[A\n"," 89% 54/61 [00:00<00:00, 59.55it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.8847851753234863, 'eval_accuracy': 0.6507276507276507, 'eval_precision': 0.6453503718143504, 'eval_recall': 0.6507276507276507, 'eval_f1': 0.6431695331695332, 'eval_runtime': 1.027, 'eval_samples_per_second': 468.369, 'eval_steps_per_second': 59.398, 'epoch': 2.0}\n"," 40% 242/605 [00:32<00:34, 10.62it/s]\n","100% 61/61 [00:01<00:00, 61.14it/s]\u001b[A\n","{'loss': 0.276, 'grad_norm': 21.05204963684082, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 363/605 [00:50<00:22, 10.59it/s]\n","  0% 0/61 [00:00<?, ?it/s]\u001b[A\n"," 11% 7/61 [00:00<00:00, 69.68it/s]\u001b[A\n"," 23% 14/61 [00:00<00:00, 63.29it/s]\u001b[A\n"," 34% 21/61 [00:00<00:00, 61.43it/s]\u001b[A\n"," 46% 28/61 [00:00<00:00, 60.51it/s]\u001b[A\n"," 57% 35/61 [00:00<00:00, 60.00it/s]\u001b[A\n"," 69% 42/61 [00:00<00:00, 59.70it/s]\u001b[A\n"," 79% 48/61 [00:00<00:00, 59.50it/s]\u001b[A\n"," 89% 54/61 [00:00<00:00, 59.28it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.96413254737854, 'eval_accuracy': 0.6860706860706861, 'eval_precision': 0.6930748377556889, 'eval_recall': 0.6860706860706861, 'eval_f1': 0.6832773067813228, 'eval_runtime': 1.03, 'eval_samples_per_second': 466.977, 'eval_steps_per_second': 59.222, 'epoch': 3.0}\n"," 60% 363/605 [00:51<00:22, 10.59it/s]\n","100% 61/61 [00:01<00:00, 60.79it/s]\u001b[A\n","{'loss': 0.1643, 'grad_norm': 1.1289974451065063, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 484/605 [01:09<00:10, 11.58it/s]\n","  0% 0/61 [00:00<?, ?it/s]\u001b[A\n"," 11% 7/61 [00:00<00:00, 68.36it/s]\u001b[A\n"," 23% 14/61 [00:00<00:00, 62.77it/s]\u001b[A\n"," 34% 21/61 [00:00<00:00, 60.97it/s]\u001b[A\n"," 46% 28/61 [00:00<00:00, 60.22it/s]\u001b[A\n"," 57% 35/61 [00:00<00:00, 59.64it/s]\u001b[A\n"," 67% 41/61 [00:00<00:00, 59.54it/s]\u001b[A\n"," 77% 47/61 [00:00<00:00, 59.27it/s]\u001b[A\n"," 87% 53/61 [00:00<00:00, 59.21it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.3608982563018799, 'eval_accuracy': 0.6694386694386695, 'eval_precision': 0.6775165494831825, 'eval_recall': 0.6694386694386695, 'eval_f1': 0.6724235427305811, 'eval_runtime': 1.0359, 'eval_samples_per_second': 464.319, 'eval_steps_per_second': 58.885, 'epoch': 4.0}\n"," 80% 484/605 [01:10<00:10, 11.58it/s]\n","100% 61/61 [00:01<00:00, 58.90it/s]\u001b[A\n","{'loss': 0.0561, 'grad_norm': 0.07638733088970184, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 605/605 [01:34<00:00, 10.29it/s]\n","  0% 0/61 [00:00<?, ?it/s]\u001b[A\n"," 10% 6/61 [00:00<00:00, 57.44it/s]\u001b[A\n"," 20% 12/61 [00:00<00:00, 51.41it/s]\u001b[A\n"," 30% 18/61 [00:00<00:00, 53.32it/s]\u001b[A\n"," 39% 24/61 [00:00<00:00, 55.60it/s]\u001b[A\n"," 49% 30/61 [00:00<00:00, 56.45it/s]\u001b[A\n"," 59% 36/61 [00:00<00:00, 57.20it/s]\u001b[A\n"," 69% 42/61 [00:00<00:00, 57.70it/s]\u001b[A\n"," 79% 48/61 [00:00<00:00, 58.02it/s]\u001b[A\n"," 89% 54/61 [00:00<00:00, 57.92it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.5388327836990356, 'eval_accuracy': 0.6777546777546778, 'eval_precision': 0.6828987124817257, 'eval_recall': 0.6777546777546778, 'eval_f1': 0.679599880115404, 'eval_runtime': 1.093, 'eval_samples_per_second': 440.061, 'eval_steps_per_second': 55.808, 'epoch': 5.0}\n","100% 605/605 [01:37<00:00, 10.29it/s]\n","100% 61/61 [00:03<00:00, 58.17it/s]\u001b[A\n","{'train_runtime': 106.0077, 'train_samples_per_second': 90.654, 'train_steps_per_second': 5.707, 'train_loss': 0.3410729889042121, 'epoch': 5.0}\n","100% 605/605 [01:45<00:00,  5.71it/s]\n","100% 61/61 [00:01<00:00, 56.90it/s]\n","Evaluation results:\n","{'eval_loss': 1.5388327836990356, 'eval_accuracy': 0.6777546777546778, 'eval_precision': 0.6828987124817257, 'eval_recall': 0.6777546777546778, 'eval_f1': 0.679599880115404, 'eval_runtime': 1.0915, 'eval_samples_per_second': 440.67, 'eval_steps_per_second': 55.885, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/xbnp4rkz\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_191726-xbnp4rkz/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/metaphor/checkpoint-363 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/xnli_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rMPtbgk9w1-","executionInfo":{"status":"ok","timestamp":1733253802520,"user_tz":360,"elapsed":117522,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"04c7d596-773b-450f-a97e-8e344298b721"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 19:21:29.377633: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 19:21:29.394490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 19:21:29.415427: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 19:21:29.421776: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 19:21:29.436725: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 19:21:30.502997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_192133-ni9g7xfa\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/ni9g7xfa\u001b[0m\n","README.md: 100% 20.8k/20.8k [00:00<00:00, 64.2MB/s]\n","train-00000-of-00001.parquet: 100% 50.2M/50.2M [00:00<00:00, 181MB/s]\n","test-00000-of-00001.parquet: 100% 308k/308k [00:00<00:00, 276MB/s]\n","validation-00000-of-00001.parquet: 100% 157k/157k [00:00<00:00, 247MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 957517.23 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 718261.66 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 700410.23 examples/s]\n","train-00000-of-00001.parquet: 100% 70.0M/70.0M [00:00<00:00, 232MB/s]\n","test-00000-of-00001.parquet: 100% 477k/477k [00:00<00:00, 338MB/s]\n","validation-00000-of-00001.parquet: 100% 239k/239k [00:00<00:00, 296MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 784663.92 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 666015.75 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 583388.28 examples/s]\n","Map: 100% 392702/392702 [00:14<00:00, 27522.04 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 28714.84 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 30218.42 examples/s]\n","Map: 100% 392702/392702 [00:14<00:00, 27130.51 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 30083.27 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 29505.81 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 6479.12 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 6330.61 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 6385.45 examples/s]\n","\n","Evaluation on English test set:\n","100% 624/627 [00:10<00:00, 60.01it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [00:10<00:00, 59.69it/s]\n","{'eval_loss': 0.8849332332611084, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.7736526946107785, 'eval_precision': 0.7765828828853307, 'eval_recall': 0.7736526946107785, 'eval_f1': 0.7695944156228263, 'eval_runtime': 11.0986, 'eval_samples_per_second': 451.408, 'eval_steps_per_second': 56.494}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [00:10<00:00, 59.28it/s]\n","{'eval_loss': 1.0579718351364136, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.6944111776447106, 'eval_precision': 0.6936013796376185, 'eval_recall': 0.6944111776447106, 'eval_f1': 0.6921510663622705, 'eval_runtime': 10.5928, 'eval_samples_per_second': 472.964, 'eval_steps_per_second': 59.191}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [00:20<00:00, 60.29it/s]\n","{'eval_loss': 0.9714525938034058, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.7340319361277445, 'eval_precision': 0.7345421572803725, 'eval_recall': 0.7340319361277445, 'eval_f1': 0.7309575793418864, 'eval_runtime': 20.7993, 'eval_samples_per_second': 481.746, 'eval_steps_per_second': 60.242}\n","100% 627/627 [00:10<00:00, 59.73it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/xnli_test/misclassified_English.jsonl\n","100% 627/627 [00:10<00:00, 59.33it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/xnli_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/ni9g7xfa\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_192133-ni9g7xfa/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/metaphor/checkpoint-363 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R2_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/anli_r2_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4m1tsu3y-nBC","executionInfo":{"status":"ok","timestamp":1733253875938,"user_tz":360,"elapsed":31257,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"4fc17ddc-ff97-474e-ba1a-ddf26426abf4"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 19:24:08.907870: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 19:24:08.924280: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 19:24:08.945277: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 19:24:08.951597: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 19:24:08.966612: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 19:24:10.036963: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_192412-vib1w4lk\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/vib1w4lk\u001b[0m\n","Generating test split: 2000 examples [00:00, 11574.48 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2476.89 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 5759.73 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 5850.99 examples/s]\n","\n","Evaluation on English test set:\n"," 96% 120/125 [00:02<00:00, 58.70it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [00:02<00:00, 57.96it/s]\n","{'eval_loss': 3.330777406692505, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.31, 'eval_precision': 0.30392424497672144, 'eval_recall': 0.31, 'eval_f1': 0.30220011813515735, 'eval_runtime': 2.7557, 'eval_samples_per_second': 362.883, 'eval_steps_per_second': 45.36}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [00:02<00:00, 59.83it/s]\n","{'eval_loss': 3.042487382888794, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.311, 'eval_precision': 0.30649966888313657, 'eval_recall': 0.311, 'eval_f1': 0.306853785050501, 'eval_runtime': 2.1054, 'eval_samples_per_second': 474.966, 'eval_steps_per_second': 59.371}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [00:04<00:00, 59.14it/s]\n","{'eval_loss': 3.1866323947906494, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.3105, 'eval_precision': 0.30520440360886353, 'eval_recall': 0.3105, 'eval_f1': 0.3047334546145447, 'eval_runtime': 4.2442, 'eval_samples_per_second': 471.23, 'eval_steps_per_second': 58.904}\n","100% 125/125 [00:02<00:00, 60.26it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/anli_r2_test/misclassified_English.jsonl\n","100% 125/125 [00:02<00:00, 57.21it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/anli_r2_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/vib1w4lk\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_192412-vib1w4lk/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/metaphor/checkpoint-363 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R1_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/anli_r1_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRXErGJi-uSh","executionInfo":{"status":"ok","timestamp":1733253909454,"user_tz":360,"elapsed":33518,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"4558fed5-db16-41d6-b37e-695ec8067412"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 19:24:40.083934: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 19:24:40.100674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 19:24:40.121934: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 19:24:40.128371: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 19:24:40.144210: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 19:24:41.244172: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_192443-pb2tlacf\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/pb2tlacf\u001b[0m\n","Generating test split: 2000 examples [00:00, 4769.12 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2000/2000 [00:00<00:00, 2162.91 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2000/2000 [00:00<00:00, 5313.55 examples/s]\n","Filter: 100% 2000/2000 [00:00<00:00, 5763.35 examples/s]\n","\n","Evaluation on English test set:\n"," 96% 120/125 [00:02<00:00, 57.33it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 125/125 [00:02<00:00, 57.54it/s]\n","{'eval_loss': 3.5661230087280273, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.261, 'eval_precision': 0.26205910056493154, 'eval_recall': 0.261, 'eval_f1': 0.25435770784094097, 'eval_runtime': 2.7495, 'eval_samples_per_second': 363.706, 'eval_steps_per_second': 45.463}\n","\n","Evaluation on Russian test set:\n","100% 125/125 [00:02<00:00, 57.93it/s]\n","{'eval_loss': 3.211967945098877, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.274, 'eval_precision': 0.2757586906024678, 'eval_recall': 0.274, 'eval_f1': 0.2696253526924165, 'eval_runtime': 2.1749, 'eval_samples_per_second': 459.794, 'eval_steps_per_second': 57.474}\n","\n","Evaluation on the entire test set:\n","100% 250/250 [00:04<00:00, 59.04it/s]\n","{'eval_loss': 3.389045476913452, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.2675, 'eval_precision': 0.2689967757041468, 'eval_recall': 0.2675, 'eval_f1': 0.2620758349923825, 'eval_runtime': 4.2509, 'eval_samples_per_second': 470.487, 'eval_steps_per_second': 58.811}\n","100% 125/125 [00:02<00:00, 58.35it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/anli_r1_test/misclassified_English.jsonl\n","100% 125/125 [00:02<00:00, 58.73it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/anli_r1_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/pb2tlacf\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_192443-pb2tlacf/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/metaphor/checkpoint-363 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R3_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/anli_r3_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDe_lF9b-2fa","executionInfo":{"status":"ok","timestamp":1733253947260,"user_tz":360,"elapsed":35305,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"e818c997-bb1c-4b9a-dd52-51ea8cb10a20"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 19:25:16.207972: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 19:25:16.223905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 19:25:16.244360: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 19:25:16.250549: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 19:25:16.265054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 19:25:17.349757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_192519-r92a5o41\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/r92a5o41\u001b[0m\n","Generating test split: 2400 examples [00:00, 13292.01 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2400/2400 [00:00<00:00, 2603.27 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:335: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2400/2400 [00:00<00:00, 5903.45 examples/s]\n","Filter: 100% 2400/2400 [00:00<00:00, 6179.89 examples/s]\n","\n","Evaluation on English test set:\n"," 96% 144/150 [00:02<00:00, 59.01it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 150/150 [00:02<00:00, 57.56it/s]\n","{'eval_loss': 3.1673433780670166, 'eval_model_preparation_time': 0.0041, 'eval_accuracy': 0.31166666666666665, 'eval_precision': 0.30711015460512175, 'eval_recall': 0.31166666666666665, 'eval_f1': 0.3036932696974644, 'eval_runtime': 3.376, 'eval_samples_per_second': 355.449, 'eval_steps_per_second': 44.431}\n","\n","Evaluation on Russian test set:\n","100% 150/150 [00:02<00:00, 59.58it/s]\n","{'eval_loss': 2.912161350250244, 'eval_model_preparation_time': 0.0041, 'eval_accuracy': 0.315, 'eval_precision': 0.31260140943866827, 'eval_recall': 0.315, 'eval_f1': 0.3103235195810951, 'eval_runtime': 2.5333, 'eval_samples_per_second': 473.69, 'eval_steps_per_second': 59.211}\n","\n","Evaluation on the entire test set:\n","100% 300/300 [00:05<00:00, 58.49it/s]\n","{'eval_loss': 3.03975248336792, 'eval_model_preparation_time': 0.0041, 'eval_accuracy': 0.31333333333333335, 'eval_precision': 0.3099163498575925, 'eval_recall': 0.31333333333333335, 'eval_f1': 0.307109847964575, 'eval_runtime': 5.1441, 'eval_samples_per_second': 466.554, 'eval_steps_per_second': 58.319}\n","100% 150/150 [00:02<00:00, 59.30it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/anli_r3_test/misclassified_English.jsonl\n","100% 150/150 [00:02<00:00, 58.36it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_model_testing/anli_r3_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/r92a5o41\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_192519-r92a5o41/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/metaphor/checkpoint-363 \\\n","    --task nli \\\n","    --dataset adversarial_shuffle.jsonl \\\n","    --do_train \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 1 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_anli_en_ru_bert_2/metaphor_shuffle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EYjTgW3G-9UW","executionInfo":{"status":"ok","timestamp":1733259005200,"user_tz":360,"elapsed":30651,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"b3dd73ce-e252-4323-d574-09e4db8f5cb5"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 20:49:38.890741: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 20:49:38.907724: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 20:49:38.928790: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 20:49:38.935157: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 20:49:38.950487: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 20:49:40.013738: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_204942-pd47sm5y\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/pd47sm5y\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['original_premise', 'premise', 'hypothesis', 'label', 'language', 'split']\n","Validation dataset columns before mapping: ['original_premise', 'premise', 'hypothesis', 'label', 'language', 'split']\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.6966, 'grad_norm': 19.498531341552734, 'learning_rate': 0.0, 'epoch': 1.0}\n","100% 75/75 [00:14<00:00, 10.67it/s]Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/nlp_final_project/run.py\", line 451, in <module>\n","    main()\n","  File \"/content/drive/MyDrive/nlp_final_project/run.py\", line 345, in main\n","    trainer.train()\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2123, in train\n","    return inner_training_loop(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2573, in _inner_training_loop\n","    self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3004, in _maybe_log_save_evaluate\n","    metrics = self._evaluate(trial, ignore_keys_for_eval)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2958, in _evaluate\n","    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3975, in evaluate\n","    output = eval_loop(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 4169, in evaluation_loop\n","    losses, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 4338, in prediction_step\n","    has_labels = False if len(self.label_names) == 0 else all(inputs.get(k) is not None for k in self.label_names)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 4338, in <genexpr>\n","    has_labels = False if len(self.label_names) == 0 else all(inputs.get(k) is not None for k in self.label_names)\n","AttributeError: 'NoneType' object has no attribute 'get'\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/pd47sm5y\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_204942-pd47sm5y/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/metaphor_shuffle/checkpoint-75 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R3_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/metaphor_shuffle_testing/anli_r3_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YjFNtAGdKCal","executionInfo":{"status":"ok","timestamp":1733259109713,"user_tz":360,"elapsed":34243,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"5879ecf2-f8fd-4d26-b124-2198c253d923"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 20:51:19.862748: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 20:51:19.879102: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 20:51:19.900059: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 20:51:19.906388: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 20:51:19.921359: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 20:51:21.009694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_205123-rdhs9osw\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/rdhs9osw\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2400/2400 [00:00<00:00, 2529.81 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2400/2400 [00:00<00:00, 5648.60 examples/s]\n","Filter: 100% 2400/2400 [00:00<00:00, 6033.09 examples/s]\n","\n","Evaluation on English test set:\n","100% 150/150 [00:02<00:00, 58.23it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 150/150 [00:02<00:00, 57.51it/s]\n","{'eval_loss': 1.9696966409683228, 'eval_model_preparation_time': 0.0054, 'eval_accuracy': 0.29583333333333334, 'eval_precision': 0.29340955535801605, 'eval_recall': 0.29583333333333334, 'eval_f1': 0.29249564068037814, 'eval_runtime': 3.1984, 'eval_samples_per_second': 375.192, 'eval_steps_per_second': 46.899}\n","\n","Evaluation on Russian test set:\n","100% 150/150 [00:02<00:00, 58.02it/s]\n","{'eval_loss': 1.7678165435791016, 'eval_model_preparation_time': 0.0054, 'eval_accuracy': 0.30666666666666664, 'eval_precision': 0.3029608744560567, 'eval_recall': 0.30666666666666664, 'eval_f1': 0.3027267314435209, 'eval_runtime': 2.6025, 'eval_samples_per_second': 461.093, 'eval_steps_per_second': 57.637}\n","\n","Evaluation on the entire test set:\n","100% 300/300 [00:05<00:00, 59.31it/s]\n","{'eval_loss': 1.8687565326690674, 'eval_model_preparation_time': 0.0054, 'eval_accuracy': 0.30125, 'eval_precision': 0.2981695373875122, 'eval_recall': 0.30125, 'eval_f1': 0.2976028004200584, 'eval_runtime': 5.0762, 'eval_samples_per_second': 472.791, 'eval_steps_per_second': 59.099}\n","100% 150/150 [00:02<00:00, 58.18it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_shuffle_testing/anli_r3_test/misclassified_English.jsonl\n","100% 150/150 [00:02<00:00, 58.11it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_shuffle_testing/anli_r3_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/rdhs9osw\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_205123-rdhs9osw/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/metaphor_shuffle/checkpoint-75 \\\n","    --task nli \\\n","    --dataset adversarial_premise.jsonl \\\n","    --do_train \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 1 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_anli_en_ru_bert_2/metaphor_shuffle_premise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3Vb3VIpSh1d","executionInfo":{"status":"ok","timestamp":1733259264566,"user_tz":360,"elapsed":41651,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"d22797f7-ac3f-4a2e-eb8a-311fdfdf91a5"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 20:53:47.271931: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 20:53:47.297681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 20:53:47.320511: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 20:53:47.327111: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 20:53:47.343489: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 20:53:48.418674: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_205350-t51exl5g\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/t51exl5g\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 1200 examples [00:00, 8401.78 examples/s]\n","Filter: 100% 1200/1200 [00:00<00:00, 61242.64 examples/s]\n","Filter: 100% 1200/1200 [00:00<00:00, 84199.02 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['original_premise', 'premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 960/960 [00:00<00:00, 1833.77 examples/s]\n","Validation dataset columns before mapping: ['original_premise', 'premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 240/240 [00:00<00:00, 573.79 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.7531, 'grad_norm': 23.112459182739258, 'learning_rate': 0.0, 'epoch': 1.0}\n","100% 60/60 [00:12<00:00, 10.77it/s]\n","  0% 0/30 [00:00<?, ?it/s]\u001b[A\n"," 20% 6/30 [00:00<00:00, 59.14it/s]\u001b[A\n"," 40% 12/30 [00:00<00:00, 54.83it/s]\u001b[A\n"," 60% 18/30 [00:00<00:00, 56.50it/s]\u001b[A\n","                                   \n","\u001b[A{'eval_loss': 0.6565447449684143, 'eval_accuracy': 0.7125, 'eval_precision': 0.7179635517870812, 'eval_recall': 0.7125, 'eval_f1': 0.7144445294415028, 'eval_runtime': 0.5491, 'eval_samples_per_second': 437.1, 'eval_steps_per_second': 54.637, 'epoch': 1.0}\n","100% 60/60 [00:12<00:00, 10.77it/s]\n","100% 30/30 [00:00<00:00, 57.37it/s]\u001b[A\n","{'train_runtime': 23.0168, 'train_samples_per_second': 41.709, 'train_steps_per_second': 2.607, 'train_loss': 0.7531243006388346, 'epoch': 1.0}\n","100% 60/60 [00:22<00:00,  2.61it/s]\n","100% 30/30 [00:00<00:00, 55.92it/s]\n","Evaluation results:\n","{'eval_loss': 0.6565447449684143, 'eval_accuracy': 0.7125, 'eval_precision': 0.7179635517870812, 'eval_recall': 0.7125, 'eval_f1': 0.7144445294415028, 'eval_runtime': 0.5554, 'eval_samples_per_second': 432.156, 'eval_steps_per_second': 54.019, 'epoch': 1.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/t51exl5g\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_205350-t51exl5g/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_anli_en_ru_bert_2/metaphor_shuffle_premise/checkpoint-60 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_R3_en_ru.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/metaphor_shuffle_premise_testing/anli_r3_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dm8fa_utTN7u","executionInfo":{"status":"ok","timestamp":1733259454455,"user_tz":360,"elapsed":33804,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"3c0e2292-ee95-4fa8-e46e-60be2e23855e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 20:57:04.914365: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 20:57:04.931439: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 20:57:04.953016: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 20:57:04.959414: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 20:57:04.974780: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 20:57:06.051438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_205708-a28bwd9z\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/a28bwd9z\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 2400/2400 [00:00<00:00, 2550.90 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 2400/2400 [00:00<00:00, 5764.69 examples/s]\n","Filter: 100% 2400/2400 [00:00<00:00, 5896.91 examples/s]\n","\n","Evaluation on English test set:\n"," 97% 146/150 [00:02<00:00, 59.64it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 150/150 [00:02<00:00, 58.37it/s]\n","{'eval_loss': 1.6937183141708374, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.28833333333333333, 'eval_precision': 0.2858328995398404, 'eval_recall': 0.28833333333333333, 'eval_f1': 0.2854983695785868, 'eval_runtime': 3.2147, 'eval_samples_per_second': 373.284, 'eval_steps_per_second': 46.661}\n","\n","Evaluation on Russian test set:\n","100% 150/150 [00:02<00:00, 59.81it/s]\n","{'eval_loss': 1.5324925184249878, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.295, 'eval_precision': 0.2936036043801707, 'eval_recall': 0.295, 'eval_f1': 0.29334384861056245, 'eval_runtime': 2.5244, 'eval_samples_per_second': 475.363, 'eval_steps_per_second': 59.42}\n","\n","Evaluation on the entire test set:\n","100% 300/300 [00:05<00:00, 59.72it/s]\n","{'eval_loss': 1.6131054162979126, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.2916666666666667, 'eval_precision': 0.2896976754414307, 'eval_recall': 0.2916666666666667, 'eval_f1': 0.289438570153553, 'eval_runtime': 5.0393, 'eval_samples_per_second': 476.254, 'eval_steps_per_second': 59.532}\n","100% 150/150 [00:02<00:00, 59.82it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_shuffle_premise_testing/anli_r3_test/misclassified_English.jsonl\n","100% 150/150 [00:02<00:00, 59.97it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/metaphor_shuffle_premise_testing/anli_r3_test/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/a28bwd9z\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_205708-a28bwd9z/logs\u001b[0m\n"]}]},{"cell_type":"markdown","source":["Strategy Reset: Below is final train test strategy. Starting with testing XNLI on Metaphors and ANLI, then training on Metaphors, then training on ANLI error sets"],"metadata":{"id":"4UCWFZeMbiA4"}},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./metaphor_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_model_testing/metaphor_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58Fn50iAT-Mx","executionInfo":{"status":"ok","timestamp":1733261954612,"user_tz":360,"elapsed":19743,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"f58f26fe-b333-415b-b2dd-10f78769d835"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 21:38:59.065138: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 21:38:59.082326: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 21:38:59.103544: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 21:38:59.109981: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 21:38:59.125366: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 21:39:00.192605: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_213902-sn9vxmhk\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/sn9vxmhk\u001b[0m\n","Generating test split: 481 examples [00:00, 52165.80 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 481/481 [00:00<00:00, 944.34 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 481/481 [00:00<00:00, 4234.46 examples/s]\n","Filter: 100% 481/481 [00:00<00:00, 5578.52 examples/s]\n","\n","Evaluation on English test set:\n","100% 30/30 [00:00<00:00, 58.14it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 30/30 [00:00<00:00, 54.68it/s]\n","{'eval_loss': 1.0208821296691895, 'eval_model_preparation_time': 0.0049, 'eval_accuracy': 0.6125, 'eval_precision': 0.6133274812734083, 'eval_recall': 0.6125, 'eval_f1': 0.6128633380215658, 'eval_runtime': 1.1901, 'eval_samples_per_second': 201.672, 'eval_steps_per_second': 25.209}\n","\n","Evaluation on Russian test set:\n","100% 31/31 [00:00<00:00, 61.44it/s]\n","{'eval_loss': 1.4121848344802856, 'eval_model_preparation_time': 0.0049, 'eval_accuracy': 0.48132780082987553, 'eval_precision': 0.5317014456301005, 'eval_recall': 0.48132780082987553, 'eval_f1': 0.49723319006974365, 'eval_runtime': 0.5198, 'eval_samples_per_second': 463.6, 'eval_steps_per_second': 59.633}\n","\n","Evaluation on the entire test set:\n","100% 61/61 [00:01<00:00, 60.70it/s]\n","{'eval_loss': 1.2169402837753296, 'eval_model_preparation_time': 0.0049, 'eval_accuracy': 0.5467775467775468, 'eval_precision': 0.5687787114622194, 'eval_recall': 0.5467775467775468, 'eval_f1': 0.5553109359412504, 'eval_runtime': 1.0196, 'eval_samples_per_second': 471.76, 'eval_steps_per_second': 59.828}\n","100% 30/30 [00:00<00:00, 60.87it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_model_testing/metaphor_final/misclassified_English.jsonl\n","100% 31/31 [00:00<00:00, 61.58it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_model_testing/metaphor_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/sn9vxmhk\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_213902-sn9vxmhk/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_model_testing/anli_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5K-1nA1EX4RW","executionInfo":{"status":"ok","timestamp":1733262036189,"user_tz":360,"elapsed":62493,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"7f75d9ff-6341-4a06-aa7f-a96174288a9f"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 21:39:38.041600: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 21:39:38.058194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 21:39:38.078768: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 21:39:38.085005: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 21:39:38.099620: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 21:39:39.156421: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_213941-d2m9yr4t\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/d2m9yr4t\u001b[0m\n","Generating test split: 6400 examples [00:00, 25151.81 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6400/6400 [00:01<00:00, 3888.70 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6400/6400 [00:01<00:00, 5867.30 examples/s]\n","Filter: 100% 6400/6400 [00:01<00:00, 6003.76 examples/s]\n","\n","Evaluation on English test set:\n"," 99% 396/400 [00:06<00:00, 58.03it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 400/400 [00:06<00:00, 58.14it/s]\n","{'eval_loss': 2.365288734436035, 'eval_model_preparation_time': 0.0042, 'eval_accuracy': 0.2946875, 'eval_precision': 0.2931778641159817, 'eval_recall': 0.2946875, 'eval_f1': 0.29301509863630193, 'eval_runtime': 7.5001, 'eval_samples_per_second': 426.659, 'eval_steps_per_second': 53.332}\n","\n","Evaluation on Russian test set:\n","100% 400/400 [00:06<00:00, 58.46it/s]\n","{'eval_loss': 2.1531004905700684, 'eval_model_preparation_time': 0.0042, 'eval_accuracy': 0.3046875, 'eval_precision': 0.30326578139373467, 'eval_recall': 0.3046875, 'eval_f1': 0.3033302323317153, 'eval_runtime': 6.8594, 'eval_samples_per_second': 466.511, 'eval_steps_per_second': 58.314}\n","\n","Evaluation on the entire test set:\n","100% 800/800 [00:13<00:00, 59.57it/s]\n","{'eval_loss': 2.2591943740844727, 'eval_model_preparation_time': 0.0042, 'eval_accuracy': 0.2996875, 'eval_precision': 0.2982109523879902, 'eval_recall': 0.2996875, 'eval_f1': 0.29817291794121314, 'eval_runtime': 13.4461, 'eval_samples_per_second': 475.973, 'eval_steps_per_second': 59.497}\n","100% 400/400 [00:06<00:00, 59.07it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_model_testing/anli_final/misclassified_English.jsonl\n","100% 400/400 [00:06<00:00, 58.83it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_model_testing/anli_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/d2m9yr4t\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_213941-d2m9yr4t/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./final_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_model_testing/comb_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXnXiu9kdtgY","executionInfo":{"status":"ok","timestamp":1733262101454,"user_tz":360,"elapsed":65097,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"70ec9737-a8ec-43e3-a393-d1378718d02e"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 21:40:40.504773: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 21:40:40.521331: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 21:40:40.542221: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 21:40:40.548582: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 21:40:40.563680: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 21:40:41.635422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_214044-rpo48or6\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/rpo48or6\u001b[0m\n","Generating test split: 6881 examples [00:00, 32999.77 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6881/6881 [00:01<00:00, 4012.01 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6881/6881 [00:01<00:00, 6204.62 examples/s]\n","Filter: 100% 6881/6881 [00:01<00:00, 6309.14 examples/s]\n","\n","Evaluation on English test set:\n","100% 428/430 [00:07<00:00, 59.92it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 430/430 [00:07<00:00, 59.46it/s]\n","{'eval_loss': 2.2714929580688477, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.3168604651162791, 'eval_precision': 0.31678055669490673, 'eval_recall': 0.3168604651162791, 'eval_f1': 0.31594075629690777, 'eval_runtime': 7.853, 'eval_samples_per_second': 438.048, 'eval_steps_per_second': 54.756}\n","\n","Evaluation on Russian test set:\n","100% 431/431 [00:07<00:00, 59.39it/s]\n","{'eval_loss': 2.101208209991455, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.31705899447834934, 'eval_precision': 0.31674738797484087, 'eval_recall': 0.31705899447834934, 'eval_f1': 0.3160579909402928, 'eval_runtime': 7.2747, 'eval_samples_per_second': 473.006, 'eval_steps_per_second': 59.246}\n","\n","Evaluation on the entire test set:\n","100% 861/861 [00:14<00:00, 60.26it/s]\n","{'eval_loss': 2.186338186264038, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.31695974422322337, 'eval_precision': 0.31676398436570447, 'eval_recall': 0.31695974422322337, 'eval_f1': 0.3159995988978596, 'eval_runtime': 14.3048, 'eval_samples_per_second': 481.027, 'eval_steps_per_second': 60.19}\n","100% 430/430 [00:07<00:00, 59.13it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_model_testing/comb_final/misclassified_English.jsonl\n","100% 431/431 [00:07<00:00, 58.48it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_model_testing/comb_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/rpo48or6\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_214044-rpo48or6/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset metaphor_training_final.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_metaphor_anli_final/metaphor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7PpH8N6d2PG","executionInfo":{"status":"ok","timestamp":1733262460791,"user_tz":360,"elapsed":116295,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"008bd666-42b5-4480-aeca-55c5e915a876"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 21:45:48.831440: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 21:45:48.848792: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 21:45:48.870353: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 21:45:48.876873: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 21:45:48.892553: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 21:45:49.973573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_214552-xkv8r865\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/xkv8r865\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 2403 examples [00:00, 12061.73 examples/s]\n","Filter: 100% 2403/2403 [00:00<00:00, 90375.19 examples/s]\n","Filter: 100% 2403/2403 [00:00<00:00, 117631.62 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 1441/1441 [00:00<00:00, 2124.94 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 481/481 [00:00<00:00, 972.38 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.7848, 'grad_norm': 18.932842254638672, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 91/455 [00:09<00:33, 10.72it/s]\n","  0% 0/61 [00:00<?, ?it/s]\u001b[A\n"," 11% 7/61 [00:00<00:00, 69.55it/s]\u001b[A\n"," 23% 14/61 [00:00<00:00, 63.25it/s]\u001b[A\n"," 34% 21/61 [00:00<00:00, 61.68it/s]\u001b[A\n"," 46% 28/61 [00:00<00:00, 61.03it/s]\u001b[A\n"," 57% 35/61 [00:00<00:00, 60.54it/s]\u001b[A\n"," 69% 42/61 [00:00<00:00, 60.35it/s]\u001b[A\n"," 80% 49/61 [00:00<00:00, 60.28it/s]\u001b[A\n","                                    \n","\u001b[A{'eval_loss': 0.7397031188011169, 'eval_accuracy': 0.5841995841995842, 'eval_precision': 0.5960188260230579, 'eval_recall': 0.5841995841995842, 'eval_f1': 0.5746864784885118, 'eval_runtime': 1.0195, 'eval_samples_per_second': 471.821, 'eval_steps_per_second': 59.836, 'epoch': 1.0}\n"," 20% 91/455 [00:10<00:33, 10.72it/s]\n","100% 61/61 [00:00<00:00, 60.04it/s]\u001b[A\n","{'loss': 0.4823, 'grad_norm': 49.82148742675781, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 182/455 [00:24<00:26, 10.49it/s]\n","  0% 0/61 [00:00<?, ?it/s]\u001b[A\n"," 11% 7/61 [00:00<00:00, 69.17it/s]\u001b[A\n"," 23% 14/61 [00:00<00:00, 62.73it/s]\u001b[A\n"," 34% 21/61 [00:00<00:00, 60.77it/s]\u001b[A\n"," 46% 28/61 [00:00<00:00, 60.29it/s]\u001b[A\n"," 57% 35/61 [00:00<00:00, 59.65it/s]\u001b[A\n"," 67% 41/61 [00:00<00:00, 59.30it/s]\u001b[A\n"," 77% 47/61 [00:00<00:00, 58.80it/s]\u001b[A\n"," 87% 53/61 [00:00<00:00, 58.73it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.0028713941574097, 'eval_accuracy': 0.6091476091476091, 'eval_precision': 0.6129450909127168, 'eval_recall': 0.6091476091476091, 'eval_f1': 0.6074523255743068, 'eval_runtime': 1.0433, 'eval_samples_per_second': 461.032, 'eval_steps_per_second': 58.468, 'epoch': 2.0}\n"," 40% 182/455 [00:25<00:26, 10.49it/s]\n","100% 61/61 [00:01<00:00, 58.44it/s]\u001b[A\n","{'loss': 0.292, 'grad_norm': 39.20154571533203, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 273/455 [00:44<00:17, 10.56it/s]\n","  0% 0/61 [00:00<?, ?it/s]\u001b[A\n"," 11% 7/61 [00:00<00:00, 65.46it/s]\u001b[A\n"," 23% 14/61 [00:00<00:00, 59.71it/s]\u001b[A\n"," 34% 21/61 [00:00<00:00, 58.79it/s]\u001b[A\n"," 44% 27/61 [00:00<00:00, 57.83it/s]\u001b[A\n"," 54% 33/61 [00:00<00:00, 57.23it/s]\u001b[A\n"," 64% 39/61 [00:00<00:00, 57.06it/s]\u001b[A\n"," 74% 45/61 [00:00<00:00, 56.58it/s]\u001b[A\n"," 84% 51/61 [00:00<00:00, 56.26it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.9742451310157776, 'eval_accuracy': 0.6403326403326404, 'eval_precision': 0.644101407518746, 'eval_recall': 0.6403326403326404, 'eval_f1': 0.6405090772107265, 'eval_runtime': 1.0845, 'eval_samples_per_second': 443.509, 'eval_steps_per_second': 56.245, 'epoch': 3.0}\n"," 60% 273/455 [00:45<00:17, 10.56it/s]\n","100% 61/61 [00:01<00:00, 56.69it/s]\u001b[A\n","{'loss': 0.1443, 'grad_norm': 6.493838787078857, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 364/455 [01:00<00:08, 10.59it/s]\n","  0% 0/61 [00:00<?, ?it/s]\u001b[A\n"," 11% 7/61 [00:00<00:00, 66.12it/s]\u001b[A\n"," 23% 14/61 [00:00<00:00, 59.97it/s]\u001b[A\n"," 34% 21/61 [00:00<00:00, 58.96it/s]\u001b[A\n"," 44% 27/61 [00:00<00:00, 58.31it/s]\u001b[A\n"," 54% 33/61 [00:00<00:00, 58.00it/s]\u001b[A\n"," 64% 39/61 [00:00<00:00, 58.12it/s]\u001b[A\n"," 74% 45/61 [00:00<00:00, 58.23it/s]\u001b[A\n"," 84% 51/61 [00:00<00:00, 58.25it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.4699236154556274, 'eval_accuracy': 0.632016632016632, 'eval_precision': 0.6416163243149657, 'eval_recall': 0.632016632016632, 'eval_f1': 0.6323887307893489, 'eval_runtime': 1.0671, 'eval_samples_per_second': 450.773, 'eval_steps_per_second': 57.167, 'epoch': 4.0}\n"," 80% 364/455 [01:01<00:08, 10.59it/s]\n","100% 61/61 [00:01<00:00, 57.51it/s]\u001b[A\n","{'loss': 0.058, 'grad_norm': 0.10959172993898392, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 455/455 [01:22<00:00, 10.21it/s]\n","  0% 0/61 [00:00<?, ?it/s]\u001b[A\n"," 10% 6/61 [00:00<00:00, 58.60it/s]\u001b[A\n"," 20% 12/61 [00:00<00:00, 51.63it/s]\u001b[A\n"," 30% 18/61 [00:00<00:00, 53.20it/s]\u001b[A\n"," 39% 24/61 [00:00<00:00, 55.28it/s]\u001b[A\n"," 49% 30/61 [00:00<00:00, 56.33it/s]\u001b[A\n"," 59% 36/61 [00:00<00:00, 57.14it/s]\u001b[A\n"," 69% 42/61 [00:00<00:00, 58.04it/s]\u001b[A\n"," 79% 48/61 [00:00<00:00, 57.91it/s]\u001b[A\n"," 89% 54/61 [00:00<00:00, 57.70it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.6889023780822754, 'eval_accuracy': 0.6195426195426196, 'eval_precision': 0.6308888463528796, 'eval_recall': 0.6195426195426196, 'eval_f1': 0.621426329916896, 'eval_runtime': 1.095, 'eval_samples_per_second': 439.272, 'eval_steps_per_second': 55.708, 'epoch': 5.0}\n","100% 455/455 [01:26<00:00, 10.21it/s]\n","100% 61/61 [00:03<00:00, 58.19it/s]\u001b[A\n","{'train_runtime': 96.8005, 'train_samples_per_second': 74.431, 'train_steps_per_second': 4.7, 'train_loss': 0.35228800826020296, 'epoch': 5.0}\n","100% 455/455 [01:36<00:00,  4.70it/s]\n","100% 61/61 [00:01<00:00, 55.76it/s]\n","Evaluation results:\n","{'eval_loss': 1.6889023780822754, 'eval_accuracy': 0.6195426195426196, 'eval_precision': 0.6308888463528796, 'eval_recall': 0.6195426195426196, 'eval_f1': 0.621426329916896, 'eval_runtime': 1.1133, 'eval_samples_per_second': 432.068, 'eval_steps_per_second': 54.794, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/xkv8r865\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_214552-xkv8r865/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor/checkpoint-273 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./metaphor_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/metaphor_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWFf8I0jfICP","executionInfo":{"status":"ok","timestamp":1733262570423,"user_tz":360,"elapsed":21002,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"537e3313-8413-40e1-be16-7a975d21a4f4"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 21:49:13.741737: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 21:49:13.758879: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 21:49:13.780162: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 21:49:13.786658: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 21:49:13.801970: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 21:49:14.885497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_214917-z7xsqliu\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/z7xsqliu\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 481/481 [00:00<00:00, 1026.00 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 481/481 [00:00<00:00, 5402.11 examples/s]\n","Filter: 100% 481/481 [00:00<00:00, 5815.62 examples/s]\n","\n","Evaluation on English test set:\n"," 83% 25/30 [00:00<00:00, 58.65it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 30/30 [00:00<00:00, 54.38it/s]\n","{'eval_loss': 0.8147266507148743, 'eval_model_preparation_time': 0.0042, 'eval_accuracy': 0.7333333333333333, 'eval_precision': 0.7404658385093168, 'eval_recall': 0.7333333333333333, 'eval_f1': 0.7338758918733888, 'eval_runtime': 1.1448, 'eval_samples_per_second': 209.651, 'eval_steps_per_second': 26.206}\n","\n","Evaluation on Russian test set:\n","100% 31/31 [00:00<00:00, 61.82it/s]\n","{'eval_loss': 0.9509599208831787, 'eval_model_preparation_time': 0.0042, 'eval_accuracy': 0.6016597510373444, 'eval_precision': 0.6056033838245171, 'eval_recall': 0.6016597510373444, 'eval_f1': 0.6033748059949748, 'eval_runtime': 0.5177, 'eval_samples_per_second': 465.537, 'eval_steps_per_second': 59.882}\n","\n","Evaluation on the entire test set:\n","100% 61/61 [00:00<00:00, 61.42it/s]\n","{'eval_loss': 0.8829848766326904, 'eval_model_preparation_time': 0.0042, 'eval_accuracy': 0.6673596673596673, 'eval_precision': 0.6685476592327518, 'eval_recall': 0.6673596673596673, 'eval_f1': 0.6676477105711037, 'eval_runtime': 1.009, 'eval_samples_per_second': 476.708, 'eval_steps_per_second': 60.456}\n","100% 30/30 [00:00<00:00, 61.33it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/metaphor_final/misclassified_English.jsonl\n","100% 31/31 [00:00<00:00, 62.35it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/metaphor_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/z7xsqliu\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_214917-z7xsqliu/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor/checkpoint-273 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/anli_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IiE_X2yyf6El","executionInfo":{"status":"ok","timestamp":1733262671762,"user_tz":360,"elapsed":61423,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"981eac18-9488-4d1a-83da-84d0716bcca3"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 21:50:14.597350: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 21:50:14.614341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 21:50:14.635435: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 21:50:14.641890: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 21:50:14.657345: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 21:50:15.726176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_215018-zlt53496\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/zlt53496\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6400/6400 [00:01<00:00, 3908.96 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6400/6400 [00:01<00:00, 5662.34 examples/s]\n","Filter: 100% 6400/6400 [00:01<00:00, 5674.75 examples/s]\n","\n","Evaluation on English test set:\n"," 99% 396/400 [00:06<00:00, 57.90it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 400/400 [00:06<00:00, 58.06it/s]\n","{'eval_loss': 3.111285924911499, 'eval_model_preparation_time': 0.0053, 'eval_accuracy': 0.2853125, 'eval_precision': 0.284419727395296, 'eval_recall': 0.2853125, 'eval_f1': 0.28440174201714913, 'eval_runtime': 7.5043, 'eval_samples_per_second': 426.423, 'eval_steps_per_second': 53.303}\n","\n","Evaluation on Russian test set:\n","100% 400/400 [00:06<00:00, 59.29it/s]\n","{'eval_loss': 2.871037006378174, 'eval_model_preparation_time': 0.0053, 'eval_accuracy': 0.2978125, 'eval_precision': 0.2973804144199781, 'eval_recall': 0.2978125, 'eval_f1': 0.2972836157454865, 'eval_runtime': 6.7639, 'eval_samples_per_second': 473.099, 'eval_steps_per_second': 59.137}\n","\n","Evaluation on the entire test set:\n","100% 800/800 [00:13<00:00, 59.58it/s]\n","{'eval_loss': 2.991161584854126, 'eval_model_preparation_time': 0.0053, 'eval_accuracy': 0.2915625, 'eval_precision': 0.29097386670142744, 'eval_recall': 0.2915625, 'eval_f1': 0.29089387380265114, 'eval_runtime': 13.4416, 'eval_samples_per_second': 476.135, 'eval_steps_per_second': 59.517}\n","100% 400/400 [00:06<00:00, 59.48it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/anli_final/misclassified_English.jsonl\n","100% 400/400 [00:06<00:00, 59.72it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/anli_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/zlt53496\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_215018-zlt53496/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor/checkpoint-273 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./final_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/comb_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ncx44HxCgI8Y","executionInfo":{"status":"ok","timestamp":1733262762333,"user_tz":360,"elapsed":64711,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"a766d6a0-88bd-4c78-aa6c-7d88e84624e8"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 21:51:41.898660: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 21:51:41.915858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 21:51:41.936521: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 21:51:41.942864: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 21:51:41.958536: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 21:51:43.029027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_215145-ufypcbyo\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/ufypcbyo\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6881/6881 [00:01<00:00, 4079.43 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6881/6881 [00:01<00:00, 5822.96 examples/s]\n","Filter: 100% 6881/6881 [00:01<00:00, 5890.91 examples/s]\n","\n","Evaluation on English test set:\n"," 99% 427/430 [00:07<00:00, 59.60it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 430/430 [00:07<00:00, 58.07it/s]\n","{'eval_loss': 2.951061248779297, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.31656976744186044, 'eval_precision': 0.31623031160045456, 'eval_recall': 0.31656976744186044, 'eval_f1': 0.31600163951072674, 'eval_runtime': 8.0774, 'eval_samples_per_second': 425.881, 'eval_steps_per_second': 53.235}\n","\n","Evaluation on Russian test set:\n","100% 431/431 [00:07<00:00, 59.84it/s]\n","{'eval_loss': 2.7365591526031494, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.3190932868352223, 'eval_precision': 0.31967822091378423, 'eval_recall': 0.3190932868352223, 'eval_f1': 0.31907201718885453, 'eval_runtime': 7.2191, 'eval_samples_per_second': 476.654, 'eval_steps_per_second': 59.703}\n","\n","Evaluation on the entire test set:\n","100% 861/861 [00:14<00:00, 60.12it/s]\n","{'eval_loss': 2.843794584274292, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.3178317105071937, 'eval_precision': 0.31800734953171483, 'eval_recall': 0.3178317105071937, 'eval_f1': 0.31756769120346884, 'eval_runtime': 14.3362, 'eval_samples_per_second': 479.973, 'eval_steps_per_second': 60.058}\n","100% 430/430 [00:07<00:00, 59.01it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/comb_final/misclassified_English.jsonl\n","100% 431/431 [00:07<00:00, 59.79it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/comb_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/ufypcbyo\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_215145-ufypcbyo/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor/checkpoint-273 \\\n","    --task nli \\\n","    --dataset negation_examples_comb.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_metaphor_anli_final/metaphor_negation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7-lvc56geQE","executionInfo":{"status":"ok","timestamp":1733263978187,"user_tz":360,"elapsed":1084255,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"f0703b5d-38fb-4479-d41e-5087e5a834f3"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 21:54:58.204097: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 21:54:58.221300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 21:54:58.242416: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 21:54:58.248874: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 21:54:58.264740: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 21:54:59.331770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_215501-rltftfwv\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/rltftfwv\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 34540 examples [00:00, 79844.79 examples/s]\n","Filter: 100% 34540/34540 [00:00<00:00, 123282.73 examples/s]\n","Filter: 100% 34540/34540 [00:00<00:00, 136395.38 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 33888/33888 [00:08<00:00, 4009.63 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 652/652 [00:00<00:00, 1241.65 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.6956, 'grad_norm': 6.3458967208862305, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 2118/10590 [03:20<13:15, 10.65it/s]\n","  0% 0/82 [00:00<?, ?it/s]\u001b[A\n","  9% 7/82 [00:00<00:01, 69.96it/s]\u001b[A\n"," 17% 14/82 [00:00<00:01, 63.78it/s]\u001b[A\n"," 26% 21/82 [00:00<00:00, 62.11it/s]\u001b[A\n"," 34% 28/82 [00:00<00:00, 61.34it/s]\u001b[A\n"," 43% 35/82 [00:00<00:00, 60.89it/s]\u001b[A\n"," 51% 42/82 [00:00<00:00, 60.62it/s]\u001b[A\n"," 60% 49/82 [00:00<00:00, 60.41it/s]\u001b[A\n"," 68% 56/82 [00:00<00:00, 60.28it/s]\u001b[A\n"," 77% 63/82 [00:01<00:00, 60.23it/s]\u001b[A\n"," 85% 70/82 [00:01<00:00, 60.16it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 1.172609806060791, 'eval_accuracy': 0.4938650306748466, 'eval_precision': 0.49442203601249785, 'eval_recall': 0.4938650306748466, 'eval_f1': 0.4929623877687865, 'eval_runtime': 1.3648, 'eval_samples_per_second': 477.735, 'eval_steps_per_second': 60.083, 'epoch': 1.0}\n"," 20% 2118/10590 [03:21<13:15, 10.65it/s]\n","100% 82/82 [00:01<00:00, 60.18it/s]\u001b[A\n","{'loss': 0.4391, 'grad_norm': 11.471982955932617, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 4236/10590 [06:47<09:58, 10.62it/s]\n","  0% 0/82 [00:00<?, ?it/s]\u001b[A\n","  9% 7/82 [00:00<00:01, 67.74it/s]\u001b[A\n"," 17% 14/82 [00:00<00:01, 61.35it/s]\u001b[A\n"," 26% 21/82 [00:00<00:01, 59.80it/s]\u001b[A\n"," 34% 28/82 [00:00<00:00, 59.40it/s]\u001b[A\n"," 41% 34/82 [00:00<00:00, 59.07it/s]\u001b[A\n"," 49% 40/82 [00:00<00:00, 59.22it/s]\u001b[A\n"," 56% 46/82 [00:00<00:00, 58.37it/s]\u001b[A\n"," 63% 52/82 [00:00<00:00, 57.99it/s]\u001b[A\n"," 71% 58/82 [00:00<00:00, 57.97it/s]\u001b[A\n"," 78% 64/82 [00:01<00:00, 58.16it/s]\u001b[A\n"," 85% 70/82 [00:01<00:00, 58.43it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 1.5426156520843506, 'eval_accuracy': 0.4570552147239264, 'eval_precision': 0.49267444332402843, 'eval_recall': 0.4570552147239264, 'eval_f1': 0.4672955136704765, 'eval_runtime': 1.4041, 'eval_samples_per_second': 464.338, 'eval_steps_per_second': 58.398, 'epoch': 2.0}\n"," 40% 4236/10590 [06:49<09:58, 10.62it/s]\n","100% 82/82 [00:01<00:00, 58.74it/s]\u001b[A\n","{'loss': 0.2591, 'grad_norm': 6.8605804443359375, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 6354/10590 [10:19<06:38, 10.63it/s]\n","  0% 0/82 [00:00<?, ?it/s]\u001b[A\n","  9% 7/82 [00:00<00:01, 68.28it/s]\u001b[A\n"," 17% 14/82 [00:00<00:01, 62.38it/s]\u001b[A\n"," 26% 21/82 [00:00<00:01, 60.36it/s]\u001b[A\n"," 34% 28/82 [00:00<00:00, 59.75it/s]\u001b[A\n"," 41% 34/82 [00:00<00:00, 59.80it/s]\u001b[A\n"," 49% 40/82 [00:00<00:00, 59.77it/s]\u001b[A\n"," 56% 46/82 [00:00<00:00, 59.36it/s]\u001b[A\n"," 63% 52/82 [00:00<00:00, 59.25it/s]\u001b[A\n"," 71% 58/82 [00:00<00:00, 59.31it/s]\u001b[A\n"," 78% 64/82 [00:01<00:00, 59.41it/s]\u001b[A\n"," 85% 70/82 [00:01<00:00, 59.38it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 2.1828317642211914, 'eval_accuracy': 0.44171779141104295, 'eval_precision': 0.47135415092628974, 'eval_recall': 0.44171779141104295, 'eval_f1': 0.44854521942069636, 'eval_runtime': 1.3855, 'eval_samples_per_second': 470.594, 'eval_steps_per_second': 59.185, 'epoch': 3.0}\n"," 60% 6354/10590 [10:20<06:38, 10.63it/s]\n","100% 82/82 [00:01<00:00, 59.44it/s]\u001b[A\n","{'loss': 0.1743, 'grad_norm': 4.1518402099609375, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 8472/10590 [13:49<03:22, 10.48it/s]\n","  0% 0/82 [00:00<?, ?it/s]\u001b[A\n","  9% 7/82 [00:00<00:01, 69.40it/s]\u001b[A\n"," 17% 14/82 [00:00<00:01, 63.50it/s]\u001b[A\n"," 26% 21/82 [00:00<00:00, 61.68it/s]\u001b[A\n"," 34% 28/82 [00:00<00:00, 60.77it/s]\u001b[A\n"," 43% 35/82 [00:00<00:00, 60.15it/s]\u001b[A\n"," 51% 42/82 [00:00<00:00, 59.97it/s]\u001b[A\n"," 60% 49/82 [00:00<00:00, 59.86it/s]\u001b[A\n"," 67% 55/82 [00:00<00:00, 59.81it/s]\u001b[A\n"," 74% 61/82 [00:01<00:00, 59.57it/s]\u001b[A\n"," 82% 67/82 [00:01<00:00, 59.56it/s]\u001b[A\n"," 89% 73/82 [00:01<00:00, 59.65it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 2.8204383850097656, 'eval_accuracy': 0.43558282208588955, 'eval_precision': 0.46480973001544, 'eval_recall': 0.43558282208588955, 'eval_f1': 0.4423892813660442, 'eval_runtime': 1.3758, 'eval_samples_per_second': 473.919, 'eval_steps_per_second': 59.603, 'epoch': 4.0}\n"," 80% 8472/10590 [13:51<03:22, 10.48it/s]\n","100% 82/82 [00:01<00:00, 59.69it/s]\u001b[A\n","{'loss': 0.1158, 'grad_norm': 23.109033584594727, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 10590/10590 [17:22<00:00, 10.63it/s]\n","  0% 0/82 [00:00<?, ?it/s]\u001b[A\n","  7% 6/82 [00:00<00:01, 58.50it/s]\u001b[A\n"," 15% 12/82 [00:00<00:01, 51.57it/s]\u001b[A\n"," 22% 18/82 [00:00<00:01, 53.41it/s]\u001b[A\n"," 29% 24/82 [00:00<00:01, 55.31it/s]\u001b[A\n"," 37% 30/82 [00:00<00:00, 56.64it/s]\u001b[A\n"," 44% 36/82 [00:00<00:00, 57.53it/s]\u001b[A\n"," 51% 42/82 [00:00<00:00, 57.94it/s]\u001b[A\n"," 59% 48/82 [00:00<00:00, 58.07it/s]\u001b[A\n"," 66% 54/82 [00:00<00:00, 58.41it/s]\u001b[A\n"," 73% 60/82 [00:01<00:00, 58.71it/s]\u001b[A\n"," 80% 66/82 [00:01<00:00, 58.96it/s]\u001b[A\n"," 88% 72/82 [00:01<00:00, 59.08it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 3.247363805770874, 'eval_accuracy': 0.44171779141104295, 'eval_precision': 0.46598474548428115, 'eval_recall': 0.44171779141104295, 'eval_f1': 0.4458852508280553, 'eval_runtime': 1.438, 'eval_samples_per_second': 453.4, 'eval_steps_per_second': 57.023, 'epoch': 5.0}\n","100% 10590/10590 [17:25<00:00, 10.63it/s]\n","100% 82/82 [00:03<00:00, 59.28it/s]\u001b[A\n","{'train_runtime': 1053.3111, 'train_samples_per_second': 160.864, 'train_steps_per_second': 10.054, 'train_loss': 0.3367736009520332, 'epoch': 5.0}\n","100% 10590/10590 [17:33<00:00, 10.05it/s]\n","100% 82/82 [00:01<00:00, 55.60it/s]\n","Evaluation results:\n","{'eval_loss': 3.247363805770874, 'eval_accuracy': 0.44171779141104295, 'eval_precision': 0.46598474548428115, 'eval_recall': 0.44171779141104295, 'eval_f1': 0.4458852508280553, 'eval_runtime': 1.4962, 'eval_samples_per_second': 435.772, 'eval_steps_per_second': 54.806, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/rltftfwv\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_215501-rltftfwv/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation/checkpoint-2118 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./metaphor_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/metaphor_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zIXAM9thOKg","executionInfo":{"status":"ok","timestamp":1733264014689,"user_tz":360,"elapsed":19961,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"5d745746-9b6a-4936-e466-54f27c5e5451"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:13:19.073057: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:13:19.089554: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:13:19.110707: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:13:19.117070: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:13:19.132085: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:13:20.204081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_221322-787gaasr\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/787gaasr\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 481/481 [00:00<00:00, 995.63 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 481/481 [00:00<00:00, 5336.12 examples/s]\n","Filter: 100% 481/481 [00:00<00:00, 5640.55 examples/s]\n","\n","Evaluation on English test set:\n"," 80% 24/30 [00:00<00:00, 57.74it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 30/30 [00:00<00:00, 55.74it/s]\n","{'eval_loss': 0.8751525282859802, 'eval_model_preparation_time': 0.0036, 'eval_accuracy': 0.625, 'eval_precision': 0.6179539295392954, 'eval_recall': 0.625, 'eval_f1': 0.607363581549593, 'eval_runtime': 1.1777, 'eval_samples_per_second': 203.789, 'eval_steps_per_second': 25.474}\n","\n","Evaluation on Russian test set:\n","100% 31/31 [00:00<00:00, 61.40it/s]\n","{'eval_loss': 1.170870304107666, 'eval_model_preparation_time': 0.0036, 'eval_accuracy': 0.4024896265560166, 'eval_precision': 0.4501844167819271, 'eval_recall': 0.4024896265560166, 'eval_f1': 0.39869194702785754, 'eval_runtime': 0.522, 'eval_samples_per_second': 461.659, 'eval_steps_per_second': 59.384}\n","\n","Evaluation on the entire test set:\n","100% 61/61 [00:01<00:00, 60.81it/s]\n","{'eval_loss': 1.023318886756897, 'eval_model_preparation_time': 0.0036, 'eval_accuracy': 0.5135135135135135, 'eval_precision': 0.5296350671167555, 'eval_recall': 0.5135135135135135, 'eval_f1': 0.5014501654409397, 'eval_runtime': 1.0191, 'eval_samples_per_second': 471.964, 'eval_steps_per_second': 59.854}\n","100% 30/30 [00:00<00:00, 60.42it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/metaphor_final/misclassified_English.jsonl\n","100% 31/31 [00:00<00:00, 61.14it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/metaphor_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/787gaasr\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_221322-787gaasr/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation/checkpoint-2118 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/anli_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8XLIjPgifFi","executionInfo":{"status":"ok","timestamp":1733264077178,"user_tz":360,"elapsed":62490,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"af2ad28b-d6a0-484d-8254-eb1bb06fcbf7"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:13:38.798861: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:13:38.815451: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:13:38.836757: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:13:38.843091: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:13:38.858185: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:13:39.926374: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_221342-n2l05kea\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/n2l05kea\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6400/6400 [00:01<00:00, 3806.82 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6400/6400 [00:01<00:00, 5772.11 examples/s]\n","Filter: 100% 6400/6400 [00:01<00:00, 5839.67 examples/s]\n","\n","Evaluation on English test set:\n"," 99% 396/400 [00:06<00:00, 59.52it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 400/400 [00:06<00:00, 58.75it/s]\n","{'eval_loss': 1.3935414552688599, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.375625, 'eval_precision': 0.378456452048828, 'eval_recall': 0.375625, 'eval_f1': 0.3528986796405977, 'eval_runtime': 7.595, 'eval_samples_per_second': 421.33, 'eval_steps_per_second': 52.666}\n","\n","Evaluation on Russian test set:\n","100% 400/400 [00:06<00:00, 59.55it/s]\n","{'eval_loss': 1.324672818183899, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.373125, 'eval_precision': 0.37909486178014506, 'eval_recall': 0.373125, 'eval_f1': 0.35079872440782967, 'eval_runtime': 6.7332, 'eval_samples_per_second': 475.258, 'eval_steps_per_second': 59.407}\n","\n","Evaluation on the entire test set:\n","100% 800/800 [00:13<00:00, 59.29it/s]\n","{'eval_loss': 1.359107255935669, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.374375, 'eval_precision': 0.3785793133906137, 'eval_recall': 0.374375, 'eval_f1': 0.35187680505385194, 'eval_runtime': 13.5095, 'eval_samples_per_second': 473.741, 'eval_steps_per_second': 59.218}\n","100% 400/400 [00:06<00:00, 59.36it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/anli_final/misclassified_English.jsonl\n","100% 400/400 [00:06<00:00, 58.30it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/anli_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/n2l05kea\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_221342-n2l05kea/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation/checkpoint-2118 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./final_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/comb_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xByhrh3nijWP","executionInfo":{"status":"ok","timestamp":1733264141926,"user_tz":360,"elapsed":64750,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"b97aa24a-0216-4504-b338-97938e6339b4"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:14:41.230604: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:14:41.248037: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:14:41.269749: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:14:41.276309: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:14:41.292377: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:14:42.382392: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_221444-7eqbuh9x\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/7eqbuh9x\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6881/6881 [00:01<00:00, 4002.34 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6881/6881 [00:01<00:00, 6074.12 examples/s]\n","Filter: 100% 6881/6881 [00:01<00:00, 6073.57 examples/s]\n","\n","Evaluation on English test set:\n"," 99% 426/430 [00:07<00:00, 58.15it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 430/430 [00:07<00:00, 58.52it/s]\n","{'eval_loss': 1.3573747873306274, 'eval_model_preparation_time': 0.0037, 'eval_accuracy': 0.3930232558139535, 'eval_precision': 0.40069399569895287, 'eval_recall': 0.3930232558139535, 'eval_f1': 0.3730536367193647, 'eval_runtime': 8.1288, 'eval_samples_per_second': 423.187, 'eval_steps_per_second': 52.898}\n","\n","Evaluation on Russian test set:\n","100% 431/431 [00:07<00:00, 59.11it/s]\n","{'eval_loss': 1.3139008283615112, 'eval_model_preparation_time': 0.0037, 'eval_accuracy': 0.3751816332461494, 'eval_precision': 0.3854831325028177, 'eval_recall': 0.3751816332461494, 'eval_f1': 0.35457077193108355, 'eval_runtime': 7.3072, 'eval_samples_per_second': 470.903, 'eval_steps_per_second': 58.983}\n","\n","Evaluation on the entire test set:\n","100% 861/861 [00:14<00:00, 59.61it/s]\n","{'eval_loss': 1.3356345891952515, 'eval_model_preparation_time': 0.0037, 'eval_accuracy': 0.3841011480889406, 'eval_precision': 0.39293220838749626, 'eval_recall': 0.3841011480889406, 'eval_f1': 0.36381392898798115, 'eval_runtime': 14.463, 'eval_samples_per_second': 475.767, 'eval_steps_per_second': 59.531}\n","100% 430/430 [00:07<00:00, 59.28it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/comb_final/misclassified_English.jsonl\n","100% 431/431 [00:07<00:00, 59.05it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/comb_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/7eqbuh9x\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_221444-7eqbuh9x/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation/checkpoint-2118 \\\n","    --task nli \\\n","    --dataset attribution_examples_comb.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_metaphor_anli_final/metaphor_negation_attribution"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fEaQm8Yeiqya","executionInfo":{"status":"ok","timestamp":1733265057219,"user_tz":360,"elapsed":915297,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"81dc6983-94e9-45cc-c863-abb29412b653"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:15:46.019549: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:15:46.036049: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:15:46.057022: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:15:46.063339: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:15:46.078166: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:15:47.144205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_221549-l14190ri\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/l14190ri\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 28836 examples [00:00, 346900.76 examples/s]\n","Filter: 100% 28836/28836 [00:00<00:00, 125386.25 examples/s]\n","Filter: 100% 28836/28836 [00:00<00:00, 136244.94 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 28084/28084 [00:07<00:00, 3854.74 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 752/752 [00:00<00:00, 1358.88 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.6526, 'grad_norm': 34.247642517089844, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 1756/8780 [02:46<10:13, 11.45it/s]\n","  0% 0/94 [00:00<?, ?it/s]\u001b[A\n","  7% 7/94 [00:00<00:01, 69.44it/s]\u001b[A\n"," 15% 14/94 [00:00<00:01, 63.33it/s]\u001b[A\n"," 22% 21/94 [00:00<00:01, 61.38it/s]\u001b[A\n"," 30% 28/94 [00:00<00:01, 60.42it/s]\u001b[A\n"," 37% 35/94 [00:00<00:00, 60.17it/s]\u001b[A\n"," 45% 42/94 [00:00<00:00, 60.08it/s]\u001b[A\n"," 52% 49/94 [00:00<00:00, 59.93it/s]\u001b[A\n"," 59% 55/94 [00:00<00:00, 59.91it/s]\u001b[A\n"," 65% 61/94 [00:01<00:00, 59.92it/s]\u001b[A\n"," 71% 67/94 [00:01<00:00, 59.84it/s]\u001b[A\n"," 78% 73/94 [00:01<00:00, 59.68it/s]\u001b[A\n"," 84% 79/94 [00:01<00:00, 59.63it/s]\u001b[A\n"," 90% 85/94 [00:01<00:00, 59.52it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 1.2895162105560303, 'eval_accuracy': 0.4375, 'eval_precision': 0.4626643167696315, 'eval_recall': 0.4375, 'eval_f1': 0.42053652249075085, 'eval_runtime': 1.5868, 'eval_samples_per_second': 473.899, 'eval_steps_per_second': 59.237, 'epoch': 1.0}\n"," 20% 1756/8780 [02:47<10:13, 11.45it/s]\n","100% 94/94 [00:01<00:00, 59.36it/s]\u001b[A\n","{'loss': 0.4023, 'grad_norm': 7.96931266784668, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 3512/8780 [05:42<07:32, 11.64it/s]\n","  0% 0/94 [00:00<?, ?it/s]\u001b[A\n","  7% 7/94 [00:00<00:01, 69.82it/s]\u001b[A\n"," 15% 14/94 [00:00<00:01, 63.56it/s]\u001b[A\n"," 22% 21/94 [00:00<00:01, 61.85it/s]\u001b[A\n"," 30% 28/94 [00:00<00:01, 60.98it/s]\u001b[A\n"," 37% 35/94 [00:00<00:00, 60.69it/s]\u001b[A\n"," 45% 42/94 [00:00<00:00, 60.48it/s]\u001b[A\n"," 52% 49/94 [00:00<00:00, 60.25it/s]\u001b[A\n"," 60% 56/94 [00:00<00:00, 60.16it/s]\u001b[A\n"," 67% 63/94 [00:01<00:00, 60.12it/s]\u001b[A\n"," 74% 70/94 [00:01<00:00, 59.88it/s]\u001b[A\n"," 81% 76/94 [00:01<00:00, 59.81it/s]\u001b[A\n"," 87% 82/94 [00:01<00:00, 59.75it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 1.6543697118759155, 'eval_accuracy': 0.4574468085106383, 'eval_precision': 0.4547117486946662, 'eval_recall': 0.4574468085106383, 'eval_f1': 0.45166989142753466, 'eval_runtime': 1.5775, 'eval_samples_per_second': 476.69, 'eval_steps_per_second': 59.586, 'epoch': 2.0}\n"," 40% 3512/8780 [05:44<07:32, 11.64it/s]\n","100% 94/94 [00:01<00:00, 59.71it/s]\u001b[A\n","{'loss': 0.2485, 'grad_norm': 22.88235092163086, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 5268/8780 [08:35<05:28, 10.68it/s]\n","  0% 0/94 [00:00<?, ?it/s]\u001b[A\n","  7% 7/94 [00:00<00:01, 69.91it/s]\u001b[A\n"," 15% 14/94 [00:00<00:01, 63.65it/s]\u001b[A\n"," 22% 21/94 [00:00<00:01, 61.79it/s]\u001b[A\n"," 30% 28/94 [00:00<00:01, 61.03it/s]\u001b[A\n"," 37% 35/94 [00:00<00:00, 60.65it/s]\u001b[A\n"," 45% 42/94 [00:00<00:00, 60.39it/s]\u001b[A\n"," 52% 49/94 [00:00<00:00, 60.22it/s]\u001b[A\n"," 60% 56/94 [00:00<00:00, 60.06it/s]\u001b[A\n"," 67% 63/94 [00:01<00:00, 59.83it/s]\u001b[A\n"," 73% 69/94 [00:01<00:00, 59.72it/s]\u001b[A\n"," 80% 75/94 [00:01<00:00, 59.74it/s]\u001b[A\n"," 86% 81/94 [00:01<00:00, 59.70it/s]\u001b[A\n"," 93% 87/94 [00:01<00:00, 59.68it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 2.088310480117798, 'eval_accuracy': 0.4800531914893617, 'eval_precision': 0.49016512155173103, 'eval_recall': 0.4800531914893617, 'eval_f1': 0.47095986153824254, 'eval_runtime': 1.5789, 'eval_samples_per_second': 476.29, 'eval_steps_per_second': 59.536, 'epoch': 3.0}\n"," 60% 5268/8780 [08:37<05:28, 10.68it/s]\n","100% 94/94 [00:01<00:00, 60.18it/s]\u001b[A\n","{'loss': 0.1634, 'grad_norm': 0.508073091506958, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 7024/8780 [11:31<02:32, 11.50it/s]\n","  0% 0/94 [00:00<?, ?it/s]\u001b[A\n","  7% 7/94 [00:00<00:01, 64.87it/s]\u001b[A\n"," 15% 14/94 [00:00<00:01, 60.51it/s]\u001b[A\n"," 22% 21/94 [00:00<00:01, 59.87it/s]\u001b[A\n"," 29% 27/94 [00:00<00:01, 59.81it/s]\u001b[A\n"," 35% 33/94 [00:00<00:01, 59.78it/s]\u001b[A\n"," 41% 39/94 [00:00<00:00, 59.80it/s]\u001b[A\n"," 48% 45/94 [00:00<00:00, 59.64it/s]\u001b[A\n"," 54% 51/94 [00:00<00:00, 59.34it/s]\u001b[A\n"," 61% 57/94 [00:00<00:00, 59.04it/s]\u001b[A\n"," 67% 63/94 [00:01<00:00, 58.94it/s]\u001b[A\n"," 74% 70/94 [00:01<00:00, 59.32it/s]\u001b[A\n"," 82% 77/94 [00:01<00:00, 59.58it/s]\u001b[A\n"," 88% 83/94 [00:01<00:00, 59.62it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 2.8609840869903564, 'eval_accuracy': 0.4601063829787234, 'eval_precision': 0.45905748920752387, 'eval_recall': 0.4601063829787234, 'eval_f1': 0.4553123443846545, 'eval_runtime': 1.6044, 'eval_samples_per_second': 468.716, 'eval_steps_per_second': 58.589, 'epoch': 4.0}\n"," 80% 7024/8780 [11:32<02:32, 11.50it/s]\n","100% 94/94 [00:01<00:00, 59.28it/s]\u001b[A\n","{'loss': 0.1065, 'grad_norm': 0.016609489917755127, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 8780/8780 [14:36<00:00, 11.59it/s]\n","  0% 0/94 [00:00<?, ?it/s]\u001b[A\n","  6% 6/94 [00:00<00:01, 59.60it/s]\u001b[A\n"," 13% 12/94 [00:00<00:01, 56.80it/s]\u001b[A\n"," 19% 18/94 [00:00<00:01, 57.97it/s]\u001b[A\n"," 26% 24/94 [00:00<00:01, 58.56it/s]\u001b[A\n"," 32% 30/94 [00:00<00:01, 59.05it/s]\u001b[A\n"," 38% 36/94 [00:00<00:00, 59.26it/s]\u001b[A\n"," 45% 42/94 [00:00<00:00, 59.45it/s]\u001b[A\n"," 51% 48/94 [00:00<00:00, 59.44it/s]\u001b[A\n"," 57% 54/94 [00:00<00:00, 59.38it/s]\u001b[A\n"," 64% 60/94 [00:01<00:00, 59.50it/s]\u001b[A\n"," 70% 66/94 [00:01<00:00, 59.45it/s]\u001b[A\n"," 77% 72/94 [00:01<00:00, 59.45it/s]\u001b[A\n"," 83% 78/94 [00:01<00:00, 59.49it/s]\u001b[A\n"," 89% 84/94 [00:01<00:00, 59.24it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 3.302947998046875, 'eval_accuracy': 0.46941489361702127, 'eval_precision': 0.4731058651314987, 'eval_recall': 0.46941489361702127, 'eval_f1': 0.46822464159104527, 'eval_runtime': 1.6145, 'eval_samples_per_second': 465.785, 'eval_steps_per_second': 58.223, 'epoch': 5.0}\n","100% 8780/8780 [14:38<00:00, 11.59it/s]\n","100% 94/94 [00:01<00:00, 59.30it/s]\u001b[A\n","{'train_runtime': 888.1499, 'train_samples_per_second': 158.104, 'train_steps_per_second': 9.886, 'train_loss': 0.3146561172937206, 'epoch': 5.0}\n","100% 8780/8780 [14:48<00:00,  9.89it/s]\n","100% 94/94 [00:03<00:00, 30.94it/s]\n","Evaluation results:\n","{'eval_loss': 3.302947998046875, 'eval_accuracy': 0.46941489361702127, 'eval_precision': 0.4731058651314987, 'eval_recall': 0.46941489361702127, 'eval_f1': 0.46822464159104527, 'eval_runtime': 1.687, 'eval_samples_per_second': 445.75, 'eval_steps_per_second': 55.719, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/l14190ri\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_221549-l14190ri/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation_attribution/checkpoint-1756 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./metaphor_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/metaphor_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QgoCL8GKi1Vr","executionInfo":{"status":"ok","timestamp":1733265121111,"user_tz":360,"elapsed":19636,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"e699e0e5-477e-43c2-dcb7-a07c3c80585d"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:31:45.688523: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:31:45.705858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:31:45.728308: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:31:45.735072: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:31:45.751530: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:31:46.825540: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_223149-hz9xvw7n\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/hz9xvw7n\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 481/481 [00:00<00:00, 979.64 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 481/481 [00:00<00:00, 5221.71 examples/s]\n","Filter: 100% 481/481 [00:00<00:00, 5555.12 examples/s]\n","\n","Evaluation on English test set:\n"," 80% 24/30 [00:00<00:00, 58.21it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 30/30 [00:00<00:00, 55.97it/s]\n","{'eval_loss': 1.000471830368042, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.5333333333333333, 'eval_precision': 0.5420411455171018, 'eval_recall': 0.5333333333333333, 'eval_f1': 0.5265973532285283, 'eval_runtime': 1.1287, 'eval_samples_per_second': 212.625, 'eval_steps_per_second': 26.578}\n","\n","Evaluation on Russian test set:\n","100% 31/31 [00:00<00:00, 60.74it/s]\n","{'eval_loss': 1.2573847770690918, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.4107883817427386, 'eval_precision': 0.4919422440169328, 'eval_recall': 0.4107883817427386, 'eval_f1': 0.4093933025844593, 'eval_runtime': 0.528, 'eval_samples_per_second': 456.47, 'eval_steps_per_second': 58.716}\n","\n","Evaluation on the entire test set:\n","100% 61/61 [00:00<00:00, 61.08it/s]\n","{'eval_loss': 1.1291953325271606, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.47193347193347196, 'eval_precision': 0.5120379008158175, 'eval_recall': 0.47193347193347196, 'eval_f1': 0.4676118761484615, 'eval_runtime': 1.0162, 'eval_samples_per_second': 473.324, 'eval_steps_per_second': 60.027}\n","100% 30/30 [00:00<00:00, 60.35it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/metaphor_final/misclassified_English.jsonl\n","100% 31/31 [00:00<00:00, 60.76it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/metaphor_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/hz9xvw7n\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_223149-hz9xvw7n/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation_attribution/checkpoint-1756 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/anli_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8loJ8EQFi6mJ","executionInfo":{"status":"ok","timestamp":1733265183279,"user_tz":360,"elapsed":62170,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"af346a6e-94e5-4128-bd96-871b672225ec"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:32:05.234317: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:32:05.251346: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:32:05.272900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:32:05.279283: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:32:05.294184: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:32:06.359027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_223208-hxn1u50w\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/hxn1u50w\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6400/6400 [00:01<00:00, 3899.16 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6400/6400 [00:01<00:00, 6100.97 examples/s]\n","Filter: 100% 6400/6400 [00:01<00:00, 6116.05 examples/s]\n","\n","Evaluation on English test set:\n"," 98% 394/400 [00:06<00:00, 59.85it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 400/400 [00:06<00:00, 58.90it/s]\n","{'eval_loss': 1.402113676071167, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.4246875, 'eval_precision': 0.43085337916220645, 'eval_recall': 0.4246875, 'eval_f1': 0.41066690132625383, 'eval_runtime': 7.395, 'eval_samples_per_second': 432.723, 'eval_steps_per_second': 54.09}\n","\n","Evaluation on Russian test set:\n","100% 400/400 [00:06<00:00, 59.13it/s]\n","{'eval_loss': 1.3525699377059937, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.4071875, 'eval_precision': 0.40941939065255634, 'eval_recall': 0.4071875, 'eval_f1': 0.3887377171138004, 'eval_runtime': 6.7821, 'eval_samples_per_second': 471.828, 'eval_steps_per_second': 58.979}\n","\n","Evaluation on the entire test set:\n","100% 800/800 [00:13<00:00, 59.84it/s]\n","{'eval_loss': 1.377341866493225, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.4159375, 'eval_precision': 0.42044434490672444, 'eval_recall': 0.4159375, 'eval_f1': 0.3998095920792942, 'eval_runtime': 13.3851, 'eval_samples_per_second': 478.143, 'eval_steps_per_second': 59.768}\n","100% 400/400 [00:06<00:00, 59.15it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/anli_final/misclassified_English.jsonl\n","100% 400/400 [00:06<00:00, 59.57it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/anli_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/hxn1u50w\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_223208-hxn1u50w/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation_attribution/checkpoint-1756 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./final_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/comb_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-am-r87zi_AH","executionInfo":{"status":"ok","timestamp":1733265247525,"user_tz":360,"elapsed":64248,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"a11183bc-19a8-4412-823e-40a145ff4129"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:33:07.440673: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:33:07.458598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:33:07.480054: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:33:07.486523: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:33:07.503224: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:33:08.576496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_223311-yo1xu52l\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/yo1xu52l\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6881/6881 [00:01<00:00, 4091.86 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6881/6881 [00:01<00:00, 5874.21 examples/s]\n","Filter: 100% 6881/6881 [00:01<00:00, 5989.00 examples/s]\n","\n","Evaluation on English test set:\n"," 99% 424/430 [00:07<00:00, 58.10it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 430/430 [00:07<00:00, 58.49it/s]\n","{'eval_loss': 1.3740921020507812, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.4322674418604651, 'eval_precision': 0.44283421066449236, 'eval_recall': 0.4322674418604651, 'eval_f1': 0.420439392035463, 'eval_runtime': 7.9725, 'eval_samples_per_second': 431.484, 'eval_steps_per_second': 53.936}\n","\n","Evaluation on Russian test set:\n","100% 431/431 [00:07<00:00, 59.59it/s]\n","{'eval_loss': 1.3459033966064453, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.4074396977622784, 'eval_precision': 0.41664903202991677, 'eval_recall': 0.4074396977622784, 'eval_f1': 0.39098204762082484, 'eval_runtime': 7.2498, 'eval_samples_per_second': 474.633, 'eval_steps_per_second': 59.45}\n","\n","Evaluation on the entire test set:\n","100% 861/861 [00:14<00:00, 59.74it/s]\n","{'eval_loss': 1.359995722770691, 'eval_model_preparation_time': 0.0035, 'eval_accuracy': 0.41985176573172506, 'eval_precision': 0.4300872193318732, 'eval_recall': 0.41985176573172506, 'eval_f1': 0.4058418578819101, 'eval_runtime': 14.429, 'eval_samples_per_second': 476.886, 'eval_steps_per_second': 59.671}\n","100% 430/430 [00:07<00:00, 59.57it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/comb_final/misclassified_English.jsonl\n","100% 431/431 [00:07<00:00, 59.73it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/comb_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/yo1xu52l\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_223311-yo1xu52l/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation_attribution/checkpoint-1756 \\\n","    --task nli \\\n","    --dataset high_overlap_examples_comb.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_metaphor_anli_final/metaphor_negation_attribution_overlap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6BPAjs2ejHqr","executionInfo":{"status":"ok","timestamp":1733265407912,"user_tz":360,"elapsed":160392,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"995463cb-f03c-4fb8-bae1-b85add86fce0"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:34:11.597981: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:34:11.614543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:34:11.635514: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:34:11.641873: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:34:11.656953: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:34:12.720361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_223415-svzldhwz\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/svzldhwz\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 3236 examples [00:00, 22611.33 examples/s]\n","Filter: 100% 3236/3236 [00:00<00:00, 89922.80 examples/s]\n","Filter: 100% 3236/3236 [00:00<00:00, 100945.04 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 3178/3178 [00:01<00:00, 2359.30 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 58/58 [00:00<00:00, 140.58 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.6455, 'grad_norm': 47.341312408447266, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 199/995 [00:19<01:14, 10.68it/s]\n","  0% 0/8 [00:00<?, ?it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.8603686690330505, 'eval_accuracy': 0.7241379310344828, 'eval_precision': 0.8184932883208745, 'eval_recall': 0.7241379310344828, 'eval_f1': 0.7648155841757835, 'eval_runtime': 0.1348, 'eval_samples_per_second': 430.247, 'eval_steps_per_second': 59.344, 'epoch': 1.0}\n"," 20% 199/995 [00:19<01:14, 10.68it/s]\n","100% 8/8 [00:00<00:00, 73.24it/s]\u001b[A\n","{'loss': 0.3297, 'grad_norm': 4.7247490882873535, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 398/995 [00:44<00:54, 11.04it/s]\n","  0% 0/8 [00:00<?, ?it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.1193705797195435, 'eval_accuracy': 0.6551724137931034, 'eval_precision': 0.7949869603013618, 'eval_recall': 0.6551724137931034, 'eval_f1': 0.7119068670792809, 'eval_runtime': 0.1417, 'eval_samples_per_second': 409.441, 'eval_steps_per_second': 56.475, 'epoch': 2.0}\n"," 40% 398/995 [00:44<00:54, 11.04it/s]\n","100% 8/8 [00:00<00:00, 68.25it/s]\u001b[A\n","{'loss': 0.1863, 'grad_norm': 0.7381496429443359, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 597/995 [01:09<00:36, 10.92it/s]\n","  0% 0/8 [00:00<?, ?it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.638780951499939, 'eval_accuracy': 0.6379310344827587, 'eval_precision': 0.7591431556948799, 'eval_recall': 0.6379310344827587, 'eval_f1': 0.6811986863711003, 'eval_runtime': 0.139, 'eval_samples_per_second': 417.309, 'eval_steps_per_second': 57.56, 'epoch': 3.0}\n"," 60% 597/995 [01:09<00:36, 10.92it/s]\n","100% 8/8 [00:00<00:00, 67.52it/s]\u001b[A\n","{'loss': 0.1282, 'grad_norm': 0.04100848734378815, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 796/995 [01:36<00:18, 10.62it/s]\n","  0% 0/8 [00:00<?, ?it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 2.276968479156494, 'eval_accuracy': 0.5344827586206896, 'eval_precision': 0.7310025542784163, 'eval_recall': 0.5344827586206896, 'eval_f1': 0.5949490043710539, 'eval_runtime': 0.133, 'eval_samples_per_second': 436.137, 'eval_steps_per_second': 60.157, 'epoch': 4.0}\n"," 80% 796/995 [01:36<00:18, 10.62it/s]\n","100% 8/8 [00:00<00:00, 74.15it/s]\u001b[A\n","{'loss': 0.1011, 'grad_norm': 34.697288513183594, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 995/995 [02:10<00:00, 10.60it/s]\n","  0% 0/8 [00:00<?, ?it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 2.04769229888916, 'eval_accuracy': 0.603448275862069, 'eval_precision': 0.7522460853940275, 'eval_recall': 0.603448275862069, 'eval_f1': 0.654895199459094, 'eval_runtime': 0.1551, 'eval_samples_per_second': 373.963, 'eval_steps_per_second': 51.581, 'epoch': 5.0}\n","100% 995/995 [02:10<00:00, 10.60it/s]\n","100% 8/8 [00:00<00:00, 59.85it/s]\u001b[A\n","{'train_runtime': 142.6351, 'train_samples_per_second': 111.403, 'train_steps_per_second': 6.976, 'train_loss': 0.27814213930062914, 'epoch': 5.0}\n","100% 995/995 [02:22<00:00,  6.98it/s]\n","100% 8/8 [00:00<00:00, 58.09it/s]\n","Evaluation results:\n","{'eval_loss': 2.04769229888916, 'eval_accuracy': 0.603448275862069, 'eval_precision': 0.7522460853940275, 'eval_recall': 0.603448275862069, 'eval_f1': 0.654895199459094, 'eval_runtime': 0.1577, 'eval_samples_per_second': 367.777, 'eval_steps_per_second': 50.728, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/svzldhwz\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_223415-svzldhwz/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation_attribution_overlap/checkpoint-199 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./metaphor_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/metaphor_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9t8xLda3lscE","executionInfo":{"status":"ok","timestamp":1733265547891,"user_tz":360,"elapsed":19448,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"60e7585b-d34c-42b0-9ffd-be3bcdb8aae5"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:38:52.754904: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:38:52.772276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:38:52.793760: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:38:52.800540: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:38:52.816463: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:38:53.998686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_223856-f5yu1xyu\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/f5yu1xyu\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 481/481 [00:00<00:00, 988.38 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 481/481 [00:00<00:00, 4982.52 examples/s]\n","Filter: 100% 481/481 [00:00<00:00, 5417.92 examples/s]\n","\n","Evaluation on English test set:\n"," 80% 24/30 [00:00<00:00, 56.54it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 30/30 [00:00<00:00, 54.43it/s]\n","{'eval_loss': 0.9551528096199036, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.5625, 'eval_precision': 0.5549884656319407, 'eval_recall': 0.5625, 'eval_f1': 0.5536846550542118, 'eval_runtime': 1.1514, 'eval_samples_per_second': 208.435, 'eval_steps_per_second': 26.054}\n","\n","Evaluation on Russian test set:\n","100% 31/31 [00:00<00:00, 61.38it/s]\n","{'eval_loss': 1.179848551750183, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.44398340248962653, 'eval_precision': 0.4756424255659897, 'eval_recall': 0.44398340248962653, 'eval_f1': 0.4541823647320736, 'eval_runtime': 0.5216, 'eval_samples_per_second': 462.079, 'eval_steps_per_second': 59.437}\n","\n","Evaluation on the entire test set:\n","100% 61/61 [00:00<00:00, 61.05it/s]\n","{'eval_loss': 1.0677343606948853, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.5031185031185031, 'eval_precision': 0.50491973063358, 'eval_recall': 0.5031185031185031, 'eval_f1': 0.5038217966615217, 'eval_runtime': 1.0154, 'eval_samples_per_second': 473.706, 'eval_steps_per_second': 60.075}\n","100% 30/30 [00:00<00:00, 59.39it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/metaphor_final/misclassified_English.jsonl\n","100% 31/31 [00:00<00:00, 61.07it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/metaphor_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/f5yu1xyu\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_223856-f5yu1xyu/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation_attribution_overlap/checkpoint-199 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/anli_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAQpUvmElxqb","executionInfo":{"status":"ok","timestamp":1733265609058,"user_tz":360,"elapsed":61168,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"bdef8a06-a173-4e83-f9ef-8a115fcb8436"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:39:11.861944: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:39:11.878909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:39:11.899928: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:39:11.906282: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:39:11.921416: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:39:12.980213: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_223915-qa17s9f1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/qa17s9f1\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6400/6400 [00:01<00:00, 3923.87 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6400/6400 [00:01<00:00, 5867.40 examples/s]\n","Filter: 100% 6400/6400 [00:01<00:00, 5874.33 examples/s]\n","\n","Evaluation on English test set:\n"," 99% 396/400 [00:06<00:00, 58.80it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 400/400 [00:06<00:00, 58.99it/s]\n","{'eval_loss': 1.567586064338684, 'eval_model_preparation_time': 0.0051, 'eval_accuracy': 0.4053125, 'eval_precision': 0.40542281226720733, 'eval_recall': 0.4053125, 'eval_f1': 0.4051455949097283, 'eval_runtime': 7.3671, 'eval_samples_per_second': 434.361, 'eval_steps_per_second': 54.295}\n","\n","Evaluation on Russian test set:\n","100% 400/400 [00:06<00:00, 59.41it/s]\n","{'eval_loss': 1.4874482154846191, 'eval_model_preparation_time': 0.0051, 'eval_accuracy': 0.3984375, 'eval_precision': 0.39795096882008607, 'eval_recall': 0.3984375, 'eval_f1': 0.3980784413909733, 'eval_runtime': 6.7475, 'eval_samples_per_second': 474.251, 'eval_steps_per_second': 59.281}\n","\n","Evaluation on the entire test set:\n","100% 800/800 [00:13<00:00, 59.65it/s]\n","{'eval_loss': 1.5275171995162964, 'eval_model_preparation_time': 0.0051, 'eval_accuracy': 0.401875, 'eval_precision': 0.40162203424077575, 'eval_recall': 0.401875, 'eval_f1': 0.4016609950097081, 'eval_runtime': 13.4284, 'eval_samples_per_second': 476.601, 'eval_steps_per_second': 59.575}\n","100% 400/400 [00:06<00:00, 59.08it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/anli_final/misclassified_English.jsonl\n","100% 400/400 [00:06<00:00, 59.73it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/anli_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/qa17s9f1\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_223915-qa17s9f1/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation_attribution_overlap/checkpoint-199 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./final_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/comb_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcRNlFu0l1-W","executionInfo":{"status":"ok","timestamp":1733265678671,"user_tz":360,"elapsed":69615,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"7596c05b-3224-4693-b419-996e0ec1c51a"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:40:13.190912: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:40:13.209233: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:40:13.231209: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:40:13.237661: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:40:13.254146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:40:14.314506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_224016-zpdsdfcf\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/zpdsdfcf\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6881/6881 [00:01<00:00, 4012.51 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6881/6881 [00:01<00:00, 5974.98 examples/s]\n","Filter: 100% 6881/6881 [00:01<00:00, 6041.84 examples/s]\n","\n","Evaluation on English test set:\n","100% 429/430 [00:07<00:00, 59.78it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 430/430 [00:07<00:00, 59.58it/s]\n","{'eval_loss': 1.5248582363128662, 'eval_model_preparation_time': 0.0036, 'eval_accuracy': 0.41627906976744183, 'eval_precision': 0.4164948484800188, 'eval_recall': 0.41627906976744183, 'eval_f1': 0.4162859370333447, 'eval_runtime': 7.8407, 'eval_samples_per_second': 438.738, 'eval_steps_per_second': 54.842}\n","\n","Evaluation on Russian test set:\n","100% 431/431 [00:07<00:00, 59.70it/s]\n","{'eval_loss': 1.4659045934677124, 'eval_model_preparation_time': 0.0036, 'eval_accuracy': 0.4016274338854984, 'eval_precision': 0.4013731297888764, 'eval_recall': 0.4016274338854984, 'eval_f1': 0.40133331456207066, 'eval_runtime': 7.2358, 'eval_samples_per_second': 475.551, 'eval_steps_per_second': 59.565}\n","\n","Evaluation on the entire test set:\n","100% 861/861 [00:14<00:00, 60.07it/s]\n","{'eval_loss': 1.4953771829605103, 'eval_model_preparation_time': 0.0036, 'eval_accuracy': 0.40895218718209564, 'eval_precision': 0.4089202235031843, 'eval_recall': 0.40895218718209564, 'eval_f1': 0.40885211194199, 'eval_runtime': 14.3484, 'eval_samples_per_second': 479.566, 'eval_steps_per_second': 60.007}\n","100% 430/430 [00:07<00:00, 59.64it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/comb_final/misclassified_English.jsonl\n","100% 431/431 [00:07<00:00, 59.39it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/comb_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/zpdsdfcf\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_224016-zpdsdfcf/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset final_train.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 5 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_metaphor_anli_final/comb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpSNyWDwrRx7","executionInfo":{"status":"ok","timestamp":1733267986602,"user_tz":360,"elapsed":2059427,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"88f00803-4d83-45ec-ceb7-1810a0831d0c"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 22:45:31.366913: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 22:45:31.383959: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 22:45:31.404959: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 22:45:31.411327: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 22:45:31.426561: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 22:45:32.489389: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_224535-7dpa1010\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/7dpa1010\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 69015 examples [00:00, 142835.59 examples/s]\n","Filter: 100% 69015/69015 [00:00<00:00, 123099.11 examples/s]\n","Filter: 100% 69015/69015 [00:00<00:00, 128852.75 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 66591/66591 [00:14<00:00, 4747.84 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 1943/1943 [00:00<00:00, 2564.42 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.6794, 'grad_norm': 9.208296775817871, 'learning_rate': 4e-05, 'epoch': 1.0}\n"," 20% 4162/20810 [06:32<26:16, 10.56it/s]\n","  0% 0/243 [00:00<?, ?it/s]\u001b[A\n","  3% 7/243 [00:00<00:03, 69.35it/s]\u001b[A\n","  6% 14/243 [00:00<00:03, 63.33it/s]\u001b[A\n","  9% 21/243 [00:00<00:03, 61.69it/s]\u001b[A\n"," 12% 28/243 [00:00<00:03, 60.86it/s]\u001b[A\n"," 14% 35/243 [00:00<00:03, 60.49it/s]\u001b[A\n"," 17% 42/243 [00:00<00:03, 60.19it/s]\u001b[A\n"," 20% 49/243 [00:00<00:03, 59.96it/s]\u001b[A\n"," 23% 56/243 [00:00<00:03, 59.94it/s]\u001b[A\n"," 26% 62/243 [00:01<00:03, 59.88it/s]\u001b[A\n"," 28% 68/243 [00:01<00:02, 59.82it/s]\u001b[A\n"," 30% 74/243 [00:01<00:02, 59.72it/s]\u001b[A\n"," 33% 80/243 [00:01<00:02, 59.68it/s]\u001b[A\n"," 35% 86/243 [00:01<00:02, 59.70it/s]\u001b[A\n"," 38% 92/243 [00:01<00:02, 59.48it/s]\u001b[A\n"," 40% 98/243 [00:01<00:02, 59.46it/s]\u001b[A\n"," 43% 104/243 [00:01<00:02, 59.44it/s]\u001b[A\n"," 45% 110/243 [00:01<00:02, 59.29it/s]\u001b[A\n"," 48% 116/243 [00:01<00:02, 58.89it/s]\u001b[A\n"," 50% 122/243 [00:02<00:02, 59.02it/s]\u001b[A\n"," 53% 128/243 [00:02<00:01, 59.23it/s]\u001b[A\n"," 55% 134/243 [00:02<00:01, 59.32it/s]\u001b[A\n"," 58% 140/243 [00:02<00:01, 59.26it/s]\u001b[A\n"," 60% 146/243 [00:02<00:01, 59.38it/s]\u001b[A\n"," 63% 152/243 [00:02<00:01, 59.49it/s]\u001b[A\n"," 65% 158/243 [00:02<00:01, 59.53it/s]\u001b[A\n"," 67% 164/243 [00:02<00:01, 59.56it/s]\u001b[A\n"," 70% 170/243 [00:02<00:01, 59.58it/s]\u001b[A\n"," 72% 176/243 [00:02<00:01, 59.64it/s]\u001b[A\n"," 75% 182/243 [00:03<00:01, 59.69it/s]\u001b[A\n"," 77% 188/243 [00:03<00:00, 59.67it/s]\u001b[A\n"," 80% 194/243 [00:03<00:00, 59.73it/s]\u001b[A\n"," 82% 200/243 [00:03<00:00, 59.64it/s]\u001b[A\n"," 85% 206/243 [00:03<00:00, 59.60it/s]\u001b[A\n"," 88% 213/243 [00:03<00:00, 59.76it/s]\u001b[A\n"," 90% 219/243 [00:03<00:00, 59.62it/s]\u001b[A\n"," 93% 225/243 [00:03<00:00, 59.59it/s]\u001b[A\n"," 95% 231/243 [00:03<00:00, 59.62it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 1.1461308002471924, 'eval_accuracy': 0.4827586206896552, 'eval_precision': 0.48367729060768083, 'eval_recall': 0.4827586206896552, 'eval_f1': 0.4825052000503868, 'eval_runtime': 4.0868, 'eval_samples_per_second': 475.438, 'eval_steps_per_second': 59.46, 'epoch': 1.0}\n"," 20% 4162/20810 [06:36<26:16, 10.56it/s]\n","100% 243/243 [00:04<00:00, 59.57it/s]\u001b[A\n","{'loss': 0.4437, 'grad_norm': 19.29572296142578, 'learning_rate': 3e-05, 'epoch': 2.0}\n"," 40% 8324/20810 [13:14<19:22, 10.74it/s]\n","  0% 0/243 [00:00<?, ?it/s]\u001b[A\n","  3% 7/243 [00:00<00:03, 69.12it/s]\u001b[A\n","  6% 14/243 [00:00<00:03, 62.95it/s]\u001b[A\n","  9% 21/243 [00:00<00:03, 61.47it/s]\u001b[A\n"," 12% 28/243 [00:00<00:03, 60.84it/s]\u001b[A\n"," 14% 35/243 [00:00<00:03, 60.50it/s]\u001b[A\n"," 17% 42/243 [00:00<00:03, 60.23it/s]\u001b[A\n"," 20% 49/243 [00:00<00:03, 59.91it/s]\u001b[A\n"," 23% 55/243 [00:00<00:03, 59.82it/s]\u001b[A\n"," 25% 61/243 [00:01<00:03, 59.76it/s]\u001b[A\n"," 28% 67/243 [00:01<00:02, 59.65it/s]\u001b[A\n"," 30% 73/243 [00:01<00:02, 59.57it/s]\u001b[A\n"," 33% 79/243 [00:01<00:02, 59.58it/s]\u001b[A\n"," 35% 85/243 [00:01<00:02, 59.58it/s]\u001b[A\n"," 37% 91/243 [00:01<00:02, 59.66it/s]\u001b[A\n"," 40% 97/243 [00:01<00:02, 59.65it/s]\u001b[A\n"," 42% 103/243 [00:01<00:02, 59.60it/s]\u001b[A\n"," 45% 109/243 [00:01<00:02, 59.65it/s]\u001b[A\n"," 47% 115/243 [00:01<00:02, 59.58it/s]\u001b[A\n"," 50% 121/243 [00:02<00:02, 59.49it/s]\u001b[A\n"," 52% 127/243 [00:02<00:01, 59.61it/s]\u001b[A\n"," 55% 133/243 [00:02<00:01, 59.69it/s]\u001b[A\n"," 57% 139/243 [00:02<00:01, 59.73it/s]\u001b[A\n"," 60% 145/243 [00:02<00:01, 59.68it/s]\u001b[A\n"," 62% 151/243 [00:02<00:01, 59.71it/s]\u001b[A\n"," 65% 157/243 [00:02<00:01, 59.76it/s]\u001b[A\n"," 67% 163/243 [00:02<00:01, 59.72it/s]\u001b[A\n"," 70% 169/243 [00:02<00:01, 59.74it/s]\u001b[A\n"," 72% 175/243 [00:02<00:01, 59.77it/s]\u001b[A\n"," 74% 181/243 [00:03<00:01, 59.70it/s]\u001b[A\n"," 77% 187/243 [00:03<00:00, 59.67it/s]\u001b[A\n"," 79% 193/243 [00:03<00:00, 59.40it/s]\u001b[A\n"," 82% 199/243 [00:03<00:00, 59.50it/s]\u001b[A\n"," 84% 205/243 [00:03<00:00, 59.57it/s]\u001b[A\n"," 87% 211/243 [00:03<00:00, 59.64it/s]\u001b[A\n"," 89% 217/243 [00:03<00:00, 59.66it/s]\u001b[A\n"," 92% 223/243 [00:03<00:00, 59.68it/s]\u001b[A\n"," 94% 229/243 [00:03<00:00, 59.66it/s]\u001b[A\n"," 97% 235/243 [00:03<00:00, 59.60it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 1.3890290260314941, 'eval_accuracy': 0.48481729284611425, 'eval_precision': 0.4847932953073734, 'eval_recall': 0.48481729284611425, 'eval_f1': 0.48480101441208334, 'eval_runtime': 4.0813, 'eval_samples_per_second': 476.075, 'eval_steps_per_second': 59.54, 'epoch': 2.0}\n"," 40% 8324/20810 [13:18<19:22, 10.74it/s]\n","100% 243/243 [00:04<00:00, 59.59it/s]\u001b[A\n","{'loss': 0.2751, 'grad_norm': 40.58195114135742, 'learning_rate': 2e-05, 'epoch': 3.0}\n"," 60% 12486/20810 [19:57<13:09, 10.54it/s]\n","  0% 0/243 [00:00<?, ?it/s]\u001b[A\n","  3% 7/243 [00:00<00:03, 68.12it/s]\u001b[A\n","  6% 14/243 [00:00<00:03, 62.77it/s]\u001b[A\n","  9% 21/243 [00:00<00:03, 61.31it/s]\u001b[A\n"," 12% 28/243 [00:00<00:03, 60.70it/s]\u001b[A\n"," 14% 35/243 [00:00<00:03, 60.23it/s]\u001b[A\n"," 17% 42/243 [00:00<00:03, 59.72it/s]\u001b[A\n"," 20% 48/243 [00:00<00:03, 59.49it/s]\u001b[A\n"," 22% 54/243 [00:00<00:03, 59.34it/s]\u001b[A\n"," 25% 60/243 [00:00<00:03, 59.39it/s]\u001b[A\n"," 27% 66/243 [00:01<00:02, 59.16it/s]\u001b[A\n"," 30% 72/243 [00:01<00:02, 59.31it/s]\u001b[A\n"," 32% 78/243 [00:01<00:02, 59.35it/s]\u001b[A\n"," 35% 84/243 [00:01<00:02, 59.41it/s]\u001b[A\n"," 37% 90/243 [00:01<00:02, 59.51it/s]\u001b[A\n"," 40% 96/243 [00:01<00:02, 59.55it/s]\u001b[A\n"," 42% 102/243 [00:01<00:02, 59.57it/s]\u001b[A\n"," 44% 108/243 [00:01<00:02, 59.41it/s]\u001b[A\n"," 47% 114/243 [00:01<00:02, 59.50it/s]\u001b[A\n"," 49% 120/243 [00:02<00:02, 59.56it/s]\u001b[A\n"," 52% 126/243 [00:02<00:01, 59.39it/s]\u001b[A\n"," 54% 132/243 [00:02<00:01, 59.38it/s]\u001b[A\n"," 57% 138/243 [00:02<00:01, 59.38it/s]\u001b[A\n"," 59% 144/243 [00:02<00:01, 59.23it/s]\u001b[A\n"," 62% 150/243 [00:02<00:01, 59.37it/s]\u001b[A\n"," 64% 156/243 [00:02<00:01, 59.38it/s]\u001b[A\n"," 67% 162/243 [00:02<00:01, 59.46it/s]\u001b[A\n"," 69% 168/243 [00:02<00:01, 59.22it/s]\u001b[A\n"," 72% 174/243 [00:02<00:01, 59.34it/s]\u001b[A\n"," 74% 180/243 [00:03<00:01, 59.38it/s]\u001b[A\n"," 77% 186/243 [00:03<00:00, 59.31it/s]\u001b[A\n"," 79% 192/243 [00:03<00:00, 59.46it/s]\u001b[A\n"," 81% 198/243 [00:03<00:00, 59.47it/s]\u001b[A\n"," 84% 204/243 [00:03<00:00, 59.53it/s]\u001b[A\n"," 86% 210/243 [00:03<00:00, 59.61it/s]\u001b[A\n"," 89% 216/243 [00:03<00:00, 59.65it/s]\u001b[A\n"," 91% 222/243 [00:03<00:00, 59.63it/s]\u001b[A\n"," 94% 228/243 [00:03<00:00, 59.66it/s]\u001b[A\n"," 96% 234/243 [00:03<00:00, 59.59it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 2.0557291507720947, 'eval_accuracy': 0.4781266083376222, 'eval_precision': 0.4768970955117, 'eval_recall': 0.4781266083376222, 'eval_f1': 0.47643734232863555, 'eval_runtime': 4.0959, 'eval_samples_per_second': 474.38, 'eval_steps_per_second': 59.328, 'epoch': 3.0}\n"," 60% 12486/20810 [20:01<13:09, 10.54it/s]\n","100% 243/243 [00:04<00:00, 59.58it/s]\u001b[A\n","{'loss': 0.1852, 'grad_norm': 39.30706787109375, 'learning_rate': 1e-05, 'epoch': 4.0}\n"," 80% 16648/20810 [26:40<06:30, 10.67it/s]\n","  0% 0/243 [00:00<?, ?it/s]\u001b[A\n","  3% 7/243 [00:00<00:03, 69.35it/s]\u001b[A\n","  6% 14/243 [00:00<00:03, 62.98it/s]\u001b[A\n","  9% 21/243 [00:00<00:03, 60.61it/s]\u001b[A\n"," 12% 28/243 [00:00<00:03, 60.01it/s]\u001b[A\n"," 14% 35/243 [00:00<00:03, 59.49it/s]\u001b[A\n"," 17% 41/243 [00:00<00:03, 59.00it/s]\u001b[A\n"," 19% 47/243 [00:00<00:03, 58.82it/s]\u001b[A\n"," 22% 53/243 [00:00<00:03, 58.64it/s]\u001b[A\n"," 24% 59/243 [00:00<00:03, 58.84it/s]\u001b[A\n"," 27% 65/243 [00:01<00:03, 59.03it/s]\u001b[A\n"," 29% 71/243 [00:01<00:02, 58.98it/s]\u001b[A\n"," 32% 77/243 [00:01<00:02, 58.55it/s]\u001b[A\n"," 34% 83/243 [00:01<00:02, 58.08it/s]\u001b[A\n"," 37% 89/243 [00:01<00:02, 58.13it/s]\u001b[A\n"," 39% 95/243 [00:01<00:02, 58.21it/s]\u001b[A\n"," 42% 101/243 [00:01<00:02, 57.86it/s]\u001b[A\n"," 44% 107/243 [00:01<00:02, 57.86it/s]\u001b[A\n"," 47% 113/243 [00:01<00:02, 57.86it/s]\u001b[A\n"," 49% 119/243 [00:02<00:02, 57.44it/s]\u001b[A\n"," 51% 125/243 [00:02<00:02, 57.39it/s]\u001b[A\n"," 54% 131/243 [00:02<00:01, 57.25it/s]\u001b[A\n"," 56% 137/243 [00:02<00:01, 57.23it/s]\u001b[A\n"," 59% 143/243 [00:02<00:01, 57.26it/s]\u001b[A\n"," 61% 149/243 [00:02<00:01, 57.79it/s]\u001b[A\n"," 64% 155/243 [00:02<00:01, 58.12it/s]\u001b[A\n"," 66% 161/243 [00:02<00:01, 58.39it/s]\u001b[A\n"," 69% 167/243 [00:02<00:01, 58.60it/s]\u001b[A\n"," 71% 173/243 [00:02<00:01, 58.82it/s]\u001b[A\n"," 74% 179/243 [00:03<00:01, 58.95it/s]\u001b[A\n"," 76% 185/243 [00:03<00:00, 59.08it/s]\u001b[A\n"," 79% 191/243 [00:03<00:00, 59.18it/s]\u001b[A\n"," 81% 197/243 [00:03<00:00, 59.32it/s]\u001b[A\n"," 84% 203/243 [00:03<00:00, 59.33it/s]\u001b[A\n"," 86% 209/243 [00:03<00:00, 59.44it/s]\u001b[A\n"," 88% 215/243 [00:03<00:00, 59.42it/s]\u001b[A\n"," 91% 221/243 [00:03<00:00, 59.32it/s]\u001b[A\n"," 93% 227/243 [00:03<00:00, 59.22it/s]\u001b[A\n"," 96% 233/243 [00:03<00:00, 59.22it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 2.4856810569763184, 'eval_accuracy': 0.496654657745754, 'eval_precision': 0.4967939934829469, 'eval_recall': 0.496654657745754, 'eval_f1': 0.49669140714225657, 'eval_runtime': 4.153, 'eval_samples_per_second': 467.855, 'eval_steps_per_second': 58.512, 'epoch': 4.0}\n"," 80% 16648/20810 [26:45<06:30, 10.67it/s]\n","100% 243/243 [00:04<00:00, 59.33it/s]\u001b[A\n","{'loss': 0.1185, 'grad_norm': 14.114646911621094, 'learning_rate': 0.0, 'epoch': 5.0}\n","100% 20810/20810 [33:31<00:00, 10.63it/s]\n","  0% 0/243 [00:00<?, ?it/s]\u001b[A\n","  2% 6/243 [00:00<00:04, 56.62it/s]\u001b[A\n","  5% 12/243 [00:00<00:04, 50.52it/s]\u001b[A\n","  7% 18/243 [00:00<00:04, 52.43it/s]\u001b[A\n"," 10% 24/243 [00:00<00:04, 54.35it/s]\u001b[A\n"," 12% 30/243 [00:00<00:03, 55.74it/s]\u001b[A\n"," 15% 36/243 [00:00<00:03, 56.91it/s]\u001b[A\n"," 17% 42/243 [00:00<00:03, 57.72it/s]\u001b[A\n"," 20% 48/243 [00:00<00:03, 58.24it/s]\u001b[A\n"," 22% 54/243 [00:00<00:03, 58.54it/s]\u001b[A\n"," 25% 60/243 [00:01<00:03, 58.77it/s]\u001b[A\n"," 27% 66/243 [00:01<00:03, 58.93it/s]\u001b[A\n"," 30% 72/243 [00:01<00:02, 59.04it/s]\u001b[A\n"," 32% 78/243 [00:01<00:02, 59.10it/s]\u001b[A\n"," 35% 84/243 [00:01<00:02, 59.20it/s]\u001b[A\n"," 37% 90/243 [00:01<00:02, 59.33it/s]\u001b[A\n"," 40% 96/243 [00:01<00:02, 59.30it/s]\u001b[A\n"," 42% 102/243 [00:01<00:02, 59.40it/s]\u001b[A\n"," 44% 108/243 [00:01<00:02, 59.47it/s]\u001b[A\n"," 47% 114/243 [00:01<00:02, 59.44it/s]\u001b[A\n"," 49% 120/243 [00:02<00:02, 59.36it/s]\u001b[A\n"," 52% 126/243 [00:02<00:01, 59.31it/s]\u001b[A\n"," 54% 132/243 [00:02<00:01, 59.16it/s]\u001b[A\n"," 57% 138/243 [00:02<00:01, 59.23it/s]\u001b[A\n"," 59% 144/243 [00:02<00:01, 59.34it/s]\u001b[A\n"," 62% 150/243 [00:02<00:01, 59.30it/s]\u001b[A\n"," 64% 156/243 [00:02<00:01, 59.31it/s]\u001b[A\n"," 67% 162/243 [00:02<00:01, 59.34it/s]\u001b[A\n"," 69% 168/243 [00:02<00:01, 59.37it/s]\u001b[A\n"," 72% 174/243 [00:02<00:01, 59.45it/s]\u001b[A\n"," 74% 180/243 [00:03<00:01, 59.49it/s]\u001b[A\n"," 77% 186/243 [00:03<00:00, 59.36it/s]\u001b[A\n"," 79% 192/243 [00:03<00:00, 59.46it/s]\u001b[A\n"," 81% 198/243 [00:03<00:00, 59.52it/s]\u001b[A\n"," 84% 204/243 [00:03<00:00, 59.48it/s]\u001b[A\n"," 86% 210/243 [00:03<00:00, 59.51it/s]\u001b[A\n"," 89% 216/243 [00:03<00:00, 59.41it/s]\u001b[A\n"," 91% 222/243 [00:03<00:00, 59.36it/s]\u001b[A\n"," 94% 228/243 [00:03<00:00, 59.39it/s]\u001b[A\n"," 96% 234/243 [00:03<00:00, 59.44it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 2.9912939071655273, 'eval_accuracy': 0.4997426659804426, 'eval_precision': 0.4988873184552375, 'eval_recall': 0.4997426659804426, 'eval_f1': 0.4983243280169643, 'eval_runtime': 4.1642, 'eval_samples_per_second': 466.594, 'eval_steps_per_second': 58.354, 'epoch': 5.0}\n","100% 20810/20810 [33:35<00:00, 10.63it/s]\n","100% 243/243 [00:04<00:00, 59.21it/s]\u001b[A\n","{'train_runtime': 2021.9792, 'train_samples_per_second': 164.668, 'train_steps_per_second': 10.292, 'train_loss': 0.3403998313071578, 'epoch': 5.0}\n","100% 20810/20810 [33:41<00:00, 10.29it/s]\n","100% 243/243 [00:04<00:00, 57.60it/s]\n","Evaluation results:\n","{'eval_loss': 2.9912939071655273, 'eval_accuracy': 0.4997426659804426, 'eval_precision': 0.4988873184552375, 'eval_recall': 0.4997426659804426, 'eval_f1': 0.4983243280169643, 'eval_runtime': 4.2374, 'eval_samples_per_second': 458.537, 'eval_steps_per_second': 57.347, 'epoch': 5.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/7dpa1010\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_224535-7dpa1010/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/comb/checkpoint-20810 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./final_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_comb/comb_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-lIVYeWsDlp","executionInfo":{"status":"ok","timestamp":1733268475962,"user_tz":360,"elapsed":65827,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"166b6a5c-9b63-4e84-e924-d9b285f73128"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 23:26:54.546468: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 23:26:54.563603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 23:26:54.584890: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 23:26:54.591499: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 23:26:54.606901: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 23:26:55.696230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_232658-8bd1r8be\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/8bd1r8be\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6881/6881 [00:01<00:00, 3934.57 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6881/6881 [00:01<00:00, 6113.57 examples/s]\n","Filter: 100% 6881/6881 [00:01<00:00, 6196.83 examples/s]\n","\n","Evaluation on English test set:\n"," 99% 426/430 [00:07<00:00, 59.03it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 430/430 [00:07<00:00, 58.87it/s]\n","{'eval_loss': 3.517791986465454, 'eval_model_preparation_time': 0.004, 'eval_accuracy': 0.426453488372093, 'eval_precision': 0.4266811298362524, 'eval_recall': 0.426453488372093, 'eval_f1': 0.4228680853528332, 'eval_runtime': 8.0034, 'eval_samples_per_second': 429.82, 'eval_steps_per_second': 53.727}\n","\n","Evaluation on Russian test set:\n","100% 431/431 [00:07<00:00, 59.51it/s]\n","{'eval_loss': 3.4155173301696777, 'eval_model_preparation_time': 0.004, 'eval_accuracy': 0.4216797442603894, 'eval_precision': 0.42339163142887143, 'eval_recall': 0.4216797442603894, 'eval_f1': 0.41884637517147766, 'eval_runtime': 7.259, 'eval_samples_per_second': 474.032, 'eval_steps_per_second': 59.374}\n","\n","Evaluation on the entire test set:\n","100% 861/861 [00:14<00:00, 60.19it/s]\n","{'eval_loss': 3.466646909713745, 'eval_model_preparation_time': 0.004, 'eval_accuracy': 0.42406626943758174, 'eval_precision': 0.42501365024514703, 'eval_recall': 0.42406626943758174, 'eval_f1': 0.4208674474869984, 'eval_runtime': 14.3197, 'eval_samples_per_second': 480.528, 'eval_steps_per_second': 60.127}\n","100% 430/430 [00:07<00:00, 59.38it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb/comb_final/misclassified_English.jsonl\n","100% 431/431 [00:07<00:00, 59.86it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb/comb_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/8bd1r8be\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_232658-8bd1r8be/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/comb/checkpoint-20810 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_comb/anli_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axirwIdBygvC","executionInfo":{"status":"ok","timestamp":1733268537070,"user_tz":360,"elapsed":61117,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"7addc11d-f23d-4fe4-af04-1756a2aaae90"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 23:28:00.091786: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 23:28:00.108414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 23:28:00.129409: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 23:28:00.135774: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 23:28:00.150835: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 23:28:01.225449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_232803-jpbv7ayy\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/jpbv7ayy\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6400/6400 [00:01<00:00, 3854.16 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6400/6400 [00:01<00:00, 5832.64 examples/s]\n","Filter: 100% 6400/6400 [00:01<00:00, 5907.81 examples/s]\n","\n","Evaluation on English test set:\n"," 99% 396/400 [00:06<00:00, 59.28it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 400/400 [00:06<00:00, 58.95it/s]\n","{'eval_loss': 3.6209545135498047, 'eval_model_preparation_time': 0.0047, 'eval_accuracy': 0.411875, 'eval_precision': 0.40997101898977933, 'eval_recall': 0.411875, 'eval_f1': 0.4071522829005939, 'eval_runtime': 7.398, 'eval_samples_per_second': 432.548, 'eval_steps_per_second': 54.068}\n","\n","Evaluation on Russian test set:\n","100% 400/400 [00:06<00:00, 58.97it/s]\n","{'eval_loss': 3.4971861839294434, 'eval_model_preparation_time': 0.0047, 'eval_accuracy': 0.4103125, 'eval_precision': 0.4093919995977582, 'eval_recall': 0.4103125, 'eval_f1': 0.4057236319239963, 'eval_runtime': 6.799, 'eval_samples_per_second': 470.66, 'eval_steps_per_second': 58.833}\n","\n","Evaluation on the entire test set:\n","100% 800/800 [00:13<00:00, 59.49it/s]\n","{'eval_loss': 3.559070348739624, 'eval_model_preparation_time': 0.0047, 'eval_accuracy': 0.41109375, 'eval_precision': 0.4096701407913569, 'eval_recall': 0.41109375, 'eval_f1': 0.40643509373538805, 'eval_runtime': 13.4655, 'eval_samples_per_second': 475.289, 'eval_steps_per_second': 59.411}\n","100% 400/400 [00:06<00:00, 59.47it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb/anli_final/misclassified_English.jsonl\n","100% 400/400 [00:06<00:00, 59.66it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb/anli_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/jpbv7ayy\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_232803-jpbv7ayy/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/comb/checkpoint-20810 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./metaphor_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_comb/metaphor_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"riDl4X2Myg-w","executionInfo":{"status":"ok","timestamp":1733268556133,"user_tz":360,"elapsed":19066,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"e0ddd1f9-de9e-4360-e993-78f57c390ea3"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 23:29:01.287485: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 23:29:01.304590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 23:29:01.325877: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 23:29:01.332261: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 23:29:01.347904: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 23:29:02.419315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_232904-ifd2iptp\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/ifd2iptp\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 481/481 [00:00<00:00, 991.84 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 481/481 [00:00<00:00, 5458.17 examples/s]\n","Filter: 100% 481/481 [00:00<00:00, 5916.39 examples/s]\n","\n","Evaluation on English test set:\n","100% 30/30 [00:00<00:00, 58.63it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 30/30 [00:00<00:00, 53.95it/s]\n","{'eval_loss': 2.1422910690307617, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.6208333333333333, 'eval_precision': 0.6344475446428571, 'eval_recall': 0.6208333333333333, 'eval_f1': 0.617219109645589, 'eval_runtime': 1.167, 'eval_samples_per_second': 205.653, 'eval_steps_per_second': 25.707}\n","\n","Evaluation on Russian test set:\n","100% 31/31 [00:00<00:00, 61.52it/s]\n","{'eval_loss': 2.331113338470459, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.5726141078838174, 'eval_precision': 0.5786020308335863, 'eval_recall': 0.5726141078838174, 'eval_f1': 0.5735547462073252, 'eval_runtime': 0.5209, 'eval_samples_per_second': 462.695, 'eval_steps_per_second': 59.517}\n","\n","Evaluation on the entire test set:\n","100% 61/61 [00:01<00:00, 60.24it/s]\n","{'eval_loss': 2.23689866065979, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.5966735966735967, 'eval_precision': 0.5969473149864741, 'eval_recall': 0.5966735966735967, 'eval_f1': 0.5961363297450847, 'eval_runtime': 1.0298, 'eval_samples_per_second': 467.079, 'eval_steps_per_second': 59.235}\n","100% 30/30 [00:00<00:00, 61.63it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb/metaphor_final/misclassified_English.jsonl\n","100% 31/31 [00:00<00:00, 62.56it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb/metaphor_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/ifd2iptp\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_232904-ifd2iptp/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_xnli_en_ru_bert_2/checkpoint-196352 \\\n","    --task nli \\\n","    --dataset final_train_2.jsonl \\\n","    --do_train \\\n","    --do_eval \\\n","    --per_device_train_batch_size 16 \\\n","    --num_train_epochs 1 \\\n","    --evaluation_strategy='epoch' \\\n","    --logging_strategy='epoch' \\\n","    --save_strategy='epoch' \\\n","    --output_dir ./output_metaphor_anli_final/comb_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QlEFjdFQ0QQ_","executionInfo":{"status":"ok","timestamp":1733269175407,"user_tz":360,"elapsed":486123,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"13a51826-d477-42a8-b031-b65cfe210969"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 23:31:33.654080: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 23:31:33.671069: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 23:31:33.692299: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 23:31:33.698879: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 23:31:33.714136: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 23:31:34.785640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_233137-ayqfq88v\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/ayqfq88v\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 76224 examples [00:00, 116843.25 examples/s]\n","Filter: 100% 76224/76224 [00:00<00:00, 128141.45 examples/s]\n","Filter: 100% 76224/76224 [00:00<00:00, 137716.25 examples/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Training dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 70914/70914 [00:14<00:00, 4789.78 examples/s]\n","Validation dataset columns before mapping: ['premise', 'hypothesis', 'label', 'language', 'split']\n","Map (num_proc=2): 100% 3386/3386 [00:01<00:00, 3364.48 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","{'loss': 0.6426, 'grad_norm': 14.095735549926758, 'learning_rate': 0.0, 'epoch': 1.0}\n","100% 4433/4433 [07:05<00:00, 11.27it/s]\n","  0% 0/424 [00:00<?, ?it/s]\u001b[A\n","  1% 6/424 [00:00<00:07, 57.10it/s]\u001b[A\n","  3% 12/424 [00:00<00:07, 52.34it/s]\u001b[A\n","  4% 18/424 [00:00<00:07, 55.35it/s]\u001b[A\n","  6% 24/424 [00:00<00:07, 56.76it/s]\u001b[A\n","  7% 30/424 [00:00<00:06, 56.80it/s]\u001b[A\n","  8% 36/424 [00:00<00:06, 57.27it/s]\u001b[A\n"," 10% 42/424 [00:00<00:06, 57.68it/s]\u001b[A\n"," 11% 48/424 [00:00<00:06, 58.10it/s]\u001b[A\n"," 13% 54/424 [00:00<00:06, 58.21it/s]\u001b[A\n"," 14% 60/424 [00:01<00:06, 58.47it/s]\u001b[A\n"," 16% 66/424 [00:01<00:06, 58.51it/s]\u001b[A\n"," 17% 72/424 [00:01<00:06, 58.31it/s]\u001b[A\n"," 18% 78/424 [00:01<00:05, 58.41it/s]\u001b[A\n"," 20% 84/424 [00:01<00:05, 58.54it/s]\u001b[A\n"," 21% 90/424 [00:01<00:05, 58.65it/s]\u001b[A\n"," 23% 96/424 [00:01<00:05, 58.62it/s]\u001b[A\n"," 24% 102/424 [00:01<00:05, 58.46it/s]\u001b[A\n"," 25% 108/424 [00:01<00:05, 58.62it/s]\u001b[A\n"," 27% 114/424 [00:01<00:05, 58.24it/s]\u001b[A\n"," 28% 120/424 [00:02<00:05, 58.53it/s]\u001b[A\n"," 30% 126/424 [00:02<00:05, 58.59it/s]\u001b[A\n"," 31% 132/424 [00:02<00:04, 58.88it/s]\u001b[A\n"," 33% 138/424 [00:02<00:04, 58.89it/s]\u001b[A\n"," 34% 144/424 [00:02<00:04, 58.30it/s]\u001b[A\n"," 35% 150/424 [00:02<00:04, 58.44it/s]\u001b[A\n"," 37% 156/424 [00:02<00:04, 58.54it/s]\u001b[A\n"," 38% 162/424 [00:02<00:04, 58.80it/s]\u001b[A\n"," 40% 168/424 [00:02<00:04, 58.97it/s]\u001b[A\n"," 41% 174/424 [00:02<00:04, 59.09it/s]\u001b[A\n"," 42% 180/424 [00:03<00:04, 58.90it/s]\u001b[A\n"," 44% 186/424 [00:03<00:04, 58.77it/s]\u001b[A\n"," 45% 192/424 [00:03<00:03, 58.65it/s]\u001b[A\n"," 47% 198/424 [00:03<00:03, 58.85it/s]\u001b[A\n"," 48% 204/424 [00:03<00:03, 59.16it/s]\u001b[A\n"," 50% 210/424 [00:03<00:03, 59.29it/s]\u001b[A\n"," 51% 216/424 [00:03<00:03, 59.42it/s]\u001b[A\n"," 52% 222/424 [00:03<00:03, 59.38it/s]\u001b[A\n"," 54% 228/424 [00:03<00:03, 59.47it/s]\u001b[A\n"," 55% 234/424 [00:04<00:03, 59.52it/s]\u001b[A\n"," 57% 240/424 [00:04<00:03, 59.57it/s]\u001b[A\n"," 58% 246/424 [00:04<00:02, 59.66it/s]\u001b[A\n"," 59% 252/424 [00:04<00:02, 59.50it/s]\u001b[A\n"," 61% 258/424 [00:04<00:02, 59.29it/s]\u001b[A\n"," 62% 264/424 [00:04<00:02, 59.08it/s]\u001b[A\n"," 64% 270/424 [00:04<00:02, 59.17it/s]\u001b[A\n","100% 4433/4433 [07:09<00:00, 11.27it/s]\n"," 67% 282/424 [00:04<00:02, 59.35it/s]\u001b[A\n"," 68% 288/424 [00:04<00:02, 59.42it/s]\u001b[A\n"," 69% 294/424 [00:05<00:02, 59.45it/s]\u001b[A\n"," 71% 300/424 [00:05<00:02, 59.46it/s]\u001b[A\n"," 72% 306/424 [00:05<00:01, 59.48it/s]\u001b[A\n"," 74% 312/424 [00:05<00:01, 59.55it/s]\u001b[A\n"," 75% 318/424 [00:05<00:01, 59.56it/s]\u001b[A\n"," 76% 324/424 [00:05<00:01, 59.58it/s]\u001b[A\n"," 78% 330/424 [00:05<00:01, 59.43it/s]\u001b[A\n"," 79% 336/424 [00:05<00:01, 59.45it/s]\u001b[A\n"," 81% 342/424 [00:05<00:01, 59.37it/s]\u001b[A\n"," 82% 348/424 [00:05<00:01, 59.45it/s]\u001b[A\n"," 83% 354/424 [00:06<00:01, 59.32it/s]\u001b[A\n"," 85% 360/424 [00:06<00:01, 58.59it/s]\u001b[A\n"," 86% 366/424 [00:06<00:00, 58.85it/s]\u001b[A\n"," 88% 372/424 [00:06<00:00, 58.42it/s]\u001b[A\n"," 89% 378/424 [00:06<00:00, 57.90it/s]\u001b[A\n"," 91% 384/424 [00:06<00:00, 56.91it/s]\u001b[A\n"," 92% 390/424 [00:06<00:00, 57.15it/s]\u001b[A\n"," 93% 396/424 [00:06<00:00, 57.80it/s]\u001b[A\n"," 95% 402/424 [00:06<00:00, 57.06it/s]\u001b[A\n"," 96% 408/424 [00:06<00:00, 57.37it/s]\u001b[A\n"," 98% 414/424 [00:07<00:00, 56.88it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 1.0996370315551758, 'eval_accuracy': 0.5587714116952156, 'eval_precision': 0.561997078902243, 'eval_recall': 0.5587714116952156, 'eval_f1': 0.5599433833691887, 'eval_runtime': 7.2745, 'eval_samples_per_second': 465.459, 'eval_steps_per_second': 58.285, 'epoch': 1.0}\n","100% 4433/4433 [07:12<00:00, 11.27it/s]\n","100% 424/424 [00:07<00:00, 56.51it/s]\u001b[A\n","{'train_runtime': 440.5743, 'train_samples_per_second': 160.958, 'train_steps_per_second': 10.062, 'train_loss': 0.6426341347035022, 'epoch': 1.0}\n","100% 4433/4433 [07:20<00:00, 10.06it/s]\n","100% 424/424 [00:07<00:00, 57.22it/s]\n","Evaluation results:\n","{'eval_loss': 1.0996370315551758, 'eval_accuracy': 0.5587714116952156, 'eval_precision': 0.561997078902243, 'eval_recall': 0.5587714116952156, 'eval_f1': 0.5599433833691887, 'eval_runtime': 7.4296, 'eval_samples_per_second': 455.742, 'eval_steps_per_second': 57.069, 'epoch': 1.0}\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/ayqfq88v\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_233137-ayqfq88v/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/comb_2/checkpoint-4433 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./metaphor_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_comb_2/metaphor_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8DjsPBp33VD_","executionInfo":{"status":"ok","timestamp":1733269197648,"user_tz":360,"elapsed":22043,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"0d681276-2a2e-4488-8cf0-6e7c30011337"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 23:39:40.097370: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 23:39:40.115589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 23:39:40.138531: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 23:39:40.144998: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 23:39:40.162947: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 23:39:41.317353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_233944-h3vbl4xt\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/h3vbl4xt\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 481/481 [00:00<00:00, 954.88 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 481/481 [00:00<00:00, 4888.24 examples/s]\n","Filter: 100% 481/481 [00:00<00:00, 4977.27 examples/s]\n","\n","Evaluation on English test set:\n","100% 30/30 [00:00<00:00, 58.57it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 30/30 [00:00<00:00, 55.01it/s]\n","{'eval_loss': 0.8373251557350159, 'eval_model_preparation_time': 0.0054, 'eval_accuracy': 0.7, 'eval_precision': 0.7073490070302973, 'eval_recall': 0.7, 'eval_f1': 0.6980015072955759, 'eval_runtime': 1.372, 'eval_samples_per_second': 174.927, 'eval_steps_per_second': 21.866}\n","\n","Evaluation on Russian test set:\n","100% 31/31 [00:00<00:00, 59.46it/s]\n","{'eval_loss': 0.968772828578949, 'eval_model_preparation_time': 0.0054, 'eval_accuracy': 0.5684647302904564, 'eval_precision': 0.5764836754749946, 'eval_recall': 0.5684647302904564, 'eval_f1': 0.5720616395772522, 'eval_runtime': 0.5382, 'eval_samples_per_second': 447.756, 'eval_steps_per_second': 57.595}\n","\n","Evaluation on the entire test set:\n","100% 61/61 [00:01<00:00, 60.86it/s]\n","{'eval_loss': 0.9031856656074524, 'eval_model_preparation_time': 0.0054, 'eval_accuracy': 0.6340956340956341, 'eval_precision': 0.6355586355586356, 'eval_recall': 0.6340956340956341, 'eval_f1': 0.6334305082908435, 'eval_runtime': 1.0182, 'eval_samples_per_second': 472.418, 'eval_steps_per_second': 59.912}\n","100% 30/30 [00:00<00:00, 61.29it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb_2/metaphor_final/misclassified_English.jsonl\n","100% 31/31 [00:00<00:00, 60.52it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb_2/metaphor_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/h3vbl4xt\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_233944-h3vbl4xt/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/comb_2/checkpoint-4433 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./anli_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_comb_2/anli_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cs9WZHcv4HWs","executionInfo":{"status":"ok","timestamp":1733269259480,"user_tz":360,"elapsed":61834,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"2097cf73-c2c6-4d35-cea2-3a21aa4a8961"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 23:40:01.845322: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 23:40:01.861651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 23:40:01.882847: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 23:40:01.889253: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 23:40:01.904143: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 23:40:02.978569: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_234005-amb4knkl\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/amb4knkl\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6400/6400 [00:01<00:00, 3882.59 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6400/6400 [00:01<00:00, 5963.93 examples/s]\n","Filter: 100% 6400/6400 [00:01<00:00, 5963.50 examples/s]\n","\n","Evaluation on English test set:\n"," 99% 396/400 [00:06<00:00, 59.40it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 400/400 [00:06<00:00, 58.31it/s]\n","{'eval_loss': 1.445540189743042, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.410625, 'eval_precision': 0.41027916145433374, 'eval_recall': 0.410625, 'eval_f1': 0.40061705277586546, 'eval_runtime': 7.4759, 'eval_samples_per_second': 428.042, 'eval_steps_per_second': 53.505}\n","\n","Evaluation on Russian test set:\n","100% 400/400 [00:06<00:00, 59.12it/s]\n","{'eval_loss': 1.3845398426055908, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.4065625, 'eval_precision': 0.40489644888199694, 'eval_recall': 0.4065625, 'eval_f1': 0.3954471963930385, 'eval_runtime': 6.785, 'eval_samples_per_second': 471.63, 'eval_steps_per_second': 58.954}\n","\n","Evaluation on the entire test set:\n","100% 800/800 [00:13<00:00, 59.57it/s]\n","{'eval_loss': 1.415040135383606, 'eval_model_preparation_time': 0.0034, 'eval_accuracy': 0.40859375, 'eval_precision': 0.407610398959141, 'eval_recall': 0.40859375, 'eval_f1': 0.3980475638204045, 'eval_runtime': 13.4448, 'eval_samples_per_second': 476.022, 'eval_steps_per_second': 59.503}\n","100% 400/400 [00:06<00:00, 59.36it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb_2/anli_final/misclassified_English.jsonl\n","100% 400/400 [00:06<00:00, 59.74it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb_2/anli_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/amb4knkl\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_234005-amb4knkl/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/comb_2/checkpoint-4433 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --predict_file ./final_test.jsonl \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_comb_2/comb_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yglq0ucJ4MOZ","executionInfo":{"status":"ok","timestamp":1733269323638,"user_tz":360,"elapsed":64160,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"7aaf4e1d-2003-4fb2-b764-b0b142725834"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-03 23:41:03.736379: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-12-03 23:41:03.753626: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-03 23:41:03.775047: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-03 23:41:03.781553: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-03 23:41:03.797522: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-03 23:41:04.887160: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlizardp1\u001b[0m (\u001b[33mlizardp1-the-university-of-texas-at-austin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/nlp_final_project/wandb/run-20241203_234107-vzipbkkl\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-r1-anli\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/vzipbkkl\u001b[0m\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 6881/6881 [00:01<00:00, 3999.49 examples/s]\n","/content/drive/MyDrive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 6881/6881 [00:01<00:00, 6259.69 examples/s]\n","Filter: 100% 6881/6881 [00:01<00:00, 6234.60 examples/s]\n","\n","Evaluation on English test set:\n","100% 428/430 [00:07<00:00, 59.52it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 430/430 [00:07<00:00, 58.92it/s]\n","{'eval_loss': 1.4031065702438354, 'eval_model_preparation_time': 0.0046, 'eval_accuracy': 0.4308139534883721, 'eval_precision': 0.43375709387129147, 'eval_recall': 0.4308139534883721, 'eval_f1': 0.4234335947540065, 'eval_runtime': 8.0577, 'eval_samples_per_second': 426.921, 'eval_steps_per_second': 53.365}\n","\n","Evaluation on Russian test set:\n","100% 431/431 [00:07<00:00, 59.83it/s]\n","{'eval_loss': 1.355420470237732, 'eval_model_preparation_time': 0.0046, 'eval_accuracy': 0.4179017727404824, 'eval_precision': 0.42277593281798015, 'eval_recall': 0.4179017727404824, 'eval_f1': 0.41054712479748334, 'eval_runtime': 7.2192, 'eval_samples_per_second': 476.649, 'eval_steps_per_second': 59.702}\n","\n","Evaluation on the entire test set:\n","100% 861/861 [00:14<00:00, 59.76it/s]\n","{'eval_loss': 1.3792600631713867, 'eval_model_preparation_time': 0.0046, 'eval_accuracy': 0.42435692486557186, 'eval_precision': 0.42825369768688953, 'eval_recall': 0.42435692486557186, 'eval_f1': 0.41699698277356434, 'eval_runtime': 14.4225, 'eval_samples_per_second': 477.103, 'eval_steps_per_second': 59.699}\n","100% 430/430 [00:07<00:00, 59.15it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb_2/comb_final/misclassified_English.jsonl\n","100% 431/431 [00:07<00:00, 59.93it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb_2/comb_final/misclassified_Russian.jsonl\n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mfinetune-r1-anli\u001b[0m at: \u001b[34mhttps://wandb.ai/lizardp1-the-university-of-texas-at-austin/xnli_nli_project/runs/vzipbkkl\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_234107-vzipbkkl/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/comb_2/checkpoint-4433 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_comb_2/xnli"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-0CPstL5Lej","executionInfo":{"status":"ok","timestamp":1733283154942,"user_tz":360,"elapsed":3262827,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"eac3d0de-a461-445b-d07d-ba649a1d13d5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-04 02:38:24.110428: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-04 02:38:24.125010: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-04 02:38:24.129064: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-04 02:38:24.140546: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-04 02:38:25.327036: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","README.md: 100% 20.8k/20.8k [00:00<00:00, 59.8MB/s]\n","train-00000-of-00001.parquet: 100% 50.2M/50.2M [00:00<00:00, 181MB/s]\n","test-00000-of-00001.parquet: 100% 308k/308k [00:00<00:00, 501MB/s]\n","validation-00000-of-00001.parquet: 100% 157k/157k [00:00<00:00, 296MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 718232.70 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 603280.40 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 666229.71 examples/s]\n","train-00000-of-00001.parquet: 100% 70.0M/70.0M [00:01<00:00, 58.5MB/s]\n","test-00000-of-00001.parquet: 100% 477k/477k [00:00<00:00, 374MB/s]\n","validation-00000-of-00001.parquet: 100% 239k/239k [00:00<00:00, 426MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 593435.89 examples/s]\n","Generating test split: 100% 5010/5010 [00:00<00:00, 729102.50 examples/s]\n","Generating validation split: 100% 2490/2490 [00:00<00:00, 657836.80 examples/s]\n","Map: 100% 392702/392702 [00:13<00:00, 29858.87 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 35697.24 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 37050.18 examples/s]\n","Map: 100% 392702/392702 [00:12<00:00, 30541.45 examples/s]\n","Map: 100% 5010/5010 [00:00<00:00, 36226.61 examples/s]\n","Map: 100% 2490/2490 [00:00<00:00, 38207.74 examples/s]\n","tokenizer_config.json: 100% 49.0/49.0 [00:00<00:00, 260kB/s]\n","config.json: 100% 625/625 [00:00<00:00, 4.88MB/s]\n","vocab.txt: 100% 996k/996k [00:00<00:00, 3.94MB/s]\n","tokenizer.json: 100% 1.96M/1.96M [00:00<00:00, 5.66MB/s]\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 8064.94 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7734.31 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7833.91 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [09:08<00:00,  1.50it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [09:08<00:00,  1.14it/s]\n","{'eval_loss': 0.6256558299064636, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.7628742514970059, 'eval_precision': 0.7693383535747274, 'eval_recall': 0.7628742514970059, 'eval_f1': 0.7639593619143134, 'eval_runtime': 551.8545, 'eval_samples_per_second': 9.078, 'eval_steps_per_second': 1.136}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [08:51<00:00,  1.18it/s]\n","{'eval_loss': 0.7857128381729126, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.6874251497005988, 'eval_precision': 0.6979752756387696, 'eval_recall': 0.6874251497005988, 'eval_f1': 0.6884590992848714, 'eval_runtime': 532.7643, 'eval_samples_per_second': 9.404, 'eval_steps_per_second': 1.177}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [17:30<00:00,  1.19it/s]\n","{'eval_loss': 0.7056843638420105, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.7251497005988023, 'eval_precision': 0.7337039739198377, 'eval_recall': 0.7251497005988023, 'eval_f1': 0.7262882492167388, 'eval_runtime': 1051.5932, 'eval_samples_per_second': 9.528, 'eval_steps_per_second': 1.192}\n","100% 627/627 [08:44<00:00,  1.20it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb_2/xnli/misclassified_English.jsonl\n","100% 627/627 [08:45<00:00,  1.19it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb_2/xnli/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/comb/checkpoint-4162 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_comb/xnli"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5YQGbzPuhseY","executionInfo":{"status":"ok","timestamp":1733286372913,"user_tz":360,"elapsed":3217981,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"881fa132-954a-49ba-c36e-81fdc086794c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-04 03:32:38.190140: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-04 03:32:38.203911: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-04 03:32:38.207966: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-04 03:32:38.218042: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-04 03:32:39.170107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 7933.27 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7944.71 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7965.56 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [08:10<00:00,  1.65it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [08:10<00:00,  1.28it/s]\n","{'eval_loss': 0.6460446119308472, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.7409181636726547, 'eval_precision': 0.7470671027751017, 'eval_recall': 0.7409181636726547, 'eval_f1': 0.741986169602037, 'eval_runtime': 493.7642, 'eval_samples_per_second': 10.147, 'eval_steps_per_second': 1.27}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [08:04<00:00,  1.29it/s]\n","{'eval_loss': 0.7692484259605408, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.6668662674650698, 'eval_precision': 0.6755762136364013, 'eval_recall': 0.6668662674650698, 'eval_f1': 0.6678244394341527, 'eval_runtime': 485.5903, 'eval_samples_per_second': 10.317, 'eval_steps_per_second': 1.291}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [18:47<00:00,  1.11it/s]\n","{'eval_loss': 0.7076465487480164, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.7038922155688623, 'eval_precision': 0.7113934550682937, 'eval_recall': 0.7038922155688623, 'eval_f1': 0.7049631026052539, 'eval_runtime': 1127.9049, 'eval_samples_per_second': 8.884, 'eval_steps_per_second': 1.111}\n","100% 627/627 [08:54<00:00,  1.17it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb/xnli/misclassified_English.jsonl\n","100% 627/627 [09:07<00:00,  1.14it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_comb/xnli/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation_attribution_overlap/checkpoint-199 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/xnli"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pkFi9ZBOi-9y","executionInfo":{"status":"ok","timestamp":1733289808684,"user_tz":360,"elapsed":3434344,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"c1933ca4-a578-456f-d029-a6f5aeb0e7ce"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-04 04:26:17.370405: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-04 04:26:17.384441: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-04 04:26:17.388364: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-04 04:26:17.398137: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-04 04:26:18.362625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 8135.19 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 8076.15 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7610.03 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [08:55<00:00,  1.60it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [08:55<00:00,  1.17it/s]\n","{'eval_loss': 0.7380754351615906, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.7149700598802395, 'eval_precision': 0.7340107977959479, 'eval_recall': 0.7149700598802395, 'eval_f1': 0.7153136902317195, 'eval_runtime': 537.7671, 'eval_samples_per_second': 9.316, 'eval_steps_per_second': 1.166}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [09:28<00:00,  1.10it/s]\n","{'eval_loss': 0.9229931831359863, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.6269461077844312, 'eval_precision': 0.6586307193867006, 'eval_recall': 0.6269461077844312, 'eval_f1': 0.6218427138631506, 'eval_runtime': 569.4433, 'eval_samples_per_second': 8.798, 'eval_steps_per_second': 1.101}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [17:54<00:00,  1.17it/s]\n","{'eval_loss': 0.8305342197418213, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.6709580838323354, 'eval_precision': 0.6968118190605531, 'eval_recall': 0.6709580838323354, 'eval_f1': 0.6693202834758938, 'eval_runtime': 1075.8712, 'eval_samples_per_second': 9.313, 'eval_steps_per_second': 1.165}\n","100% 627/627 [10:37<00:00,  1.02s/it]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/xnli/misclassified_English.jsonl\n","100% 627/627 [09:48<00:00,  1.07it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_overlap_model_testing/xnli/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation_attribution/checkpoint-1756 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/xnli"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLE_yVzVjGww","executionInfo":{"status":"ok","timestamp":1733293219930,"user_tz":360,"elapsed":3411257,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"aa8b0355-8b84-49a5-8fe4-13be81235010"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-04 05:23:32.229892: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-04 05:23:32.245264: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-04 05:23:32.249616: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-04 05:23:32.262422: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-04 05:23:33.210867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 8069.39 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7783.87 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7826.23 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [08:31<00:00,  1.59it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [08:31<00:00,  1.23it/s]\n","{'eval_loss': 0.7468556761741638, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.6978043912175649, 'eval_precision': 0.7269768760886339, 'eval_recall': 0.6978043912175649, 'eval_f1': 0.6993910244810518, 'eval_runtime': 516.0645, 'eval_samples_per_second': 9.708, 'eval_steps_per_second': 1.215}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [08:23<00:00,  1.24it/s]\n","{'eval_loss': 0.9042216539382935, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.6183632734530938, 'eval_precision': 0.6549352262518859, 'eval_recall': 0.6183632734530938, 'eval_f1': 0.6173968001686457, 'eval_runtime': 504.7276, 'eval_samples_per_second': 9.926, 'eval_steps_per_second': 1.242}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [17:23<00:00,  1.20it/s]\n","{'eval_loss': 0.8255387544631958, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.6580838323353293, 'eval_precision': 0.6913323652524206, 'eval_recall': 0.6580838323353293, 'eval_f1': 0.6586530981934043, 'eval_runtime': 1044.5331, 'eval_samples_per_second': 9.593, 'eval_steps_per_second': 1.2}\n","100% 627/627 [10:40<00:00,  1.02s/it]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/xnli/misclassified_English.jsonl\n","100% 627/627 [11:16<00:00,  1.08s/it]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_attribution_model_testing/xnli/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor_negation/checkpoint-2118 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/xnli"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2K0qEHcdjX9I","executionInfo":{"status":"ok","timestamp":1733296672893,"user_tz":360,"elapsed":3452968,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"16abb3ea-ca26-4b99-9e22-99fcfbda9b6b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-04 06:20:23.853163: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-04 06:20:23.868145: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-04 06:20:23.872329: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-04 06:20:23.884753: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-04 06:20:24.824749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Using the latest cached version of the dataset since facebook/xnli couldn't be found on the Hugging Face Hub\n","Found the latest cached dataset configuration 'en' at /root/.cache/huggingface/datasets/facebook___xnli/en/0.0.0/b8dd5d7af51114dbda02c0e3f6133f332186418e (last modified on Wed Dec  4 05:23:51 2024).\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 7723.29 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7743.41 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7857.58 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [09:10<00:00,  1.64it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [09:10<00:00,  1.14it/s]\n","{'eval_loss': 0.633558452129364, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.7439121756487026, 'eval_precision': 0.7453251810628859, 'eval_recall': 0.7439121756487026, 'eval_f1': 0.7436238008720282, 'eval_runtime': 554.6873, 'eval_samples_per_second': 9.032, 'eval_steps_per_second': 1.13}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [10:00<00:00,  1.04it/s]\n","{'eval_loss': 0.7750473618507385, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.6614770459081837, 'eval_precision': 0.6637899262866269, 'eval_recall': 0.6614770459081837, 'eval_f1': 0.6612277779738636, 'eval_runtime': 601.1996, 'eval_samples_per_second': 8.333, 'eval_steps_per_second': 1.043}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [18:18<00:00,  1.14it/s]\n","{'eval_loss': 0.7043029069900513, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.7026946107784431, 'eval_precision': 0.7044729165252519, 'eval_recall': 0.7026946107784431, 'eval_f1': 0.7024264423882075, 'eval_runtime': 1099.4686, 'eval_samples_per_second': 9.113, 'eval_steps_per_second': 1.14}\n","100% 627/627 [10:26<00:00,  1.00it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/xnli/misclassified_English.jsonl\n","100% 627/627 [09:01<00:00,  1.16it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_negation_model_testing/xnli/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":["!python3 run.py \\\n","    --model ./output_metaphor_anli_final/metaphor/checkpoint-273 \\\n","    --task nli \\\n","    --dataset facebook/xnli \\\n","    --do_predict \\\n","    --output_dir ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/xnli"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rq9eecw9jfwo","executionInfo":{"status":"ok","timestamp":1733299965425,"user_tz":360,"elapsed":3292545,"user":{"displayName":"Liza Pavlova","userId":"00412632503379369479"}},"outputId":"3ae38d95-7857-46a4-bb23-0df931e42cee"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-04 07:17:56.792508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-04 07:17:56.812981: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-04 07:17:56.819094: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-04 07:17:56.840941: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-12-04 07:17:57.851102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Preprocessing data... (this takes a little bit, should only happen once per dataset)\n","Map (num_proc=2): 100% 10020/10020 [00:01<00:00, 7747.08 examples/s]\n","/content/drive/My Drive/nlp_final_project/run.py:334: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = trainer_class(\n","Evaluating on the test set...\n","Filter: 100% 10020/10020 [00:01<00:00, 7795.77 examples/s]\n","Filter: 100% 10020/10020 [00:01<00:00, 7851.46 examples/s]\n","\n","Evaluation on English test set:\n","100% 627/627 [08:28<00:00,  1.62it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","100% 627/627 [08:28<00:00,  1.23it/s]\n","{'eval_loss': 0.7432028651237488, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.7822355289421158, 'eval_precision': 0.7822527010838699, 'eval_recall': 0.7822355289421158, 'eval_f1': 0.7814999139593708, 'eval_runtime': 511.9539, 'eval_samples_per_second': 9.786, 'eval_steps_per_second': 1.225}\n","\n","Evaluation on Russian test set:\n","100% 627/627 [08:39<00:00,  1.21it/s]\n","{'eval_loss': 0.9673462510108948, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.6978043912175649, 'eval_precision': 0.7017824672789587, 'eval_recall': 0.6978043912175649, 'eval_f1': 0.6973319438394747, 'eval_runtime': 520.0927, 'eval_samples_per_second': 9.633, 'eval_steps_per_second': 1.206}\n","\n","Evaluation on the entire test set:\n","100% 1253/1253 [17:10<00:00,  1.22it/s]\n","{'eval_loss': 0.855274498462677, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.7400199600798403, 'eval_precision': 0.7415504952399885, 'eval_recall': 0.7400199600798403, 'eval_f1': 0.7395386191410805, 'eval_runtime': 1031.2278, 'eval_samples_per_second': 9.717, 'eval_steps_per_second': 1.215}\n","100% 627/627 [10:25<00:00,  1.00it/s]\n","Misclassified examples for English have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/xnli/misclassified_English.jsonl\n","100% 627/627 [09:34<00:00,  1.09it/s]\n","Misclassified examples for Russian have been saved to ./output_xnli_en_ru_bert_2_test/xnli_metaphor_model_testing/xnli/misclassified_Russian.jsonl\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"08WmM4lzclET"},"execution_count":null,"outputs":[]}]}